{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medium link:\n",
    "https://medium.com/@ltashebir77/seq2seq-a-transformer-driven-german-to-english-translator-df411ac42c2d\n",
    "\n",
    "# Github including pyfiles:\n",
    "https://github.com/lashebir/de-en-translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from train import save_training_results_to_df, train_epoch, evaluate, translate, my_check_disk_space, save_model_locally\n",
    "# from preprocess import get_dataloaders2, split_parallel_corpus_chunked, TranslationIterableDataset, get_dataloader_from_files, train_tokenizer\n",
    "from preprocess import load_tokenizer, get_dataloader_from_files\n",
    "from test_model import load_tokenizer, test_model, translate_batch, calculate_bleu, save_results_to_df, translate\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from mlflow.models.signature import infer_signature\n",
    "# from model import Seq2SeqTransformer\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import sentencepiece as spm\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import nltk\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del batch, output, loss\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        print(\"Model embedding vocab size:\", self.embedding.num_embeddings)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=512, nhead=8, num_encoder_layers=6,\n",
    "                 num_decoder_layers=6, dim_feedforward=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        \n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        print(\"Embedding matrix shape:\", self.embedding.weight.shape)\n",
    "\n",
    "        \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "    \n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, src_key_padding_mask=None, tgt_key_padding_mask=None):\n",
    "    # Create subsequent mask for decoder if not provided\n",
    "        if tgt_mask is None:\n",
    "            tgt_seq_len = tgt.size(1)\n",
    "            tgt_mask = self.generate_square_subsequent_mask(tgt_seq_len).to(tgt.device).bool()\n",
    "\n",
    "        if src_key_padding_mask is None:\n",
    "            src_key_padding_mask = (src == 0)  # assuming pad_id = 0\n",
    "        if tgt_key_padding_mask is None:\n",
    "            tgt_key_padding_mask = (tgt == 0)\n",
    "\n",
    "        # Embed and positionally encode\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        tgt = self.embedding(tgt) * math.sqrt(self.d_model)\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "\n",
    "        # Transformer\n",
    "        output = self.transformer(\n",
    "            src,\n",
    "            tgt,\n",
    "            tgt_mask=tgt_mask,\n",
    "            src_key_padding_mask=src_key_padding_mask.bool(),\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask.bool()\n",
    "        )\n",
    "\n",
    "        # Output projection\n",
    "        return self.output_layer(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Training new tokenizer...\n",
      "Train: 8000, Val: 1000, Test: 1000\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: tokenizer_input.txt\n",
      "  input_format: \n",
      "  model_prefix: translation_tokenizer\n",
      "  model_type: BPE\n",
      "  vocab_size: 32000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: [DE]\n",
      "  user_defined_symbols: [EN]\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 1\n",
      "  bos_id: 2\n",
      "  eos_id: 3\n",
      "  pad_id: 0\n",
      "  unk_piece: [UNK]\n",
      "  bos_piece: [BOS]\n",
      "  eos_piece: [EOS]\n",
      "  pad_piece: [PAD]\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: tokenizer_input.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 15959 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: [PAD]\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: [UNK]\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: [BOS]\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: [EOS]\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: [DE]\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: [EN]\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=2571543\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=105\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 15959 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 15959\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 39803\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=58837 min_freq=17\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13648 size=20 all=2738 active=1977 piece=or\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8415 size=40 all=3738 active=2977 piece=▁h\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5705 size=60 all=4539 active=3778 piece=▁is\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4250 size=80 all=5659 active=4898 piece=ve\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3361 size=100 all=6794 active=6033 piece=lich\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3340 min_freq=281\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2883 size=120 all=7649 active=1813 piece=isch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2397 size=140 all=8254 active=2418 piece=de\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1927 size=160 all=8973 active=3137 piece=▁von\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1707 size=180 all=9707 active=3871 piece=uld\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1493 size=200 all=10157 active=4321 piece=▁have\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1478 min_freq=251\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1351 size=220 all=10771 active=1615 piece=rä\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1222 size=240 all=11484 active=2328 piece=über\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1116 size=260 all=12106 active=2950 piece=ungs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1015 size=280 all=12858 active=3702 piece=aus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=943 size=300 all=13608 active=4452 piece=art\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=937 min_freq=214\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=862 size=320 all=14197 active=1530 piece=00\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=799 size=340 all=14782 active=2115 piece=heit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=752 size=360 all=15237 active=2570 piece=▁haben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=700 size=380 all=15792 active=3125 piece=tern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=651 size=400 all=16312 active=3645 piece=ise\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=651 min_freq=192\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=624 size=420 all=16691 active=1333 piece=▁part\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=583 size=440 all=17113 active=1755 piece=ical\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=552 size=460 all=17635 active=2277 piece=▁from\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=526 size=480 all=18115 active=2757 piece=vel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=497 size=500 all=18578 active=3220 piece=▁polit\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=495 min_freq=169\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=470 size=520 all=18965 active=1381 piece=ction\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=450 size=540 all=19374 active=1790 piece=ance\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=425 size=560 all=19775 active=2191 piece=mer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=410 size=580 all=20048 active=2464 piece=che\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=401 size=600 all=20424 active=2840 piece=▁int\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=401 min_freq=150\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=384 size=620 all=20672 active=1262 piece=du\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=368 size=640 all=20991 active=1581 piece=▁ch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=357 size=660 all=21365 active=1955 piece=ließ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=344 size=680 all=21730 active=2320 piece=olitik\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=332 size=700 all=22095 active=2685 piece=▁iss\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=331 min_freq=129\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=321 size=720 all=22372 active=1380 piece=ität\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=310 size=740 all=22837 active=1845 piece=ahl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=300 size=760 all=23071 active=2079 piece=ign\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=291 size=780 all=23468 active=2476 piece=alt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=284 size=800 all=23911 active=2919 piece=unkt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=284 min_freq=112\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=276 size=820 all=24198 active=1468 piece=▁say\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=266 size=840 all=24406 active=1676 piece=lt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=259 size=860 all=24640 active=1910 piece=▁proposal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=250 size=880 all=24826 active=2096 piece=rol\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=241 size=900 all=25070 active=2340 piece=schließ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=241 min_freq=99\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=233 size=920 all=25284 active=1446 piece=▁ins\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=229 size=940 all=25551 active=1713 piece=▁over\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=224 size=960 all=25725 active=1887 piece=▁mark\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=219 size=980 all=25947 active=2109 piece=ständ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=213 size=1000 all=26203 active=2365 piece=bens\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=213 min_freq=89\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=209 size=1020 all=26439 active=1517 piece=▁point\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=203 size=1040 all=26609 active=1687 piece=▁ar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=199 size=1060 all=26901 active=1979 piece=ublic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=196 size=1080 all=27155 active=2233 piece=▁requ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=192 size=1100 all=27306 active=2384 piece=fe\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=192 min_freq=82\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=188 size=1120 all=27592 active=1610 piece=rukt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=184 size=1140 all=27850 active=1868 piece=▁weil\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=181 size=1160 all=28102 active=2120 piece=▁2000\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=178 size=1180 all=28314 active=2332 piece=▁ter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=175 size=1200 all=28436 active=2454 piece=elbst\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=175 min_freq=75\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=171 size=1220 all=28654 active=1628 piece=fall\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=168 size=1240 all=28839 active=1813 piece=▁dafür\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=163 size=1260 all=28946 active=1920 piece=EG\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=160 size=1280 all=29192 active=2166 piece=▁Mrs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=158 size=1300 all=29332 active=2306 piece=▁Gro\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=158 min_freq=70\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=156 size=1320 all=29433 active=1565 piece=▁erw\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=153 size=1340 all=29548 active=1680 piece=ene\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=151 size=1360 all=29726 active=1858 piece=▁pla\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=149 size=1380 all=29838 active=1970 piece=▁future\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=145 size=1400 all=29995 active=2127 piece=ischer\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=145 min_freq=65\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=142 size=1420 all=30197 active=1665 piece=▁ihrer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=139 size=1440 all=30344 active=1812 piece=cond\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=137 size=1460 all=30473 active=1941 piece=ium\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=135 size=1480 all=30702 active=2170 piece=▁maj\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=133 size=1500 all=30836 active=2304 piece=ised\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=133 min_freq=61\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=131 size=1520 all=31021 active=1703 piece=▁democ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=129 size=1540 all=31198 active=1880 piece=▁ser\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=128 size=1560 all=31352 active=2034 piece=▁find\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=126 size=1580 all=31458 active=2140 piece=reichen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=123 size=1600 all=31630 active=2312 piece=aum\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=123 min_freq=57\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=122 size=1620 all=31739 active=1676 piece=▁measures\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=120 size=1640 all=31903 active=1840 piece=▁legal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=118 size=1660 all=31998 active=1935 piece=erk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=116 size=1680 all=32140 active=2077 piece=ents\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=115 size=1700 all=32291 active=2228 piece=▁require\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=115 min_freq=53\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=113 size=1720 all=32431 active=1752 piece=▁aller\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=112 size=1740 all=32544 active=1865 piece=▁world\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=110 size=1760 all=32699 active=2020 piece=▁few\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=109 size=1780 all=32844 active=2165 piece=▁Vertrag\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=106 size=1800 all=32970 active=2291 piece=▁Au\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=106 min_freq=50\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=105 size=1820 all=33089 active=1764 piece=▁einmal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=103 size=1840 all=33193 active=1868 piece=elf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=102 size=1860 all=33382 active=2057 piece=rache\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=101 size=1880 all=33488 active=2163 piece=grund\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=100 size=1900 all=33655 active=2330 piece=▁Beit\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=100 min_freq=47\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=99 size=1920 all=33819 active=1842 piece=▁stand\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=98 size=1940 all=33951 active=1974 piece=▁Punkt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=97 size=1960 all=34102 active=2125 piece=government\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=96 size=1980 all=34211 active=2234 piece=governmental\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=94 size=2000 all=34345 active=2368 piece=▁cr\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=94 min_freq=45\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=93 size=2020 all=34387 active=1754 piece=▁Fl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=92 size=2040 all=34577 active=1944 piece=▁Best\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=91 size=2060 all=34671 active=2038 piece=▁glau\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=90 size=2080 all=34758 active=2125 piece=druck\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=89 size=2100 all=34843 active=2210 piece=führung\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=89 min_freq=43\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=88 size=2120 all=34986 active=1876 piece=▁nationalen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=86 size=2140 all=35095 active=1985 piece=flicht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=85 size=2160 all=35247 active=2137 piece=▁rules\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=84 size=2180 all=35332 active=2222 piece=▁proced\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=82 size=2200 all=35485 active=2375 piece=▁bew\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=82 min_freq=41\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=2220 all=35657 active=1938 piece=ervor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=2240 all=35766 active=2047 piece=▁Umsetzung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=80 size=2260 all=35880 active=2161 piece=▁security\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=79 size=2280 all=35998 active=2279 piece=leicht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=78 size=2300 all=36051 active=2332 piece=▁dep\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=78 min_freq=39\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77 size=2320 all=36110 active=1852 piece=▁6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77 size=2340 all=36217 active=1959 piece=cycling\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=76 size=2360 all=36338 active=2080 piece=▁lack\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=75 size=2380 all=36412 active=2154 piece=fach\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74 size=2400 all=36544 active=2286 piece=half\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=74 min_freq=37\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74 size=2420 all=36584 active=1867 piece=▁achieve\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=73 size=2440 all=36659 active=1942 piece=▁Pal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=73 size=2460 all=36763 active=2046 piece=▁authority\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72 size=2480 all=36896 active=2179 piece=▁having\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=71 size=2500 all=37003 active=2286 piece=▁Haider\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=71 min_freq=35\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=70 size=2520 all=37104 active=1951 piece=▁gentle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=69 size=2540 all=37175 active=2022 piece=▁after\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=2560 all=37263 active=2110 piece=äten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=2580 all=37333 active=2180 piece=▁Vorschläge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=67 size=2600 all=37435 active=2282 piece=▁groups\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=67 min_freq=34\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=2620 all=37525 active=1962 piece=unkte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=65 size=2640 all=37585 active=2022 piece=urn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=65 size=2660 all=37728 active=2165 piece=unktion\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=2680 all=37815 active=2252 piece=mitt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=2700 all=37918 active=2355 piece=rachtens\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=64 min_freq=33\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=63 size=2720 all=37974 active=1951 piece=allen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=2740 all=38070 active=2047 piece=/2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=2760 all=38234 active=2211 piece=völker\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=2780 all=38302 active=2279 piece=▁15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=2800 all=38406 active=2383 piece=gument\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=61 min_freq=32\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=2820 all=38499 active=2005 piece=▁Lös\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=2840 all=38551 active=2057 piece=▁months\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=59 size=2860 all=38577 active=2083 piece=ppos\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=59 size=2880 all=38626 active=2132 piece=▁verschiedenen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=2900 all=38767 active=2273 piece=▁erinn\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=58 min_freq=30\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=2920 all=38817 active=1986 piece=▁Instrument\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=2940 all=38925 active=2094 piece=▁inner\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=2960 all=38926 active=2095 piece=▁vorgesehen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=2980 all=39018 active=2187 piece=schutz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=3000 all=39155 active=2324 piece=▁Als\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=55 min_freq=29\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=3020 all=39247 active=2048 piece=▁interests\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=3040 all=39341 active=2142 piece=▁week\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=3060 all=39411 active=2212 piece=esse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=3080 all=39484 active=2285 piece=▁Schutz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=3100 all=39634 active=2435 piece=▁bod\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=52 min_freq=28\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=3120 all=39714 active=2060 piece=▁intend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=3140 all=39732 active=2078 piece=imum\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=3160 all=39798 active=2144 piece=▁Diskuss\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=3180 all=39936 active=2282 piece=gent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=3200 all=40058 active=2404 piece=isches\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=50 min_freq=27\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=3220 all=40118 active=2042 piece=▁procedure\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=3240 all=40287 active=2211 piece=gaben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=3260 all=40367 active=2291 piece=kontrolle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=3280 all=40483 active=2407 piece=▁Koh\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=3300 all=40518 active=2442 piece=▁experien\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=48 min_freq=26\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=3320 all=40588 active=2093 piece=▁cru\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=3340 all=40626 active=2131 piece=olitiken\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=3360 all=40657 active=2162 piece=▁ze\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=3380 all=40759 active=2264 piece=▁build\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=3400 all=40804 active=2309 piece=▁Beschäftigungs\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=45 min_freq=26\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=3420 all=40903 active=2133 piece=▁getan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=3440 all=40929 active=2159 piece=▁objective\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=3460 all=41007 active=2237 piece=▁Our\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=3480 all=41102 active=2332 piece=▁unemp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=3500 all=41140 active=2370 piece=▁Programms\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=44 min_freq=25\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=3520 all=41194 active=2111 piece=rang\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=3540 all=41289 active=2206 piece=▁share\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=3560 all=41337 active=2254 piece=▁congratul\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=3580 all=41421 active=2338 piece=▁pri\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=3600 all=41499 active=2416 piece=▁wobei\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=42 min_freq=24\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=3620 all=41542 active=2118 piece=▁unserem\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=3640 all=41564 active=2140 piece=asch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=3660 all=41673 active=2249 piece=finden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=3680 all=41704 active=2280 piece=▁recogn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=3700 all=41748 active=2324 piece=▁criminal\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=41 min_freq=23\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=3720 all=41799 active=2138 piece=äss\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=3740 all=41949 active=2288 piece=ience\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=3760 all=41997 active=2336 piece=iveness\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=3780 all=42027 active=2366 piece=▁Verfügung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=3800 all=42109 active=2448 piece=fern\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=39 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=3820 all=42206 active=2189 piece=▁Städ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=3840 all=42250 active=2233 piece=▁behand\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=3860 all=42290 active=2273 piece=▁2000-2006\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=3880 all=42432 active=2415 piece=temp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=3900 all=42551 active=2534 piece=uclear\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=38 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=3920 all=42589 active=2163 piece=▁Integr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=3940 all=42613 active=2187 piece=▁unemployment\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=3960 all=42751 active=2325 piece=▁Kar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=3980 all=42838 active=2412 piece=▁turn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=4000 all=42882 active=2456 piece=▁Treaties\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=37 min_freq=21\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=4020 all=42929 active=2192 piece=äuf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=4040 all=43036 active=2299 piece=teuer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=4060 all=43105 active=2368 piece=▁Langen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=4080 all=43129 active=2392 piece=▁Verwaltung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=4100 all=43219 active=2482 piece=iken\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=35 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=4120 all=43313 active=2249 piece=▁affe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=4140 all=43370 active=2306 piece=▁wegen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=4160 all=43380 active=2316 piece=▁vernünft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=4180 all=43381 active=2317 piece=bod\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=4200 all=43530 active=2466 piece=▁ago\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=34 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=4220 all=43594 active=2241 piece=▁basic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=4240 all=43621 active=2268 piece=▁sorgen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=4260 all=43647 active=2294 piece=▁unaccept\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=4280 all=43703 active=2350 piece=▁11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=4300 all=43781 active=2428 piece=▁When\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=33 min_freq=19\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=4320 all=43846 active=2255 piece=▁Straf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=4340 all=43891 active=2300 piece=▁stellt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=4360 all=43917 active=2326 piece=▁Zweitens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=4380 all=43919 active=2328 piece=▁significant\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=4400 all=43981 active=2390 piece=resp\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=32 min_freq=19\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=4420 all=44060 active=2266 piece=▁Bezie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=4440 all=44077 active=2283 piece=▁immedi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=4460 all=44091 active=2297 piece=▁creating\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=4480 all=44085 active=2291 piece=▁establishing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=4500 all=44232 active=2438 piece=▁Rep\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=31 min_freq=18\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=4520 all=44341 active=2316 piece=▁firm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=4540 all=44407 active=2382 piece=▁using\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=4560 all=44435 active=2410 piece=▁geführt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=4580 all=44432 active=2407 piece=▁Transport\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4600 all=44422 active=2397 piece=ave\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=30 min_freq=18\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4620 all=44520 active=2314 piece=▁occ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4640 all=44596 active=2390 piece=▁total\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4660 all=44642 active=2436 piece=ichtlich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4680 all=44665 active=2459 piece=▁Natürlich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4700 all=44663 active=2457 piece=▁gewährleisten\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=30 min_freq=17\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4720 all=44758 active=2329 piece=▁UN\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4740 all=44870 active=2441 piece=fälle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4760 all=44973 active=2544 piece=▁home\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4780 all=45023 active=2594 piece=▁fraud\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4800 all=45047 active=2618 piece=▁review\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=29 min_freq=17\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4820 all=45085 active=2288 piece=▁everyone\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4840 all=45091 active=2294 piece=▁subsidiarity\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=4860 all=45198 active=2401 piece=tain\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=4880 all=45301 active=2504 piece=änden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=4900 all=45359 active=2562 piece=▁assoc\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=28 min_freq=17\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=4920 all=45396 active=2304 piece=▁events\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=4940 all=45420 active=2328 piece=▁gleichen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=4960 all=45429 active=2337 piece=▁wesentlich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=4980 all=45463 active=2371 piece=cher\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=5000 all=45577 active=2485 piece=griff\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=27 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=5020 all=45625 active=2321 piece=▁talk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=5040 all=45658 active=2354 piece=▁highl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=5060 all=45684 active=2380 piece=zuführen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=5080 all=45695 active=2391 piece=▁Vitorino\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=5100 all=45720 active=2416 piece=▁contribute\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=27 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=5120 all=45706 active=2272 piece=mü\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=5140 all=45866 active=2432 piece=▁unc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=5160 all=45916 active=2482 piece=▁sort\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=5180 all=45927 active=2493 piece=▁fragen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=5200 all=45953 active=2519 piece=▁Bedenken\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=26 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=5220 all=45962 active=2307 piece=▁conference\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5240 all=46012 active=2357 piece=▁21\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5260 all=46106 active=2451 piece=wahl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5280 all=46181 active=2526 piece=▁Brit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5300 all=46235 active=2580 piece=▁benöt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=25 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5320 all=46277 active=2349 piece=▁konnte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5340 all=46287 active=2359 piece=▁competen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5360 all=46280 active=2352 piece=▁effectively\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5380 all=46340 active=2412 piece=ober\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5400 all=46432 active=2504 piece=elten\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5420 all=46509 active=2391 piece=▁poll\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5440 all=46543 active=2425 piece=▁jedes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5460 all=46550 active=2432 piece=▁braucht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5480 all=46544 active=2426 piece=▁referred\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5500 all=46556 active=2438 piece=organisation\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5520 all=46624 active=2391 piece=üng\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5540 all=46731 active=2498 piece=▁fal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5560 all=46799 active=2566 piece=▁Flex\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5580 all=46823 active=2590 piece=▁Costa\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5600 all=46863 active=2630 piece=zeichne\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=23 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5620 all=46892 active=2366 piece=▁origin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5640 all=46924 active=2398 piece=▁reading\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5660 all=46941 active=2415 piece=▁betrachte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5680 all=46938 active=2412 piece=▁konzentrieren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5700 all=47032 active=2506 piece=just\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5720 all=47136 active=2448 piece=inden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5740 all=47215 active=2527 piece=▁verm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5760 all=47254 active=2566 piece=▁übern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5780 all=47296 active=2608 piece=▁strict\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5800 all=47322 active=2634 piece=▁Haushalt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5820 all=47326 active=2369 piece=▁zuständig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5840 all=47342 active=2385 piece=ubl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5860 all=47448 active=2491 piece=zess\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5880 all=47497 active=2540 piece=▁2002\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5900 all=47544 active=2587 piece=idents\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=21 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5920 all=47559 active=2388 piece=General\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5940 all=47605 active=2434 piece=▁impact\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5960 all=47616 active=2445 piece=▁element\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5980 all=47620 active=2449 piece=▁investig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=6000 all=47617 active=2446 piece=▁Ausbildung\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=21 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=6020 all=47612 active=2376 piece=▁Fremdenverkehr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6040 all=47722 active=2486 piece=▁kl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6060 all=47826 active=2590 piece=▁zul\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6080 all=47887 active=2651 piece=▁exem\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6100 all=47932 active=2696 piece=ördert\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=20 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6120 all=47944 active=2407 piece=fordern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6140 all=47971 active=2434 piece=▁ausges\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6160 all=47997 active=2460 piece=▁approve\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6180 all=48004 active=2467 piece=setzungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6200 all=48004 active=2467 piece=▁derartige\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=20 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6220 all=47992 active=2389 piece=▁sovereignty\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6240 all=48045 active=2442 piece=cke\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6260 all=48195 active=2592 piece=ilit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6280 all=48239 active=2636 piece=▁Dann\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6300 all=48274 active=2671 piece=cedure\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=19 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6320 all=48296 active=2435 piece=▁sogen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6340 all=48357 active=2496 piece=ältigen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6360 all=48372 active=2511 piece=▁hoffen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6380 all=48380 active=2519 piece=▁letzter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6400 all=48392 active=2531 piece=▁heritage\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=19 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6420 all=48383 active=2411 piece=▁vermeiden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6440 all=48372 active=2400 piece=▁intervention\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6460 all=48416 active=2444 piece=akis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6480 all=48527 active=2555 piece=▁Dut\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6500 all=48597 active=2625 piece=ormen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6520 all=48641 active=2472 piece=gerung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6540 all=48716 active=2547 piece=▁happy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6560 all=48771 active=2602 piece=ulative\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6580 all=48809 active=2640 piece=anderung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6600 all=48814 active=2645 piece=▁intends\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6620 all=48821 active=2448 piece=▁größeren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6640 all=48821 active=2448 piece=▁entscheid\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6660 all=48818 active=2445 piece=▁beschränken\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6680 all=48807 active=2434 piece=oe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6700 all=48915 active=2542 piece=Vert\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6720 all=49008 active=2535 piece=▁Ins\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6740 all=49070 active=2597 piece=reibt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6760 all=49135 active=2662 piece=▁quot\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6780 all=49222 active=2749 piece=▁Daten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6800 all=49252 active=2779 piece=ktionen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6820 all=49273 active=2479 piece=▁untern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6840 all=49284 active=2490 piece=▁lokaler\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6860 all=49290 active=2496 piece=▁advisers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6880 all=49290 active=2496 piece=▁Vertrages\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6900 all=49275 active=2481 piece=▁Energieträ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6920 all=49263 active=2450 piece=▁credibility\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6940 all=49251 active=2438 piece=▁Kohäsionsfonds\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=6960 all=49324 active=2511 piece=riè\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=6980 all=49405 active=2592 piece=ragt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=7000 all=49471 active=2658 piece=▁nöt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=7020 all=49551 active=2551 piece=uting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=7040 all=49584 active=2584 piece=▁lies\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=7060 all=49643 active=2643 piece=▁China\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=7080 all=49652 active=2652 piece=ategien\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=7100 all=49690 active=2690 piece=▁facing\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=7120 all=49696 active=2491 piece=änderung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=7140 all=49695 active=2490 piece=▁respekt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=7160 all=49714 active=2509 piece=▁financed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=7180 all=49704 active=2499 piece=▁combating\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=7200 all=49690 active=2485 piece=▁challenges\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=7220 all=49672 active=2467 piece=▁Altfahrzeuge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=7240 all=49658 active=2453 piece=▁Stahlindustrie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7260 all=49773 active=2568 piece=▁23\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7280 all=49848 active=2643 piece=▁Bol\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7300 all=49894 active=2689 piece=isher\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7320 all=49942 active=2538 piece=▁insp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7340 all=49998 active=2594 piece=jahres\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7360 all=50045 active=2641 piece=▁domin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7380 all=50070 active=2666 piece=▁Gewähr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7400 all=50078 active=2674 piece=▁lokale\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7420 all=50109 active=2535 piece=▁Kingdom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7440 all=50104 active=2530 piece=▁niemand\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7460 all=50115 active=2541 piece=▁Lösungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7480 all=50104 active=2530 piece=▁secondly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7500 all=50110 active=2536 piece=▁disadvant\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7520 all=50113 active=2506 piece=▁bestätigen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7540 all=50099 active=2492 piece=▁gefährlicher\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7560 all=50119 active=2512 piece=MEs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7580 all=50193 active=2586 piece=feil\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7600 all=50278 active=2671 piece=▁PSE\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7620 all=50322 active=2558 piece=hilos\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7640 all=50355 active=2591 piece=▁abst\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7660 all=50383 active=2619 piece=inding\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7680 all=50471 active=2707 piece=▁aktiv\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7700 all=50476 active=2712 piece=fertigt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7720 all=50491 active=2535 piece=▁chance\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7740 all=50501 active=2545 piece=▁racism\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7760 all=50535 active=2579 piece=▁Akteure\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7780 all=50542 active=2586 piece=▁gezeigt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7800 all=50538 active=2582 piece=▁consolid\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7820 all=50525 active=2512 piece=▁Botschaft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7840 all=50516 active=2503 piece=▁Bolkestein\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7860 all=50501 active=2488 piece=▁distributed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7880 all=50488 active=2475 piece=▁notification\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7900 all=50479 active=2466 piece=IS\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7920 all=50555 active=2595 piece=etze\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7940 all=50621 active=2661 piece=▁GDP\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7960 all=50695 active=2735 piece=inter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7980 all=50761 active=2801 piece=▁merg\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=8000 all=50805 active=2845 piece=▁Dalai\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=8020 all=50822 active=2558 piece=▁lives\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=8040 all=50864 active=2600 piece=▁Fehler\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=8060 all=50873 active=2609 piece=▁leicht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=8080 all=50907 active=2643 piece=▁Finnish\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=8100 all=50918 active=2654 piece=▁glauben\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=8120 all=50923 active=2551 piece=▁Eurojust\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=8140 all=50919 active=2547 piece=▁verfolgt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=8160 all=50911 active=2539 piece=▁ergriffen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=8180 all=50899 active=2527 piece=▁strategies\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=8200 all=50887 active=2515 piece=▁Bereitschaft\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8220 all=50891 active=2549 piece=AG\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8240 all=50983 active=2641 piece=▁Ah\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8260 all=51032 active=2690 piece=oura\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8280 all=51075 active=2733 piece=▁Lis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8300 all=51137 active=2795 piece=reize\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8320 all=51178 active=2596 piece=▁ante\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8340 all=51198 active=2616 piece=atever\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8360 all=51250 active=2668 piece=uklear\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8380 all=51270 active=2688 piece=▁Tagen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8400 all=51287 active=2705 piece=▁sixth\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8420 all=51340 active=2618 piece=▁Gerade\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8440 all=51352 active=2630 piece=▁compla\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8460 all=51365 active=2643 piece=▁stattf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8480 all=51378 active=2656 piece=▁Ordnung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8500 all=51378 active=2656 piece=▁genuine\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8520 all=51389 active=2580 piece=▁Behinder\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8540 all=51387 active=2578 piece=▁fighting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8560 all=51377 active=2568 piece=▁zugrunde\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8580 all=51368 active=2559 piece=▁ernsthaft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8600 all=51358 active=2549 piece=▁betrachten\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8620 all=51349 active=2559 piece=▁Schwerpunkt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8640 all=51333 active=2543 piece=▁Griechenland\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=8660 all=51317 active=2527 piece=▁bevorstehenden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8680 all=51348 active=2558 piece=det\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8700 all=51422 active=2632 piece=▁48\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8720 all=51505 active=2653 piece=uses\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8740 all=51551 active=2699 piece=▁tut\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8760 all=51600 active=2748 piece=itrak\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8780 all=51649 active=2797 piece=▁aver\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8800 all=51671 active=2819 piece=arding\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8820 all=51749 active=2660 piece=▁Dafür\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8840 all=51751 active=2662 piece=▁price\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8860 all=51769 active=2680 piece=gebiete\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8880 all=51802 active=2713 piece=▁angeht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8900 all=51805 active=2716 piece=▁island\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8920 all=51817 active=2603 piece=oubtedly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8940 all=51816 active=2602 piece=▁average\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8960 all=51813 active=2599 piece=▁highest\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=8980 all=51810 active=2596 piece=vorschlag\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=9000 all=51811 active=2597 piece=▁deswegen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=9020 all=51795 active=2575 piece=▁Kernkraft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=9040 all=51791 active=2571 piece=▁geltenden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=9060 all=51793 active=2573 piece=▁Umstruktur\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=9080 all=51779 active=2559 piece=▁reconsider\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=9100 all=51769 active=2549 piece=▁eingeleitet\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=9120 all=51751 active=2571 piece=▁Betrügereien\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=9140 all=51732 active=2552 piece=▁Christdemokrat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9160 all=51759 active=2579 piece=ikh\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9180 all=51815 active=2635 piece=▁Sc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9200 all=51871 active=2691 piece=isms\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9220 all=51938 active=2659 piece=▁Fäh\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9240 all=51974 active=2695 piece=Gebie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9260 all=52039 active=2760 piece=uling\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9280 all=52084 active=2805 piece=▁Mann\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9300 all=52104 active=2825 piece=▁inev\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9320 all=52158 active=2658 piece=itizen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9340 all=52169 active=2669 piece=▁Maast\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9360 all=52184 active=2684 piece=▁fried\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9380 all=52190 active=2690 piece=▁towns\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9400 all=52214 active=2714 piece=▁Hatzid\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9420 all=52215 active=2611 piece=▁geleis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9440 all=52219 active=2615 piece=▁seiten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9460 all=52230 active=2626 piece=rounding\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9480 all=52226 active=2622 piece=▁anderes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9500 all=52216 active=2612 piece=▁operate\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9520 all=52211 active=2606 piece=glichkeit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9540 all=52215 active=2610 piece=▁decisive\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9560 all=52203 active=2598 piece=▁repeated\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9580 all=52209 active=2604 piece=▁Reformpro\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9600 all=52198 active=2593 piece=▁immediate\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9620 all=52182 active=2594 piece=katastrophe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9640 all=52172 active=2584 piece=▁gefährlich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9660 all=52159 active=2571 piece=▁Jahrtausend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9680 all=52143 active=2555 piece=▁undertaking\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9700 all=52125 active=2537 piece=▁unabhängigen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=9720 all=52107 active=2589 piece=▁ausgezeichneten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=9740 all=52164 active=2646 piece=mpt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=9760 all=52239 active=2721 piece=ancy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=9780 all=52302 active=2784 piece=schl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=9800 all=52372 active=2854 piece=▁Mot\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=9820 all=52414 active=2659 piece=going\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=9840 all=52478 active=2723 piece=raxis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=9860 all=52500 active=2745 piece=▁Such\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=9880 all=52522 active=2767 piece=▁hull\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=9900 all=52551 active=2796 piece=digten\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=9920 all=52590 active=2665 piece=▁Phase\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=9940 all=52602 active=2677 piece=▁dient\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=9960 all=52608 active=2683 piece=▁spend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=9980 all=52642 active=2717 piece=samkeit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10000 all=52662 active=2737 piece=▁Surely\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10020 all=52656 active=2628 piece=▁fehlen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10040 all=52656 active=2628 piece=▁sought\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10060 all=52643 active=2615 piece=bewerber\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10080 all=52681 active=2653 piece=▁Budgets\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10100 all=52680 active=2652 piece=▁genannt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10120 all=52671 active=2625 piece=greifende\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10140 all=52693 active=2647 piece=▁Sjöstedt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10160 all=52685 active=2639 piece=▁erweiter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10180 all=52680 active=2634 piece=▁regulate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10200 all=52678 active=2632 piece=▁Abkommens\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10220 all=52668 active=2624 piece=▁einfachen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10240 all=52656 active=2612 piece=▁unmöglich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10260 all=52645 active=2601 piece=▁britischen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10280 all=52630 active=2586 piece=▁recognises\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10300 all=52617 active=2573 piece=▁Mitgliedern\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10320 all=52603 active=2617 piece=▁hervorragen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10340 all=52590 active=2604 piece=▁Kooperations\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10360 all=52573 active=2587 piece=▁unzureichend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=10380 all=52556 active=2570 piece=▁Constitutional\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10400 all=52599 active=2613 piece=96/\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10420 all=52661 active=2690 piece=rel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10440 all=52729 active=2758 piece=disc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10460 all=52773 active=2802 piece=udem\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10480 all=52792 active=2821 piece=▁Okt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10500 all=52823 active=2852 piece=5-002\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10520 all=52876 active=2691 piece=known\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10540 all=52911 active=2726 piece=▁Bill\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10560 all=52928 active=2743 piece=▁Well\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10580 all=52944 active=2759 piece=▁size\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10600 all=52996 active=2811 piece=istern\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10620 all=53037 active=2688 piece=waffen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10640 all=53057 active=2708 piece=▁Marin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10660 all=53058 active=2709 piece=▁displ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10680 all=53072 active=2723 piece=▁sozio\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10700 all=53084 active=2735 piece=ivation\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10720 all=53110 active=2678 piece=▁Formen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10740 all=53102 active=2670 piece=▁attend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10760 all=53106 active=2674 piece=▁looked\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10780 all=53099 active=2667 piece=▁umfaßt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10800 all=53126 active=2694 piece=ordinary\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10820 all=53145 active=2673 piece=▁Jacques\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10840 all=53143 active=2671 piece=▁beziehe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10860 all=53136 active=2664 piece=▁hierfür\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10880 all=53137 active=2665 piece=▁rechnen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10900 all=53149 active=2677 piece=▁Betriebs\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10920 all=53141 active=2645 piece=▁bereiten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10940 all=53129 active=2633 piece=▁infringe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10960 all=53115 active=2619 piece=▁strictly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=10980 all=53123 active=2627 piece=▁Mobilität\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=11000 all=53119 active=2623 piece=▁erläutert\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=11020 all=53100 active=2637 piece=▁wichtiges\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=11040 all=53096 active=2633 piece=▁Vorschlags\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=11060 all=53082 active=2619 piece=▁legitimate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=11080 all=53067 active=2604 piece=▁Königreichs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=11100 all=53053 active=2590 piece=▁verzeichnen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=11120 all=53039 active=2639 piece=▁productivity\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=11140 all=53021 active=2621 piece=▁investigation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=11160 all=53003 active=2603 piece=▁Schlußfolgerung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11180 all=53058 active=2658 piece=kan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11200 all=53121 active=2721 piece=aupt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11220 all=53206 active=2739 piece=kauf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11240 all=53260 active=2793 piece=öten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11260 all=53276 active=2809 piece=▁arg\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11280 all=53296 active=2829 piece=Richt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11300 all=53348 active=2881 piece=hrter\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11320 all=53414 active=2731 piece=runde\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11340 all=53451 active=2768 piece=▁Herz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11360 all=53465 active=2782 piece=▁bomb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11380 all=53482 active=2799 piece=▁tagt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11400 all=53512 active=2829 piece=irable\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11420 all=53558 active=2720 piece=▁Bedro\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11440 all=53568 active=2730 piece=▁Menge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11460 all=53578 active=2740 piece=▁decre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11480 all=53585 active=2747 piece=▁perce\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11500 all=53598 active=2760 piece=Bericht\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11520 all=53636 active=2717 piece=trieben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11540 all=53641 active=2722 piece=▁Privat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11560 all=53633 active=2714 piece=▁annehm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11580 all=53633 active=2714 piece=▁klären\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11600 all=53621 active=2702 piece=▁sieben\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11620 all=53628 active=2689 piece=ifiziert\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11640 all=53639 active=2700 piece=▁Pfeiler\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11660 all=53640 active=2701 piece=▁collect\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11680 all=53631 active=2692 piece=▁gezielt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11700 all=53620 active=2681 piece=▁perform\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11720 all=53613 active=2672 piece=▁warning\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11740 all=53607 active=2666 piece=▁Beratung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11760 all=53599 active=2658 piece=▁Vielzahl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11780 all=53589 active=2648 piece=▁evidence\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11800 all=53574 active=2633 piece=▁mobility\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11820 all=53565 active=2670 piece=▁versteht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11840 all=53564 active=2669 piece=▁Gerichten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11860 all=53554 active=2659 piece=▁eingehend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11880 all=53539 active=2644 piece=▁outermost\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11900 all=53529 active=2634 piece=▁Argumenten\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11920 all=53513 active=2661 piece=▁ausgeführt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11940 all=53493 active=2641 piece=▁philosophy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11960 all=53480 active=2628 piece=▁Ergebnissen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=11980 all=53465 active=2613 piece=▁keinesfalls\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=12000 all=53445 active=2593 piece=▁Futtermittel\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=12020 all=53425 active=2653 piece=▁ökonomischen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=12040 all=53405 active=2633 piece=▁verwirklichen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=12060 all=53385 active=2613 piece=▁Sitzungsperiode\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12080 all=53397 active=2625 piece=gy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12100 all=53442 active=2670 piece=arg\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12120 all=53482 active=2707 piece=obb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12140 all=53571 active=2796 piece=äme\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12160 all=53587 active=2812 piece=▁UC\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12180 all=53627 active=2852 piece=east\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12200 all=53671 active=2896 piece=ller\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12220 all=53726 active=2736 piece=tung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12240 all=53755 active=2765 piece=▁Ari\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12260 all=53766 active=2776 piece=▁Ruß\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12280 all=53786 active=2796 piece=▁zit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12300 all=53810 active=2820 piece=hagen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12320 all=53853 active=2732 piece=orary\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12340 all=53905 active=2784 piece=usive\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12360 all=53936 active=2815 piece=▁Effe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12380 all=53955 active=2834 piece=▁Stör\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12400 all=53972 active=2851 piece=▁gone\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12420 all=53980 active=2707 piece=(1998)\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12440 all=54001 active=2728 piece=faktor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12460 all=54046 active=2773 piece=städte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12480 all=54053 active=2780 piece=▁Flugh\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12500 all=54049 active=2776 piece=▁Sport\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12520 all=54050 active=2704 piece=▁essen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12540 all=54048 active=2702 piece=▁posed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12560 all=54046 active=2700 piece=▁zumal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12580 all=54071 active=2725 piece=reicher\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12600 all=54112 active=2766 piece=zogenen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12620 all=54116 active=2707 piece=▁Heimat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12640 all=54111 active=2702 piece=▁Serben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12660 all=54112 active=2703 piece=▁centre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12680 all=54116 active=2707 piece=▁fertig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12700 all=54119 active=2710 piece=▁racial\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12720 all=54120 active=2707 piece=▁verste\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12740 all=54134 active=2721 piece=ikations\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12760 all=54160 active=2747 piece=▁Kapitel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12780 all=54155 active=2742 piece=▁Wissens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12800 all=54146 active=2733 piece=▁factors\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12820 all=54133 active=2695 piece=▁municip\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12840 all=54131 active=2693 piece=▁showing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12860 all=54128 active=2690 piece=leistungs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12880 all=54143 active=2705 piece=▁Laufbahn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12900 all=54137 active=2699 piece=▁aufbauen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12920 all=54126 active=2696 piece=▁gebildet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12940 all=54115 active=2685 piece=▁schließt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12960 all=54114 active=2684 piece=▁ähnliche\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=12980 all=54111 active=2681 piece=▁Certainly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13000 all=54099 active=2669 piece=▁Rechtfert\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13020 all=54084 active=2689 piece=▁betreiben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13040 all=54067 active=2672 piece=▁gefährden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13060 all=54049 active=2654 piece=▁undermine\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13080 all=54040 active=2645 piece=▁Dokumenten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13100 all=54024 active=2629 piece=▁appelliere\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13120 all=54011 active=2689 piece=▁inevitably\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13140 all=53991 active=2669 piece=▁tremendous\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13160 all=53973 active=2651 piece=▁Instruments\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13180 all=53956 active=2634 piece=▁earthquakes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13200 all=53941 active=2619 piece=▁potentielle\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13220 all=53924 active=2681 piece=▁Insbesondere\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13240 all=53907 active=2664 piece=▁fortzusetzen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13260 all=53889 active=2646 piece=▁Österreicher\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13280 all=53872 active=2629 piece=▁eingebrachten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13300 all=53854 active=2611 piece=▁Wiederaufnahme\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=13320 all=53835 active=2674 piece=▁Mitgliedsländer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13340 all=53852 active=2691 piece=ez\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13360 all=53896 active=2735 piece=dds\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13380 all=53954 active=2793 piece=▁4.\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13400 all=53970 active=2809 piece=5-02\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13420 all=54010 active=2737 piece=held\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13440 all=54053 active=2780 piece=ores\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13460 all=54097 active=2824 piece=wind\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13480 all=54128 active=2855 piece=▁Frü\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13500 all=54143 active=2870 piece=▁ast\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13520 all=54162 active=2725 piece=▁ört\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13540 all=54195 active=2758 piece=höhen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13560 all=54241 active=2804 piece=ptive\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13580 all=54267 active=2830 piece=ässer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13600 all=54260 active=2823 piece=▁Mart\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13620 all=54268 active=2720 piece=▁conj\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13640 all=54272 active=2724 piece=▁heik\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13660 all=54277 active=2729 piece=▁ster\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13680 all=54292 active=2744 piece=banken\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13700 all=54332 active=2784 piece=jenige\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13720 all=54363 active=2746 piece=ruhest\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13740 all=54390 active=2773 piece=▁Amtes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13760 all=54384 active=2767 piece=▁Korru\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13780 all=54387 active=2770 piece=▁birgt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13800 all=54389 active=2772 piece=▁hohes\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13820 all=54393 active=2724 piece=▁shape\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13840 all=54398 active=2729 piece=Article\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13860 all=54417 active=2748 piece=laubnis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13880 all=54446 active=2777 piece=▁Before\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13900 all=54445 active=2776 piece=▁KULTUR\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13920 all=54442 active=2720 piece=▁adhere\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13940 all=54451 active=2729 piece=▁einzum\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13960 all=54438 active=2716 piece=▁lowest\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=13980 all=54428 active=2706 piece=▁tragic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14000 all=54431 active=2709 piece=ensystem\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14020 all=54449 active=2738 piece=▁Ansehen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14040 all=54438 active=2727 piece=▁Konkurr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14060 all=54429 active=2718 piece=▁Umfangs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14080 all=54415 active=2704 piece=▁billigt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14100 all=54408 active=2697 piece=▁erfreut\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14120 all=54395 active=2708 piece=▁immense\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14140 all=54385 active=2698 piece=▁prinzip\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14160 all=54377 active=2690 piece=▁thirdly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14180 all=54371 active=2684 piece=elessness\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14200 all=54377 active=2690 piece=▁Decision\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14220 all=54373 active=2715 piece=▁Selbstge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14240 all=54359 active=2701 piece=▁combined\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14260 all=54345 active=2687 piece=▁findings\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14280 all=54330 active=2672 piece=▁modernen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14300 all=54320 active=2662 piece=▁struktur\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14320 all=54319 active=2711 piece=initiative\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14340 all=54314 active=2706 piece=▁Erzeugung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14360 all=54305 active=2697 piece=▁Vorbehalt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14380 all=54289 active=2681 piece=▁conflicts\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14400 all=54280 active=2672 piece=▁höchstens\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14420 all=54264 active=2698 piece=▁penalties\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14440 all=54251 active=2685 piece=▁schneller\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14460 all=54241 active=2675 piece=▁zerstören\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14480 all=54232 active=2666 piece=▁Innovation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14500 all=54221 active=2655 piece=▁ansprechen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14520 all=54211 active=2702 piece=▁dependency\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14540 all=54199 active=2690 piece=▁incentives\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14560 all=54180 active=2671 piece=▁referendum\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14580 all=54163 active=2654 piece=▁vorherigen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14600 all=54148 active=2639 piece=▁Anmerkungen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14620 all=54132 active=2692 piece=▁Wortmeldung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14640 all=54115 active=2675 piece=▁einzuräumen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14660 all=54095 active=2655 piece=▁reformieren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14680 all=54078 active=2638 piece=▁Auffassungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14700 all=54061 active=2621 piece=▁Unionsbürger\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14720 all=54042 active=2685 piece=▁explanations\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14740 all=54025 active=2668 piece=▁verschwinden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14760 all=54007 active=2650 piece=▁Verteidigungs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14780 all=53989 active=2632 piece=▁weitestgehend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14800 all=53970 active=2613 piece=▁interregionale\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=14820 all=53950 active=2679 piece=▁bereitzustellen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=14840 all=53974 active=2703 piece=FL\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=14860 all=54001 active=2730 piece=so\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=14880 all=54036 active=2765 piece=Der\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=14900 all=54064 active=2793 piece=enk\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=14920 all=54117 active=2751 piece=olk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=14940 all=54158 active=2792 piece=äle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=14960 all=54167 active=2801 piece=▁83\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=14980 all=54182 active=2816 piece=1997\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15000 all=54205 active=2839 piece=buch\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15020 all=54244 active=2745 piece=iano\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15040 all=54284 active=2785 piece=owis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15060 all=54308 active=2809 piece=urse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15080 all=54323 active=2824 piece=▁250\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15100 all=54324 active=2825 piece=▁Cux\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15120 all=54328 active=2720 piece=▁Mun\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15140 all=54336 active=2728 piece=▁Wür\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15160 all=54345 active=2737 piece=▁leb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15180 all=54363 active=2755 piece=Freie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15200 all=54384 active=2776 piece=ayann\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15220 all=54413 active=2747 piece=föder\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15240 all=54440 active=2774 piece=limin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15260 all=54465 active=2799 piece=suche\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15280 all=54494 active=2828 piece=▁Bele\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15300 all=54496 active=2830 piece=▁Krit\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15320 all=54503 active=2731 piece=▁Rett\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15340 all=54506 active=2734 piece=▁aufs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15360 all=54510 active=2738 piece=▁gift\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15380 all=54515 active=2743 piece=▁race\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15400 all=54522 active=2750 piece=▁würd\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15420 all=54542 active=2743 piece=antien\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15440 all=54569 active=2770 piece=gerade\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15460 all=54600 active=2801 piece=iteten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15480 all=54629 active=2830 piece=terung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15500 all=54669 active=2870 piece=ührend\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15520 all=54663 active=2727 piece=▁EAGFL\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15540 all=54659 active=2723 piece=▁Kapaz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15560 all=54659 active=2723 piece=▁Reise\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15580 all=54650 active=2714 piece=▁Waren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15600 all=54653 active=2717 piece=▁embar\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15620 all=54656 active=2733 piece=▁imply\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15640 all=54656 active=2733 piece=▁pilot\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15660 all=54654 active=2731 piece=▁strug\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15680 all=54655 active=2732 piece=4/2000)\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15700 all=54679 active=2756 piece=gründen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15720 all=54709 active=2762 piece=schwung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15740 all=54727 active=2780 piece=▁Ariane\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15760 all=54725 active=2778 piece=▁Gegner\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15780 all=54715 active=2768 piece=▁Mengen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15800 all=54707 active=2760 piece=▁Sprung\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15820 all=54701 active=2729 piece=▁arrive\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15840 all=54703 active=2731 piece=▁ecolog\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15860 all=54696 active=2724 piece=▁grünes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15880 all=54688 active=2716 piece=▁merger\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15900 all=54685 active=2713 piece=▁stoßen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15920 all=54684 active=2734 piece=▁wächst\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15940 all=54693 active=2743 piece=gewichte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15960 all=54713 active=2763 piece=streicht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=15980 all=54702 active=2752 piece=▁Eurodac\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16000 all=54697 active=2747 piece=▁Kräften\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16020 all=54690 active=2728 piece=▁Umstand\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16040 all=54680 active=2718 piece=▁backing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16060 all=54670 active=2708 piece=▁divided\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16080 all=54658 active=2696 piece=▁exploit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16100 all=54641 active=2679 piece=▁hundred\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16120 all=54631 active=2723 piece=▁popular\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16140 all=54614 active=2706 piece=▁tragedy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16160 all=54608 active=2700 piece=behaltlos\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16180 all=54623 active=2715 piece=ränkungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16200 all=54631 active=2723 piece=▁Bereichs\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16220 all=54617 active=2718 piece=▁Industry\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16240 all=54605 active=2706 piece=▁Schatten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16260 all=54592 active=2693 piece=▁anfangen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16280 all=54587 active=2688 piece=▁compiled\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16300 all=54572 active=2673 piece=▁distingu\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16320 all=54556 active=2711 piece=▁frontier\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16340 all=54547 active=2702 piece=▁mehrmals\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16360 all=54529 active=2684 piece=▁regarded\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16380 all=54512 active=2667 piece=▁standing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16400 all=54507 active=2662 piece=▁vorgeben\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16420 all=54504 active=2723 piece=haltigkeit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16440 all=54502 active=2721 piece=▁Eisenbahn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16460 all=54493 active=2712 piece=▁Quaestors\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16480 all=54482 active=2701 piece=▁accepting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16500 all=54463 active=2682 piece=▁delegates\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16520 all=54455 active=2716 piece=▁fragility\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16540 all=54439 active=2700 piece=▁kostspiel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16560 all=54425 active=2686 piece=▁schnellen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16580 all=54410 active=2671 piece=▁verzerren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16600 all=54391 active=2652 piece=▁übernimmt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16620 all=54375 active=2704 piece=▁Amerikaner\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16640 all=54360 active=2689 piece=▁Memorandum\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16660 all=54345 active=2674 piece=▁angefangen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16680 all=54330 active=2659 piece=▁besonderer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16700 all=54311 active=2640 piece=▁entgegenzu\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16720 all=54298 active=2703 piece=▁indirectly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16740 all=54282 active=2687 piece=▁prescribed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16760 all=54263 active=2668 piece=▁umstritten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16780 all=54249 active=2654 piece=▁zweckmäßig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16800 all=54236 active=2641 piece=▁Altfahrzeug\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16820 all=54221 active=2696 piece=▁Materialien\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16840 all=54202 active=2677 piece=▁amtierender\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16860 all=54185 active=2660 piece=▁dargestellt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16880 all=54165 active=2640 piece=▁hervorgehen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16900 all=54146 active=2621 piece=▁rückwirkend\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16920 all=54133 active=2695 piece=unktionalität\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16940 all=54118 active=2680 piece=▁Mitarbeitern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16960 all=54098 active=2660 piece=▁ausschließen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=16980 all=54080 active=2642 piece=▁gerichtliche\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=17000 all=54061 active=2623 piece=▁unterbrochen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=17020 all=54048 active=2690 piece=▁Erscheinungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=17040 all=54028 active=2670 piece=▁Untersuchungs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=17060 all=54008 active=2650 piece=▁entschuldigen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=17080 all=53988 active=2630 piece=angelegenheiten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=17100 all=53968 active=2610 piece=▁comprehensible\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=17120 all=53948 active=2679 piece=▁Gesamtfangmenge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17140 all=53934 active=2665 piece=Er\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17160 all=53960 active=2691 piece=aca\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17180 all=53994 active=2725 piece=iki\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17200 all=54031 active=2762 piece=▁(1\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17220 all=54045 active=2714 piece=,000\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17240 all=54072 active=2741 piece=chit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17260 all=54098 active=2767 piece=irbt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17280 all=54120 active=2789 piece=reht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17300 all=54143 active=2812 piece=zähl\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17320 all=54175 active=2737 piece=ofar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17340 all=54184 active=2746 piece=▁22,\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17360 all=54182 active=2744 piece=▁Kum\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17380 all=54197 active=2759 piece=▁bla\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17400 all=54206 active=2768 piece=▁rus\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17420 all=54219 active=2723 piece=▁ord\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17440 all=54233 active=2737 piece=ampen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17460 all=54258 active=2762 piece=dende\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17480 all=54274 active=2778 piece=iefly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17500 all=54293 active=2797 piece=lehrt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17520 all=54323 active=2743 piece=▁Ans\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17540 all=54339 active=2759 piece=lösen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17560 all=54360 active=2780 piece=reckt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17580 all=54392 active=2812 piece=uität\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17600 all=54413 active=2833 piece=▁81(3\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17620 all=54437 active=2743 piece=quem\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17640 all=54457 active=2763 piece=▁Büro\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17660 all=54462 active=2768 piece=▁Kauk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17680 all=54465 active=2771 piece=▁Symp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17700 all=54466 active=2772 piece=▁dens\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17720 all=54487 active=2743 piece=▁ewig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17740 all=54487 active=2743 piece=▁mild\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17760 all=54489 active=2745 piece=▁soft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17780 all=54495 active=2751 piece=Israel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17800 all=54509 active=2765 piece=attete\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17820 all=54530 active=2745 piece=fuhren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17840 all=54550 active=2765 piece=illage\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17860 all=54570 active=2785 piece=meldes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17880 all=54581 active=2796 piece=region\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17900 all=54609 active=2824 piece=wärtig\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17920 all=54612 active=2733 piece=▁Among\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17940 all=54608 active=2729 piece=▁Flamm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17960 all=54602 active=2723 piece=▁Neues\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=17980 all=54599 active=2720 piece=▁Women\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18000 all=54591 active=2712 piece=▁bread\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18020 all=54592 active=2730 piece=▁false\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18040 all=54584 active=2722 piece=▁hulls\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18060 all=54594 active=2732 piece=▁marks\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18080 all=54592 active=2730 piece=▁scene\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18100 all=54583 active=2721 piece=▁unbef\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18120 all=54586 active=2732 piece=▁womit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18140 all=54595 active=2741 piece=beugung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18160 all=54603 active=2749 piece=hörlich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18180 all=54621 active=2767 piece=nehmung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18200 all=54633 active=2779 piece=stitute\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18220 all=54657 active=2755 piece=zählung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18240 all=54652 active=2750 piece=▁Firmen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18260 all=54652 active=2750 piece=▁Kammer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18280 all=54643 active=2741 piece=▁Result\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18300 all=54634 active=2732 piece=▁Zeilen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18320 all=54634 active=2732 piece=▁begins\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18340 all=54621 active=2719 piece=▁deplor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18360 all=54611 active=2709 piece=▁fossil\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18380 all=54598 active=2696 piece=▁hypoth\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18400 all=54605 active=2703 piece=▁murder\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18420 all=54596 active=2720 piece=▁relies\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18440 all=54589 active=2713 piece=▁strebt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18460 all=54587 active=2711 piece=▁vessel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18480 all=54575 active=2699 piece=aneously\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18500 all=54598 active=2722 piece=inquency\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18520 all=54612 active=2743 piece=stockung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18540 all=54624 active=2755 piece=▁António\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18560 all=54615 active=2746 piece=▁Fischer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18580 all=54613 active=2744 piece=▁Kulture\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18600 all=54604 active=2735 piece=▁Russian\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18620 all=54595 active=2722 piece=▁Verlaub\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18640 all=54577 active=2704 piece=▁anzusch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18660 all=54569 active=2696 piece=▁blicken\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18680 all=54551 active=2678 piece=▁diverse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18700 all=54536 active=2663 piece=▁fashion\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18720 all=54517 active=2708 piece=▁homogen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18740 all=54510 active=2701 piece=▁letztes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18760 all=54499 active=2690 piece=▁pretext\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18780 all=54479 active=2670 piece=▁specify\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18800 all=54471 active=2662 piece=▁unrecht\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18820 all=54470 active=2722 piece=▁worries\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18840 all=54470 active=2722 piece=enteilung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18860 all=54483 active=2735 piece=potential\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18880 all=54483 active=2735 piece=▁Caucasus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18900 all=54472 active=2724 piece=▁Mischung\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18920 all=54458 active=2710 piece=▁Trennung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18940 all=54449 active=2701 piece=▁angelegt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18960 all=54435 active=2687 piece=▁beschloß\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=18980 all=54422 active=2674 piece=▁definite\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19000 all=54403 active=2655 piece=▁entzieht\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19020 all=54386 active=2704 piece=▁gedenken\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19040 all=54374 active=2692 piece=▁honoured\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19060 all=54362 active=2680 piece=▁limiting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19080 all=54348 active=2666 piece=▁postpone\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19100 all=54328 active=2646 piece=▁sichtbar\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19120 all=54310 active=2699 piece=▁unakzept\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19140 all=54299 active=2688 piece=▁zulässig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19160 all=54297 active=2686 piece=restricted\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19180 all=54297 active=2686 piece=▁Beiträgen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19200 all=54282 active=2671 piece=▁Geometrie\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19220 all=54265 active=2698 piece=▁Positives\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19240 all=54248 active=2681 piece=▁Steuervor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19260 all=54234 active=2667 piece=▁angesehen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19280 all=54215 active=2648 piece=▁buildings\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19300 all=54203 active=2636 piece=▁ehemalige\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19320 all=54185 active=2693 piece=▁exclusive\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19340 all=54166 active=2674 piece=▁guideline\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19360 all=54147 active=2655 piece=▁katastrop\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19380 all=54128 active=2636 piece=▁president\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19400 all=54108 active=2616 piece=▁sceptical\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19420 all=54091 active=2689 piece=▁südlichen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19440 all=54076 active=2674 piece=▁vollendet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19460 all=54063 active=2661 piece=freundliche\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19480 all=54047 active=2645 piece=▁Behinderte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19500 all=54030 active=2628 piece=▁Konkurrenz\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19520 all=54010 active=2682 piece=▁Sichtweise\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19540 all=53992 active=2664 piece=▁accounting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19560 all=53973 active=2645 piece=▁begonnenen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19580 all=53954 active=2626 piece=▁concentric\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19600 all=53934 active=2606 piece=▁disturbing\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19620 all=53916 active=2679 piece=▁genommenen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19640 all=53898 active=2661 piece=▁ländlicher\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19660 all=53881 active=2644 piece=▁presidents\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19680 all=53864 active=2627 piece=▁spanischer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19700 all=53846 active=2609 piece=▁versichert\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19720 all=53829 active=2676 piece=verwaltungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19740 all=53812 active=2659 piece=▁Finanzielle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19760 all=53795 active=2642 piece=▁Rückwirkung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19780 all=53779 active=2626 piece=▁arbeitenden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19800 all=53760 active=2607 piece=▁concessions\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19820 all=53741 active=2669 piece=▁endeavoured\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19840 all=53721 active=2649 piece=▁hinnehmbare\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19860 all=53701 active=2629 piece=▁observatory\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19880 all=53682 active=2610 piece=▁schädlicher\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19900 all=53665 active=2593 piece=▁unterstellt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19920 all=53649 active=2668 piece=schlossenheit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19940 all=53632 active=2651 piece=▁Fortschritts\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19960 all=53614 active=2633 piece=▁Steuerfragen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=19980 all=53596 active=2615 piece=▁apparatchiks\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=20000 all=53579 active=2598 piece=▁eingegangene\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=20020 all=53562 active=2662 piece=▁perpetrators\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=20040 all=53542 active=2642 piece=▁unterrichtet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=20060 all=53522 active=2622 piece=ungsaustauschs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=20080 all=53504 active=2604 piece=▁Griechenlands\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=20100 all=53487 active=2587 piece=▁Transnational\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=20120 all=53468 active=2655 piece=▁certification\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=20140 all=53448 active=2635 piece=▁interpretiert\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=20160 all=53428 active=2615 piece=▁vorgebrachten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=20180 all=53408 active=2595 piece=▁Mitgliedschaft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=20200 all=53388 active=2575 piece=▁demonstrations\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=20220 all=53368 active=2650 piece=▁transportieren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=20240 all=53348 active=2630 piece=▁Fahrzeugbestand\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=20260 all=53328 active=2610 piece=▁dementsprechend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20280 all=53313 active=2595 piece=ec\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20300 all=53327 active=2609 piece=EPs\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20320 all=53336 active=2675 piece=ynn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20340 all=53343 active=2682 piece=5/95\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20360 all=53347 active=2686 piece=digt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20380 all=53361 active=2700 piece=ogel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20400 all=53377 active=2716 piece=ölle\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20420 all=53379 active=2669 piece=▁24.\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20440 all=53364 active=2654 piece=▁CFI\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20460 all=53353 active=2643 piece=▁VEU\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20480 all=53357 active=2647 piece=/60/9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20500 all=53360 active=2650 piece=afran\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20520 all=53371 active=2678 piece=arrel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20540 all=53381 active=2688 piece=ermis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20560 all=53395 active=2702 piece=latte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20580 all=53405 active=2712 piece=sense\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20600 all=53414 active=2721 piece=örung\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20620 all=53417 active=2673 piece=▁Aspe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20640 all=53412 active=2668 piece=▁Goll\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20660 all=53412 active=2668 piece=▁Rojo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20680 all=53404 active=2660 piece=▁boyc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20700 all=53404 active=2660 piece=▁inex\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20720 all=53414 active=2679 piece=▁nuts\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20740 all=53410 active=2675 piece=4-0018\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20760 all=53409 active=2674 piece=ackson\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20780 all=53419 active=2684 piece=elodie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20800 all=53432 active=2697 piece=iametr\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20820 all=53442 active=2679 piece=ilitar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20840 all=53455 active=2692 piece=loying\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20860 all=53470 active=2707 piece=roused\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20880 all=53479 active=2716 piece=würfen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20900 all=53473 active=2710 piece=▁Akten\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20920 all=53481 active=2681 piece=5-0007\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20940 all=53482 active=2682 piece=▁Chevè\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20960 all=53472 active=2672 piece=▁Hätte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=20980 all=53458 active=2658 piece=▁Nazis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21000 all=53446 active=2646 piece=▁Stoff\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21020 all=53448 active=2674 piece=▁soph\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21040 all=53449 active=2675 piece=▁Uzbek\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21060 all=53447 active=2673 piece=▁anzup\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21080 all=53440 active=2666 piece=▁disgu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21100 all=53434 active=2660 piece=▁grüne\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21120 all=53435 active=2673 piece=ahndet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21140 all=53434 active=2672 piece=▁loose\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21160 all=53426 active=2664 piece=▁quiet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21180 all=53423 active=2661 piece=▁terat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21200 all=53414 active=2652 piece=Suffolk\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21220 all=53416 active=2673 piece=▁earm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21240 all=53417 active=2674 piece=arantee\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21260 all=53428 active=2685 piece=etitive\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21280 all=53438 active=2695 piece=ilegien\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21300 all=53449 active=2706 piece=merkmal\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21320 all=53454 active=2675 piece=▁army\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21340 all=53454 active=2675 piece=▁versö\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21360 all=53459 active=2680 piece=reating\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21380 all=53467 active=2688 piece=trading\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21400 all=53478 active=2699 piece=ächtige\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21420 all=53485 active=2679 piece=▁Gale\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21440 all=53485 active=2679 piece=▁petty\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21460 all=53488 active=2682 piece=▁Ankara\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21480 all=53481 active=2675 piece=▁Ermord\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21500 all=53471 active=2665 piece=▁Kernen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21520 all=53475 active=2677 piece=istin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21540 all=53478 active=2680 piece=geschra\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21560 all=53475 active=2677 piece=▁Mexiko\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21580 all=53464 active=2666 piece=▁Postul\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21600 all=53459 active=2661 piece=▁Taking\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21620 all=53461 active=2675 piece=klären\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21640 all=53467 active=2681 piece=▁Tauern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21660 all=53457 active=2671 piece=▁apathy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21680 all=53445 active=2659 piece=▁devour\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21700 all=53432 active=2646 piece=▁forged\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21720 all=53441 active=2681 piece=▁Beleg\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21740 all=53440 active=2680 piece=▁Innere\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21760 all=53432 active=2672 piece=▁hurdle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21780 all=53426 active=2666 piece=▁lovers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21800 all=53416 active=2656 piece=▁reiche\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21820 all=53424 active=2679 piece=peist\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21840 all=53429 active=2684 piece=▁gutem\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21860 all=53426 active=2681 piece=▁reopen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21880 all=53414 active=2669 piece=▁sounds\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21900 all=53411 active=2666 piece=▁uneven\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21920 all=53419 active=2678 piece=▁exod\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21940 all=53422 active=2681 piece=züchter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21960 all=53412 active=2671 piece=▁vorzug\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=21980 all=53399 active=2658 piece=Struktur\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22000 all=53411 active=2670 piece=ceivable\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22020 all=53420 active=2679 piece=obles\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22040 all=53420 active=2679 piece=▁Lanka\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22060 all=53411 active=2670 piece=▁marker\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22080 all=53414 active=2673 piece=gehenden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22100 all=53421 active=2680 piece=liegende\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22120 all=53429 active=2678 piece=worth\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22140 all=53426 active=2675 piece=▁umtre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22160 all=53426 active=2675 piece=ragender\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22180 all=53432 active=2681 piece=ssystems\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22200 all=53435 active=2684 piece=widrigen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22220 all=53453 active=2688 piece=thaus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22240 all=53456 active=2691 piece=▁weilt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22260 all=53452 active=2687 piece=▁94/728/\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22280 all=53437 active=2672 piece=▁Brunnen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22300 all=53425 active=2660 piece=▁Finance\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22320 all=53434 active=2681 piece=▁seiz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22340 all=53438 active=2685 piece=tretens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22360 all=53428 active=2675 piece=▁Gefälle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22380 all=53414 active=2661 piece=▁Looking\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22400 all=53407 active=2654 piece=▁Protest\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22420 all=53419 active=2682 piece=▁nerv\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22440 all=53421 active=2684 piece=reifens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22460 all=53425 active=2688 piece=▁Journal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22480 all=53409 active=2672 piece=▁Studium\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22500 all=53400 active=2663 piece=▁Vorgabe\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22520 all=53410 active=2680 piece=eiting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22540 all=53412 active=2682 piece=Staudam\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22560 all=53412 active=2682 piece=stellers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22580 all=53397 active=2667 piece=▁aroused\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22600 all=53385 active=2655 piece=▁benannt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22620 all=53396 active=2681 piece=räder\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22640 all=53393 active=2678 piece=▁ärmer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22660 all=53385 active=2670 piece=beratung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22680 all=53371 active=2656 piece=▁catches\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22700 all=53352 active=2637 piece=▁devolve\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22720 all=53355 active=2671 piece=▁332,\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22740 all=53349 active=2665 piece=enommen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22760 all=53348 active=2664 piece=▁durchle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22780 all=53339 active=2655 piece=▁expires\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22800 all=53324 active=2640 piece=▁gekürzt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22820 all=53333 active=2676 piece=▁hege\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22840 all=53332 active=2675 piece=▁Inform\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22860 all=53325 active=2668 piece=▁gespart\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22880 all=53312 active=2655 piece=▁infiltr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22900 all=53301 active=2644 piece=▁liaison\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22920 all=53303 active=2668 piece=▁ital\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22940 all=53300 active=2665 piece=▁Attent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22960 all=53288 active=2653 piece=▁mancher\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=22980 all=53273 active=2638 piece=▁opacity\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23000 all=53261 active=2626 piece=▁ranging\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23020 all=53268 active=2671 piece=ourge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23040 all=53264 active=2667 piece=▁dankt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23060 all=53267 active=2670 piece=▁Compens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23080 all=53257 active=2660 piece=▁scourge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23100 all=53242 active=2645 piece=▁strikes\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23120 all=53248 active=2669 piece=eyhun\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23140 all=53251 active=2672 piece=flöcher\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23160 all=53244 active=2665 piece=▁suppose\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23180 all=53231 active=2652 piece=▁ungünst\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23200 all=53220 active=2641 piece=▁zuwenig\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23220 all=53217 active=2658 piece=▁disg\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23240 all=53217 active=2658 piece=▁rührt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23260 all=53211 active=2652 piece=▁wieviel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23280 all=53201 active=2642 piece=Staudamms\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23300 all=53208 active=2649 piece=eidenheit\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23320 all=53226 active=2678 piece=▁ally\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23340 all=53225 active=2677 piece=▁Sobald\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23360 all=53221 active=2673 piece=führenden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23380 all=53225 active=2677 piece=istellung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23400 all=53222 active=2674 piece=tegration\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23420 all=53234 active=2672 piece=▁Star\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23440 all=53229 active=2667 piece=▁karib\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23460 all=53222 active=2660 piece=venience\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23480 all=53222 active=2660 piece=verhütung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23500 all=53229 active=2667 piece=▁Alicante\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23520 all=53226 active=2659 piece=▁Spur\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23540 all=53228 active=2661 piece=▁Vandam\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23560 all=53212 active=2645 piece=▁Ambition\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23580 all=53197 active=2630 piece=▁Bosnians\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23600 all=53182 active=2615 piece=▁Embargos\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23620 all=53196 active=2674 piece=▁Dipl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23640 all=53188 active=2666 piece=▁Casaca\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23660 all=53176 active=2654 piece=▁Entgegen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23680 all=53162 active=2640 piece=▁Hunderte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23700 all=53146 active=2624 piece=▁Lorraine\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23720 all=53160 active=2672 piece=▁Ehr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23740 all=53165 active=2677 piece=▁hieße\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23760 all=53149 active=2661 piece=chanismus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23780 all=53134 active=2646 piece=▁PREUSSAG\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23800 all=53120 active=2632 piece=▁Seifenbl\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23820 all=53130 active=2665 piece=▁Haß\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23840 all=53132 active=2667 piece=▁Heran\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23860 all=53121 active=2656 piece=▁crystal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23880 all=53108 active=2643 piece=▁Unwetter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23900 all=53093 active=2628 piece=▁ablaufen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23920 all=53101 active=2663 piece=▁embe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23940 all=53095 active=2657 piece=▁élites\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23960 all=53081 active=2643 piece=▁allotted\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=23980 all=53065 active=2627 piece=▁aufweist\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24000 all=53045 active=2607 piece=▁besseres\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24020 all=53058 active=2666 piece=▁pas\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24040 all=53060 active=2668 piece=ifiques\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24060 all=53054 active=2662 piece=▁bestände\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24080 all=53035 active=2643 piece=▁comprise\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24100 all=53024 active=2632 piece=▁electing\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24120 all=53035 active=2663 piece=▁1917\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24140 all=53025 active=2653 piece=▁Halten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24160 all=53010 active=2638 piece=▁täglich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24180 all=52993 active=2621 piece=▁ereignet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24200 all=52976 active=2604 piece=▁falscher\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24220 all=52980 active=2653 piece=orten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24240 all=52995 active=2668 piece=▁beding\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24260 all=52984 active=2657 piece=▁festlegt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24280 all=52969 active=2642 piece=▁geradezu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24300 all=52952 active=2625 piece=▁headlong\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24320 all=52950 active=2646 piece=▁hearings\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24340 all=52937 active=2633 piece=▁invested\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24360 all=52922 active=2618 piece=▁mainland\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24380 all=52904 active=2600 piece=▁ordinary\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24400 all=52889 active=2585 piece=▁probable\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24420 all=52874 active=2630 piece=▁schwächt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24440 all=52858 active=2614 piece=▁stopping\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24460 all=52845 active=2601 piece=▁underpin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24480 all=52831 active=2587 piece=▁vertieft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24500 all=52816 active=2572 piece=▁Überdies\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24520 all=52798 active=2623 piece=-0808/99):\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24540 all=52789 active=2614 piece=demokraten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24560 all=52782 active=2607 piece=punktmäßig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24580 all=52780 active=2605 piece=▁Alexander\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24600 all=52764 active=2589 piece=▁Champagne\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24620 all=52746 active=2621 piece=▁Europarat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24640 all=52729 active=2604 piece=▁Höhepunkt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24660 all=52710 active=2585 piece=▁Lockerung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24680 all=52694 active=2569 piece=▁Political\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24700 all=52677 active=2552 piece=▁Steuerung\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24720 all=52659 active=2616 piece=▁abstained\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24740 all=52639 active=2596 piece=▁anzuhören\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24760 all=52621 active=2578 piece=▁balancing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24780 all=52601 active=2558 piece=▁conferred\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24800 all=52581 active=2538 piece=▁disposing\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24820 all=52569 active=2618 piece=▁entailing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24840 all=52551 active=2600 piece=▁ethnische\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24860 all=52533 active=2582 piece=▁gelungene\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24880 all=52513 active=2562 piece=▁hurricane\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24900 all=52495 active=2544 piece=▁jahrelang\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24920 all=52479 active=2609 piece=▁mißbräuch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24940 all=52465 active=2595 piece=▁polluters\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24960 all=52448 active=2578 piece=▁reinstate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=24980 all=52433 active=2563 piece=▁shoulders\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25000 all=52413 active=2543 piece=▁technisch\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25020 all=52395 active=2603 piece=▁unterhalb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25040 all=52379 active=2587 piece=▁verziehen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25060 all=52368 active=2576 piece=▁Übersicht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25080 all=52349 active=2557 piece=bahnunglück\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25100 all=52341 active=2549 piece=rukturellen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25120 all=52327 active=2604 piece=▁1999/2124(\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25140 all=52308 active=2585 piece=▁Auswertung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25160 all=52290 active=2567 piece=▁Durchbruch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25180 all=52273 active=2550 piece=▁Industriel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25200 all=52255 active=2532 piece=▁Minireform\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25220 all=52236 active=2594 piece=▁Scheideweg\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25240 all=52218 active=2576 piece=▁Ultimately\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25260 all=52204 active=2562 piece=▁abgelaufen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25280 all=52185 active=2543 piece=▁angedrohte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25300 all=52165 active=2523 piece=▁ausgedehnt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25320 all=52145 active=2589 piece=▁beschämend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25340 all=52126 active=2570 piece=▁controlled\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25360 all=52107 active=2551 piece=▁eingehende\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25380 all=52088 active=2532 piece=▁extinguish\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25400 all=52069 active=2513 piece=▁gewünschte\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25420 all=52051 active=2586 piece=▁ingredient\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25440 all=52031 active=2566 piece=▁natürliche\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25460 all=52011 active=2546 piece=▁profession\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25480 all=51992 active=2527 piece=▁schlüssige\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25500 all=51974 active=2509 piece=▁tightening\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25520 all=51957 active=2582 piece=▁vergleicht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25540 all=51940 active=2565 piece=▁wichtigere\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25560 all=51922 active=2547 piece=5-0004/2000)\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25580 all=51904 active=2529 piece=gebeschlüsse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25600 all=51890 active=2515 piece=vereinbarung\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25620 all=51871 active=2576 piece=▁Chamberlain\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25640 all=51851 active=2556 piece=▁Hauptstädte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25660 all=51833 active=2538 piece=▁Lebensdauer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25680 all=51813 active=2518 piece=▁Resolutions\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25700 all=51793 active=2498 piece=▁Unterscheid\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25720 all=51780 active=2575 piece=▁Zuwanderung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25740 all=51762 active=2557 piece=▁aufenthalts\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25760 all=51742 active=2537 piece=▁challenging\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25780 all=51723 active=2518 piece=▁degradieren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25800 all=51703 active=2498 piece=▁eingenommen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25820 all=51684 active=2566 piece=▁erschließen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25840 all=51664 active=2546 piece=▁geschätzten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25860 all=51646 active=2528 piece=▁irgendeinen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25880 all=51626 active=2508 piece=▁mehrjährige\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25900 all=51607 active=2489 piece=▁parteipolit\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25920 all=51587 active=2561 piece=▁reconciling\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25940 all=51568 active=2542 piece=▁structuring\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25960 all=51550 active=2524 piece=▁unzulässige\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=25980 all=51531 active=2505 piece=▁wherewithal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26000 all=51513 active=2487 piece=geschlossenen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26020 all=51493 active=2556 piece=▁Befriedigung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26040 all=51475 active=2538 piece=▁Drogenhandel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26060 all=51457 active=2520 piece=▁Hauptaufgabe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26080 all=51437 active=2500 piece=▁Redebeiträge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26100 all=51418 active=2481 piece=▁Ungleichheit\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26120 all=51398 active=2551 piece=▁angeprangert\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26140 all=51378 active=2531 piece=▁begünstigten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26160 all=51359 active=2512 piece=▁dissatisfied\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26180 all=51339 active=2492 piece=▁gigantischer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26200 all=51319 active=2472 piece=▁indifference\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26220 all=51300 active=2547 piece=▁medizinische\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26240 all=51280 active=2527 piece=▁präsentieren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26260 all=51260 active=2507 piece=▁statistische\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26280 all=51242 active=2489 piece=▁unreasonable\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26300 all=51222 active=2469 piece=▁vorzubringen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26320 all=51202 active=2542 piece=constitutional\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26340 all=51182 active=2522 piece=▁Energieformen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26360 all=51162 active=2502 piece=▁Gewinnspannen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26380 all=51142 active=2482 piece=▁Meinungsunter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26400 all=51122 active=2462 piece=▁Umweltschäden\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26420 all=51103 active=2538 piece=▁anzuschließen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26440 all=51083 active=2518 piece=▁disappointing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26460 all=51063 active=2498 piece=▁hinausgehende\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26480 all=51044 active=2479 piece=▁nachgeordnete\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26500 all=51024 active=2459 piece=▁sophisticated\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26520 all=51005 active=2533 piece=▁unterbrochene\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26540 all=50986 active=2514 piece=▁zuwiderlaufen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26560 all=50966 active=2494 piece=▁Diamantopoulou\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26580 all=50946 active=2474 piece=▁Kernprinzipien\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26600 all=50926 active=2454 piece=▁Rechtsextremen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26620 all=50906 active=2527 piece=▁Unterstützungs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26640 all=50886 active=2507 piece=▁beträchtliches\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26660 all=50866 active=2487 piece=▁humanistischen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26680 all=50846 active=2467 piece=▁redistributing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26700 all=50826 active=2447 piece=▁untergeordnete\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26720 all=50806 active=2522 piece=ungskriminalität\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26740 all=50786 active=2502 piece=▁Großbritanniens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26760 all=50766 active=2482 piece=▁Rechtsordnungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26780 all=50746 active=2462 piece=▁Umweltsanierung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26800 all=50726 active=2442 piece=▁fertigzustellen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=26820 all=50706 active=2517 piece=▁überwältigenden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=26840 all=50706 active=2517 piece=öteb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=26860 all=50699 active=2510 piece=analp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=26880 all=50704 active=2515 piece=oiren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=26900 all=50693 active=2504 piece=▁Chef\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=26920 all=50680 active=2522 piece=259/99\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=26940 all=50680 active=2522 piece=gneten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=26960 all=50681 active=2523 piece=sfremd\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=26980 all=50677 active=2519 piece=▁1923.\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27000 all=50661 active=2503 piece=▁Fauna\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27020 all=50654 active=2527 piece=▁Macao\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27040 all=50639 active=2512 piece=▁blown\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27060 all=50625 active=2498 piece=▁inexp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27080 all=50616 active=2489 piece=10.1999\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27100 all=50610 active=2483 piece=emakers\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27120 all=50601 active=2521 piece=▁fußen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27140 all=50599 active=2519 piece=iebiger\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27160 all=50601 active=2521 piece=ropping\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27180 all=50599 active=2519 piece=wellers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27200 all=50591 active=2511 piece=▁ECOFIN\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27220 all=50585 active=2524 piece=▁Invol\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27240 all=50581 active=2520 piece=▁Fläche\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27260 all=50568 active=2507 piece=▁Promot\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27280 all=50561 active=2500 piece=▁anpaßt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27300 all=50549 active=2488 piece=▁deskri\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27320 all=50547 active=2525 piece=▁1.27\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27340 all=50538 active=2516 piece=43/1999\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27360 all=50530 active=2508 piece=▁flirts\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27380 all=50517 active=2495 piece=▁lethal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27400 all=50505 active=2483 piece=▁outmod\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27420 all=50495 active=2515 piece=▁squash\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27440 all=50479 active=2499 piece=-0041/99\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27460 all=50472 active=2492 piece=beigesch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27480 all=50471 active=2491 piece=gremiums\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27500 all=50470 active=2490 piece=oclastic\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27520 all=50467 active=2520 piece=uarantee\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27540 all=50470 active=2523 piece=▁400,000\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27560 all=50453 active=2506 piece=▁Ehrlich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27580 all=50438 active=2491 piece=▁Kostend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27600 all=50423 active=2476 piece=▁Raument\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27620 all=50417 active=2515 piece=▁Rinderw\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27640 all=50409 active=2507 piece=▁Verleug\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27660 all=50397 active=2495 piece=▁beeilen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27680 all=50382 active=2480 piece=▁deletes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27700 all=50365 active=2463 piece=▁gepreßt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27720 all=50358 active=2512 piece=▁Flecht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27740 all=50347 active=2501 piece=▁Rentens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27760 all=50334 active=2488 piece=▁konzert\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27780 all=50321 active=2475 piece=▁prävent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27800 all=50304 active=2458 piece=▁shifted\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27820 all=50294 active=2506 piece=uttala\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27840 all=50286 active=2498 piece=▁sauber\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27860 all=50272 active=2484 piece=▁sponsor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27880 all=50255 active=2467 piece=▁vacuums\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27900 all=50237 active=2449 piece=▁ärmerer\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27920 all=50240 active=2515 piece=rowded\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27940 all=50232 active=2507 piece=5-0259/99\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27960 all=50225 active=2500 piece=confusing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=27980 all=50224 active=2499 piece=hvermögen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28000 all=50225 active=2500 piece=offenheit\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28020 all=50224 active=2510 piece=schafters\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28040 all=50213 active=2499 piece=▁Bombenan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28060 all=50198 active=2484 piece=▁Fusionsw\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28080 all=50184 active=2470 piece=▁Militärb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28100 all=50166 active=2452 piece=▁Rotstift\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28120 all=50154 active=2497 piece=perdstown\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28140 all=50140 active=2483 piece=▁Todesurs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28160 all=50125 active=2468 piece=▁anschloß\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28180 all=50105 active=2448 piece=▁betrüben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28200 all=50088 active=2431 piece=▁direktem\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28220 all=50079 active=2496 piece=assioned\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28240 all=50069 active=2486 piece=fachleute\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28260 all=50055 active=2472 piece=▁embodied\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28280 all=50035 active=2452 piece=▁festeren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28300 all=50017 active=2434 piece=▁gesagten\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28320 all=50013 active=2497 piece=ibanon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28340 all=50013 active=2497 piece=zeihung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28360 all=50005 active=2489 piece=▁erhöhte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28380 all=49993 active=2477 piece=▁disquiet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28400 all=49979 active=2463 piece=▁inasmuch\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28420 all=49973 active=2493 piece=höfliche\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28440 all=49959 active=2479 piece=▁letztmal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28460 all=49944 active=2464 piece=▁nervösen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28480 all=49927 active=2447 piece=▁pondered\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28500 all=49909 active=2429 piece=▁ruiniert\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28520 all=49896 active=2483 piece=dications\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28540 all=49882 active=2469 piece=▁seminars\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28560 all=49864 active=2451 piece=▁tauschen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28580 all=49850 active=2437 piece=▁vermuten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28600 all=49831 active=2418 piece=Scoreboard\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28620 all=49824 active=2485 piece=endrunde\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28640 all=49814 active=2475 piece=▁Abfassen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28660 all=49810 active=2471 piece=bewußteren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28680 all=49802 active=2463 piece=gewöhnlich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28700 all=49792 active=2453 piece=onoclastic\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28720 all=49788 active=2485 piece=alistin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28740 all=49783 active=2480 piece=eitsgrad\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28760 all=49770 active=2467 piece=comprehens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28780 all=49770 active=2467 piece=upportable\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28800 all=49759 active=2456 piece=▁Auswüchse\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28820 all=49758 active=2487 piece=▁Dagmar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28840 all=49746 active=2475 piece=▁Bausteine\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28860 all=49731 active=2460 piece=▁Emotionen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28880 all=49714 active=2443 piece=▁Gründungs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28900 all=49697 active=2426 piece=▁Kontrover\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28920 all=49685 active=2472 piece=▁Letzteres\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28940 all=49667 active=2454 piece=▁Quästorin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28960 all=49649 active=2436 piece=▁Tragödien\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=28980 all=49632 active=2419 piece=▁ablehnend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29000 all=49612 active=2399 piece=▁attaining\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29020 all=49602 active=2471 piece=derbring\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29040 all=49596 active=2465 piece=ministern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29060 all=49581 active=2450 piece=▁Billionen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29080 all=49564 active=2433 piece=▁beschämen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29100 all=49546 active=2415 piece=▁conjuring\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29120 all=49548 active=2480 piece=▁fatig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29140 all=49540 active=2472 piece=▁küstenn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29160 all=49530 active=2462 piece=▁cynegetic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29180 all=49511 active=2443 piece=▁downright\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29200 all=49491 active=2423 piece=▁embracing\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29220 all=49484 active=2468 piece=dokumente\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29240 all=49477 active=2461 piece=▁advocated\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29260 all=49457 active=2441 piece=▁floodtide\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29280 all=49439 active=2423 piece=▁getrieben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29300 all=49420 active=2404 piece=▁kleineres\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29320 all=49406 active=2457 piece=▁Kleine\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29340 all=49395 active=2446 piece=▁abläuft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29360 all=49380 active=2431 piece=▁sinister\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29380 all=49361 active=2412 piece=▁licensing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29400 all=49344 active=2395 piece=▁nuklearer\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29420 all=49338 active=2462 piece=▁Latin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29440 all=49327 active=2451 piece=▁Wahltag\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29460 all=49314 active=2438 piece=▁beratende\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29480 all=49294 active=2418 piece=▁prevailed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29500 all=49276 active=2400 piece=▁schlüssig\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29520 all=49262 active=2450 piece=▁altering\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29540 all=49249 active=2437 piece=▁schuldige\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29560 all=49230 active=2418 piece=▁subsidiär\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29580 all=49214 active=2402 piece=▁unlautere\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29600 all=49198 active=2386 piece=▁vertraten\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29620 all=49193 active=2455 piece=zögert\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29640 all=49182 active=2444 piece=iertheit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29660 all=49169 active=2431 piece=▁Londoner\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29680 all=49154 active=2416 piece=▁verwüstet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29700 all=49139 active=2401 piece=▁überholen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29720 all=49130 active=2448 piece=▁gegriffen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29740 all=49113 active=2431 piece=Fördergebie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29760 all=49108 active=2426 piece=bestreitbar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29780 all=49100 active=2418 piece=ifikationen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29800 all=49092 active=2410 piece=osovarische\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29820 all=49084 active=2446 piece=▁Endlich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29840 all=49068 active=2430 piece=▁unabsetz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29860 all=49050 active=2412 piece=raproduktiv\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29880 all=49042 active=2404 piece=ungsmonopol\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29900 all=49033 active=2395 piece=▁Absolutely\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29920 all=49033 active=2452 piece=uniary\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29940 all=49023 active=2442 piece=verluste\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29960 all=49009 active=2428 piece=▁sticking\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=29980 all=48992 active=2411 piece=▁Asienkrise\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30000 all=48973 active=2392 piece=▁Billigflag\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30020 all=48964 active=2439 piece=▁notes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30040 all=48958 active=2433 piece=▁anhängt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30060 all=48945 active=2420 piece=▁revolved\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30080 all=48932 active=2407 piece=▁Calvinists\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30100 all=48914 active=2389 piece=▁Erfassungs\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30120 all=48911 active=2443 piece=lassungs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30140 all=48900 active=2432 piece=▁mehrerer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30160 all=48887 active=2419 piece=▁Baugruppen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30180 all=48871 active=2403 piece=▁Gefährlich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30200 all=48855 active=2387 piece=▁Kernfaktor\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30220 all=48853 active=2441 piece=content\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30240 all=48848 active=2436 piece=▁harness\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30260 all=48833 active=2421 piece=▁harangued\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30280 all=48815 active=2403 piece=▁Leidtragen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30300 all=48800 active=2388 piece=▁Optimismus\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30320 all=48796 active=2436 piece=hension\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30340 all=48789 active=2429 piece=▁Großkonz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30360 all=48775 active=2415 piece=▁hinwegzuf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30380 all=48757 active=2397 piece=▁Reedereien\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30400 all=48740 active=2380 piece=▁Selbstmord\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30420 all=48738 active=2435 piece=▁hired\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30440 all=48726 active=2423 piece=rosionsan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30460 all=48716 active=2413 piece=▁Madagascar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30480 all=48699 active=2396 piece=▁Todesopfer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30500 all=48681 active=2378 piece=▁Vorgängern\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30520 all=48678 active=2432 piece=▁bigot\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30540 all=48674 active=2428 piece=▁Holzweg\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30560 all=48660 active=2414 piece=▁Statuten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30580 all=48645 active=2399 piece=verwertungs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30600 all=48627 active=2381 piece=▁abzusenken\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30620 all=48626 active=2431 piece=▁expuls\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30640 all=48616 active=2421 piece=▁vermengt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30660 all=48598 active=2403 piece=▁Besonderer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30680 all=48578 active=2383 piece=▁aufgewühlt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30700 all=48558 active=2363 piece=▁beeinflußt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30720 all=48553 active=2423 piece=viates\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30740 all=48544 active=2414 piece=ectivity\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30760 all=48534 active=2404 piece=▁fatalist\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30780 all=48520 active=2390 piece=▁Startpunkt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30800 all=48501 active=2371 piece=▁bridgehead\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30820 all=48498 active=2422 piece=▁Jassir\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30840 all=48487 active=2411 piece=geladenen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30860 all=48472 active=2396 piece=▁demonstra\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30880 all=48457 active=2381 piece=▁championed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30900 all=48438 active=2362 piece=▁discovered\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30920 all=48436 active=2420 piece=▁shudder\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30940 all=48425 active=2409 piece=▁ermöglich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30960 all=48410 active=2394 piece=▁eingereist\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=30980 all=48390 active=2374 piece=▁erschreckt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31000 all=48371 active=2355 piece=▁fossilised\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31020 all=48365 active=2413 piece=uplicit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31040 all=48357 active=2405 piece=▁rejoice\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31060 all=48343 active=2391 piece=▁expeditiv\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31080 all=48326 active=2374 piece=▁geachteten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31100 all=48306 active=2354 piece=▁healthcare\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31120 all=48299 active=2409 piece=Trojan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31140 all=48289 active=2399 piece=▁cheque\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31160 all=48282 active=2392 piece=▁Klartext\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31180 all=48270 active=2380 piece=ungswirkung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31200 all=48252 active=2362 piece=▁indistinct\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31220 all=48243 active=2404 piece=▁sahen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31240 all=48235 active=2396 piece=unktuelle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31260 all=48219 active=2380 piece=hinnehmbare\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31280 all=48201 active=2362 piece=▁katholisch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31300 all=48182 active=2343 piece=▁minimising\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31320 all=48181 active=2409 piece=▁53⁄4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31340 all=48175 active=2403 piece=ukrativ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31360 all=48170 active=2398 piece=▁prozess\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31380 all=48155 active=2383 piece=▁Kernpunkt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31400 all=48137 active=2365 piece=▁multiplied\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31420 all=48132 active=2402 piece=▁luxury\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31440 all=48121 active=2391 piece=linquished\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31460 all=48103 active=2373 piece=▁nochmalige\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31480 all=48083 active=2353 piece=▁powerhouse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31500 all=48064 active=2334 piece=▁registered\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31520 all=48053 active=2393 piece=▁grâce\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31540 all=48044 active=2384 piece=lementen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31560 all=48036 active=2376 piece=▁entschäd\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31580 all=48021 active=2361 piece=▁afternoons\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31600 all=48002 active=2342 piece=▁schlimmste\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31620 all=48001 active=2400 piece=tragsb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31640 all=47995 active=2394 piece=▁inquis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31660 all=47980 active=2379 piece=▁bindende\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31680 all=47965 active=2364 piece=▁repression\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31700 all=47945 active=2344 piece=▁suspicions\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31720 all=47939 active=2392 piece=▁Höher\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31740 all=47931 active=2384 piece=▁Aromast\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31760 all=47920 active=2373 piece=▁Verschlag\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31780 all=47903 active=2356 piece=▁symbolisch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31800 all=47885 active=2338 piece=▁underscore\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31820 all=47880 active=2390 piece=strösen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31840 all=47866 active=2376 piece=▁missions\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31860 all=47852 active=2362 piece=▁Anwesenden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=31880 all=47833 active=2343 piece=▁universell\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: translation_tokenizer.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: translation_tokenizer.vocab\n",
      "Tokenizer training complete!\n",
      "Loading tokenizer...\n",
      "\n",
      "Tokenizer Info:\n",
      "Vocabulary size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "\n",
      "Creating dataloaders...\n",
      "\n",
      "Training set sample:\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Input (DE): [DE] Veränderungen sollten nicht zu schnell eingeführt werden oder zu radikal sein, weil sonst die öffentliche Meinung eine Ratifizierung künftiger EU-Verträge erheblich erschweren könnte.\n",
      "Target (EN): [EN] Changes should not be brought about too quickly and cannot be too sweeping, otherwise public opinion will make ratification of any future European Union treaty very difficult indeed.\n",
      "\n",
      "Validation set sample:\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size:Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Input (DE): [DE] Wenn Sie den Text aufmerksam lesen, so können Sie erkennen, daß dieser Vorschlag für eine Kapitalsteuer ein ganz normales Instrument darstellt, mit dem versucht werden soll, die internationalen Anleger zu einem verantwortlichen Handeln auf den Finanzmärkten zu verpflichten.\n",
      "Target (EN): [EN] If you look carefully, this proposed tax on capital is just one of several instruments aimed at forcing international investors to behave responsibly on the financial markets.\n",
      "\n",
      "Test set sample:\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [EN] ID: 5\n",
      "\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Input (DE): [DE] Auch vor dem Hintergrund dieser Maßnahmenliste, die im übrigen nicht einmal vollständig ist, kann ich hier und heute vor der Ratspräsidentschaft und den Abgeordneten erneut und mit großer Überzeugung versichern: Wenn 1999 das Jahr der Konsolidierung des Wirkens der Union in diesem maßgeblichen Bereich war, so hoffe ich, daß 1999 auch der Aufbruch in eine neuen Phase war, deren Ziel die Beschleunigung der Schaffung eines Raums der Freiheit, der Sicherheit und des Rechts ist.\n",
      "Target (EN): [EN] This list of actions, which is not exhaustive, should, here today, in the presence of the Council Presidency and of the Members of this House, help to make it clear that, while 1999 was a year of consolidation for EU action in this key area, it also - I very much hope - represented the start of a new phase, marked by the desire to speed up the establishment of an area of freedom, security and justice.\n",
      "\n",
      "Epoch 1/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "/opt/anaconda3/envs/de-en-translator/lib/python3.9/site-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 1/250 [00:09<39:23,  9.49s/it, loss=10.6207, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:14<27:25,  6.64s/it, loss=10.2647, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:16<18:44,  4.55s/it, loss=10.0091, tokens/sMax input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:22<21:40,  5.29s/it, loss=9.8367, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:24<16:51,  4.13s/it, loss=9.6960, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:29<17:05,  4.20s/it, loss=9.5892, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:31<14:09,  3.50s/it, loss=9.5023, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:33<13:10,  3.27s/it, loss=9.4270, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:38<15:09,  3.78s/it, loss=9.3528, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:40<12:56,  3.24s/it, loss=9.2751, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:44<13:46,  3.46s/it, loss=9.2032, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:48<14:06,  3.56s/it, loss=9.1468, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:50<12:41,  3.21s/it, loss=9.0872, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:52<10:58,  2.79s/it, loss=9.0299, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [00:54<09:32,  2.44s/it, loss=8.9733, tokens/sMax input_id: 31969\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [00:56<08:40,  2.23s/it, loss=8.9193, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [00:58<09:06,  2.35s/it, loss=8.8813, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:02<10:19,  2.67s/it, loss=8.8313, tokens/sMax input_id: 31977\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:06<12:38,  3.29s/it, loss=8.7868, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:13<16:14,  4.24s/it, loss=8.7441, tokens/sMax input_id: 31978\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:15<13:56,  3.65s/it, loss=8.6989, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:18<13:23,  3.52s/it, loss=8.6639, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:21<11:47,  3.12s/it, loss=8.6198, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:23<11:11,  2.97s/it, loss=8.5841, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:28<13:06,  3.49s/it, loss=8.5460, tokens/sMax input_id: 31978\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:35<17:22,  4.65s/it, loss=8.5108, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:38<14:53,  4.01s/it, loss=8.4705, tokens/sMax input_id: 31970\n",
      "Max target_input: 31988\n",
      "Max label: 31988\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [01:44<17:03,  4.61s/it, loss=8.4367, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [01:47<15:31,  4.21s/it, loss=8.4017, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [01:50<14:16,  3.89s/it, loss=8.3634, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [01:54<14:12,  3.89s/it, loss=8.3304, tokens/sMax input_id: 31958\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [02:01<17:53,  4.92s/it, loss=8.2909, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [02:04<15:34,  4.30s/it, loss=8.2578, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:07<13:39,  3.79s/it, loss=8.2232, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:10<12:59,  3.62s/it, loss=8.1934, tokens/sMax input_id: 31957\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:13<11:41,  3.28s/it, loss=8.1597, tokens/sMax input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:15<11:15,  3.17s/it, loss=8.1261, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:18<10:16,  2.91s/it, loss=8.0908, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:22<11:33,  3.29s/it, loss=8.0554, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:25<10:57,  3.13s/it, loss=8.0256, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:27<10:24,  2.99s/it, loss=7.9943, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:32<12:24,  3.58s/it, loss=7.9604, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:37<13:49,  4.01s/it, loss=7.9336, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:40<11:56,  3.48s/it, loss=7.9020, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [02:43<11:21,  3.32s/it, loss=7.8748, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [02:45<10:16,  3.02s/it, loss=7.8483, tokens/sMax input_id: 31963\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [02:47<09:50,  2.91s/it, loss=7.8202, tokens/sMax input_id: 31969\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [02:53<12:44,  3.79s/it, loss=7.7887, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [02:56<11:47,  3.52s/it, loss=7.7602, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [03:00<11:52,  3.56s/it, loss=7.7364, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [03:06<14:12,  4.29s/it, loss=7.7117, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:08<12:19,  3.73s/it, loss=7.6843, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:11<11:28,  3.49s/it, loss=7.6581, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:18<14:33,  4.46s/it, loss=7.6346, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:22<14:10,  4.36s/it, loss=7.6127, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:26<14:00,  4.33s/it, loss=7.5887, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:29<11:51,  3.68s/it, loss=7.5622, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:33<12:56,  4.04s/it, loss=7.5398, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:36<11:01,  3.46s/it, loss=7.5175, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [03:40<11:53,  3.75s/it, loss=7.4944, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [03:43<11:23,  3.61s/it, loss=7.4712, tokens/sMax input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [03:46<10:18,  3.29s/it, loss=7.4486, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [03:48<09:15,  2.97s/it, loss=7.4248, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [03:54<11:41,  3.77s/it, loss=7.4030, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [03:56<10:36,  3.44s/it, loss=7.3810, tokens/sMax input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [04:01<11:38,  3.80s/it, loss=7.3599, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [04:04<10:49,  3.55s/it, loss=7.3385, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [04:07<10:00,  3.30s/it, loss=7.3192, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [04:10<09:56,  3.29s/it, loss=7.2996, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [04:12<08:56,  2.98s/it, loss=7.2808, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:16<09:44,  3.27s/it, loss=7.2608, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:18<08:46,  2.96s/it, loss=7.2417, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:20<07:48,  2.65s/it, loss=7.2220, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:22<07:09,  2.44s/it, loss=7.2051, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [04:24<06:41,  2.29s/it, loss=7.1868, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [04:27<07:21,  2.54s/it, loss=7.1701, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [04:30<07:16,  2.53s/it, loss=7.1546, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [04:34<08:40,  3.02s/it, loss=7.1388, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [04:36<08:11,  2.87s/it, loss=7.1238, tokens/sMax input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [04:39<07:55,  2.80s/it, loss=7.1092, tokens/sMax input_id: 31959\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [04:42<08:02,  2.85s/it, loss=7.0943, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [04:47<09:33,  3.41s/it, loss=7.0788, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [04:51<10:03,  3.61s/it, loss=7.0633, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [04:55<10:04,  3.64s/it, loss=7.0481, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [04:57<09:14,  3.36s/it, loss=7.0326, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [05:00<08:22,  3.07s/it, loss=7.0152, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [05:01<07:18,  2.69s/it, loss=7.0007, tokens/sMax input_id: 31969\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [05:04<06:59,  2.59s/it, loss=6.9867, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [05:11<10:32,  3.93s/it, loss=6.9746, tokens/sMax input_id: 31958\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [05:13<08:47,  3.30s/it, loss=6.9603, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [05:16<08:28,  3.20s/it, loss=6.9470, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [05:18<08:04,  3.07s/it, loss=6.9341, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [05:22<08:04,  3.08s/it, loss=6.9231, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [05:24<07:32,  2.90s/it, loss=6.9086, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [05:27<07:22,  2.85s/it, loss=6.8980, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [05:29<06:37,  2.58s/it, loss=6.8833, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [05:31<06:25,  2.52s/it, loss=6.8702, tokens/sMax input_id: 31968\n",
      "Max target_input: 31967\n",
      "Max label: 31967\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [05:36<07:56,  3.13s/it, loss=6.8610, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [05:38<07:16,  2.89s/it, loss=6.8457, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [05:45<10:37,  4.25s/it, loss=6.8363, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [05:47<08:49,  3.55s/it, loss=6.8242, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [05:50<07:52,  3.19s/it, loss=6.8118, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [05:52<07:26,  3.04s/it, loss=6.8001, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [05:55<07:09,  2.94s/it, loss=6.7906, tokens/Max input_id: 31938\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [05:57<06:31,  2.70s/it, loss=6.7803, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [06:01<07:01,  2.93s/it, loss=6.7692, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [06:03<06:51,  2.88s/it, loss=6.7592, tokens/Max input_id: 31963\n",
      "Max target_input: 31998\n",
      "Max label: 31998\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [06:07<07:11,  3.04s/it, loss=6.7487, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [06:09<06:39,  2.84s/it, loss=6.7403, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [06:15<08:21,  3.58s/it, loss=6.7295, tokens/Max input_id: 31970\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [06:17<07:41,  3.32s/it, loss=6.7206, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [06:20<07:01,  3.06s/it, loss=6.7100, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [06:27<09:38,  4.22s/it, loss=6.7008, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [06:29<08:16,  3.65s/it, loss=6.6913, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [06:31<07:06,  3.16s/it, loss=6.6813, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [06:35<07:21,  3.29s/it, loss=6.6723, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [06:41<09:18,  4.20s/it, loss=6.6643, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [06:48<11:09,  5.07s/it, loss=6.6557, tokens/Max input_id: 31959\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [06:52<10:17,  4.71s/it, loss=6.6474, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [06:54<08:18,  3.84s/it, loss=6.6387, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [06:56<07:25,  3.45s/it, loss=6.6308, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [06:59<07:03,  3.31s/it, loss=6.6242, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [07:03<07:03,  3.33s/it, loss=6.6155, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [07:04<06:02,  2.88s/it, loss=6.6054, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [07:07<05:59,  2.87s/it, loss=6.5965, tokens/Max input_id: 31958\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [07:10<05:50,  2.83s/it, loss=6.5886, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [07:12<05:08,  2.50s/it, loss=6.5793, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [07:15<05:16,  2.60s/it, loss=6.5706, tokens/Max input_id: 31970\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [07:17<04:54,  2.43s/it, loss=6.5625, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [07:19<04:45,  2.38s/it, loss=6.5547, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [07:22<04:55,  2.48s/it, loss=6.5490, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [07:23<04:33,  2.32s/it, loss=6.5407, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [07:26<04:52,  2.50s/it, loss=6.5331, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [07:32<06:48,  3.52s/it, loss=6.5247, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [07:36<07:05,  3.70s/it, loss=6.5167, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [07:39<06:17,  3.31s/it, loss=6.5098, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [07:41<05:30,  2.92s/it, loss=6.5015, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [07:43<05:11,  2.79s/it, loss=6.4937, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [07:45<04:43,  2.56s/it, loss=6.4868, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [07:47<04:26,  2.42s/it, loss=6.4807, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [07:51<04:58,  2.74s/it, loss=6.4731, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [07:53<04:29,  2.49s/it, loss=6.4668, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [07:56<04:51,  2.73s/it, loss=6.4595, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [07:59<04:45,  2.70s/it, loss=6.4513, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [08:05<06:35,  3.77s/it, loss=6.4457, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [08:09<06:46,  3.91s/it, loss=6.4396, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [08:11<05:46,  3.37s/it, loss=6.4320, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [08:14<05:15,  3.09s/it, loss=6.4272, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [08:18<05:41,  3.38s/it, loss=6.4211, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [08:23<06:40,  4.00s/it, loss=6.4150, tokens/Max input_id: 31977\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [08:26<06:05,  3.70s/it, loss=6.4101, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [08:31<06:37,  4.05s/it, loss=6.4040, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [08:33<05:41,  3.52s/it, loss=6.3979, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [08:38<06:21,  3.97s/it, loss=6.3913, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [08:40<05:18,  3.35s/it, loss=6.3852, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [08:44<05:19,  3.40s/it, loss=6.3803, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [08:48<05:27,  3.52s/it, loss=6.3752, tokens/Max input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [08:52<05:33,  3.62s/it, loss=6.3722, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [08:56<05:45,  3.80s/it, loss=6.3663, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [08:59<05:29,  3.66s/it, loss=6.3609, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [09:05<06:21,  4.28s/it, loss=6.3554, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [09:08<05:47,  3.95s/it, loss=6.3510, tokens/Max input_id: 31963\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [09:10<04:48,  3.31s/it, loss=6.3447, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [09:12<04:16,  2.98s/it, loss=6.3389, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [09:17<04:51,  3.43s/it, loss=6.3338, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [09:21<05:23,  3.85s/it, loss=6.3293, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [09:26<05:42,  4.12s/it, loss=6.3228, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [09:31<05:55,  4.34s/it, loss=6.3184, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [09:33<04:47,  3.55s/it, loss=6.3124, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [09:37<04:56,  3.71s/it, loss=6.3073, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [09:44<06:22,  4.84s/it, loss=6.3005, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [09:46<05:08,  3.96s/it, loss=6.2953, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [09:49<04:39,  3.63s/it, loss=6.2920, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [09:51<04:01,  3.17s/it, loss=6.2871, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [09:53<03:29,  2.79s/it, loss=6.2824, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [09:56<03:26,  2.79s/it, loss=6.2772, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [09:58<03:14,  2.67s/it, loss=6.2731, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [10:00<02:59,  2.50s/it, loss=6.2679, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [10:03<02:57,  2.49s/it, loss=6.2638, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [10:06<03:11,  2.73s/it, loss=6.2593, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [10:08<02:52,  2.50s/it, loss=6.2536, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [10:15<04:17,  3.79s/it, loss=6.2480, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [10:17<03:44,  3.35s/it, loss=6.2432, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [10:19<03:17,  3.00s/it, loss=6.2383, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [10:21<02:55,  2.69s/it, loss=6.2342, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [10:24<02:54,  2.73s/it, loss=6.2291, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [10:26<02:31,  2.41s/it, loss=6.2246, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [10:28<02:28,  2.40s/it, loss=6.2192, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [10:31<02:32,  2.49s/it, loss=6.2143, tokens/Max input_id: 31964\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [10:37<03:43,  3.72s/it, loss=6.2101, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [10:40<03:24,  3.46s/it, loss=6.2065, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [10:44<03:18,  3.42s/it, loss=6.2013, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [10:46<02:59,  3.14s/it, loss=6.1976, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [10:49<02:53,  3.09s/it, loss=6.1931, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [10:51<02:37,  2.86s/it, loss=6.1889, tokens/Max input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [10:54<02:27,  2.74s/it, loss=6.1841, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [10:56<02:18,  2.61s/it, loss=6.1792, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [11:00<02:32,  2.94s/it, loss=6.1737, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [11:03<02:33,  3.01s/it, loss=6.1696, tokens/Max input_id: 31977\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [11:07<02:46,  3.33s/it, loss=6.1652, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [11:13<03:16,  4.01s/it, loss=6.1619, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [11:19<03:41,  4.61s/it, loss=6.1588, tokens/Max input_id: 31963\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [11:21<03:10,  4.05s/it, loss=6.1545, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [11:25<02:56,  3.84s/it, loss=6.1507, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [11:29<02:52,  3.84s/it, loss=6.1479, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [11:32<02:43,  3.71s/it, loss=6.1445, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [11:35<02:33,  3.57s/it, loss=6.1408, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [11:38<02:14,  3.19s/it, loss=6.1375, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [11:40<02:01,  2.95s/it, loss=6.1335, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [11:43<01:58,  2.96s/it, loss=6.1295, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [11:46<01:59,  3.06s/it, loss=6.1245, tokens/Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [11:50<01:59,  3.13s/it, loss=6.1202, tokens/Max input_id: 31977\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [11:52<01:43,  2.81s/it, loss=6.1165, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [11:54<01:36,  2.69s/it, loss=6.1131, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [11:57<01:33,  2.67s/it, loss=6.1084, tokens/Max input_id: 31970\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [11:59<01:31,  2.68s/it, loss=6.1052, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [12:04<01:51,  3.37s/it, loss=6.1009, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [12:07<01:43,  3.23s/it, loss=6.0972, tokens/Max input_id: 31959\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [12:10<01:33,  3.01s/it, loss=6.0933, tokens/Max input_id: 31957\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [12:12<01:26,  2.87s/it, loss=6.0906, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [12:15<01:23,  2.90s/it, loss=6.0863, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [12:18<01:17,  2.77s/it, loss=6.0819, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [12:20<01:14,  2.77s/it, loss=6.0783, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [12:24<01:18,  3.03s/it, loss=6.0756, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [12:27<01:15,  3.03s/it, loss=6.0716, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [12:29<01:07,  2.80s/it, loss=6.0662, tokens/Max input_id: 31977\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [12:31<00:56,  2.45s/it, loss=6.0618, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [12:33<00:49,  2.27s/it, loss=6.0573, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [12:37<00:58,  2.80s/it, loss=6.0541, tokens/Max input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [12:39<00:49,  2.49s/it, loss=6.0503, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [12:43<00:57,  3.03s/it, loss=6.0463, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [12:49<01:08,  3.83s/it, loss=6.0423, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [12:51<00:55,  3.26s/it, loss=6.0383, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [12:57<01:08,  4.27s/it, loss=6.0348, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [13:00<00:55,  3.70s/it, loss=6.0321, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [13:06<01:04,  4.59s/it, loss=6.0296, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [13:10<00:54,  4.22s/it, loss=6.0259, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [13:13<00:46,  3.87s/it, loss=6.0226, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [13:17<00:45,  4.13s/it, loss=6.0192, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [13:20<00:35,  3.59s/it, loss=6.0164, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [13:22<00:28,  3.15s/it, loss=6.0132, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [13:25<00:24,  3.04s/it, loss=6.0104, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [13:27<00:19,  2.82s/it, loss=6.0066, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [13:30<00:16,  2.76s/it, loss=6.0039, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [13:32<00:12,  2.56s/it, loss=6.0001, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [13:35<00:10,  2.71s/it, loss=5.9964, tokens/Max input_id: 31963\n",
      "Max target_input: 31986\n",
      "Max label: 31986\n",
      "Training:  99%|█████████▉| 247/250 [13:38<00:08,  2.99s/it, loss=5.9947, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training:  99%|█████████▉| 248/250 [13:41<00:05,  2.81s/it, loss=5.9923, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Training: 100%|█████████▉| 249/250 [13:43<00:02,  2.64s/it, loss=5.9903, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training: 100%|██████████| 250/250 [14:01<00:00,  3.37s/it, loss=5.9879, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "/opt/anaconda3/envs/de-en-translator/lib/python3.9/site-packages/torch/nn/modules/transformer.py:505: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "Evaluating:   3%|█                               | 1/32 [00:07<03:42,  7.19s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:08<01:51,  3.70s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:09<01:16,  2.65s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:10<00:54,  1.95s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:11<00:44,  1.65s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:12<00:38,  1.46s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:13<00:32,  1.28s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:14<00:28,  1.17s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:16<00:27,  1.19s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:16<00:23,  1.06s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:17<00:22,  1.07s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:18<00:18,  1.06it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:19<00:18,  1.00it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:20<00:16,  1.09it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:21<00:15,  1.09it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:22<00:17,  1.11s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:23<00:16,  1.11s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:24<00:14,  1.03s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:25<00:13,  1.02s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:26<00:11,  1.03it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:27<00:09,  1.13it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:28<00:08,  1.12it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:29<00:08,  1.02it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:30<00:08,  1.03s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:31<00:07,  1.00s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:32<00:06,  1.11s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:33<00:05,  1.04s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:47<00:00,  1.47s/it]\n",
      "Removed old checkpoint: model_epoch_1.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_1.pt\n",
      "Saved training results to training_results_20250511_162111.csv\n",
      "Train Loss: 5.9879\n",
      "Val Loss: 5.3034\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: I would like to the European Parliament to the European Parliament, the European Parliament, the European Parliament.\n",
      "\n",
      "Epoch 2/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "Tokenizer vocab size:   [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:10<43:27, 10.47s/it, loss=4.9719, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:14<28:14,  6.83s/it, loss=5.1907, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:16<19:09,  4.66s/it, loss=5.2119, tokens/s=Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:22<20:54,  5.10s/it, loss=5.1574, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:24<16:05,  3.94s/it, loss=5.1484, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:27<15:17,  3.76s/it, loss=5.1340, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:29<12:57,  3.20s/it, loss=5.1260, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:32<11:50,  2.94s/it, loss=5.1295, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:37<14:12,  3.54s/it, loss=5.1275, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:39<12:08,  3.04s/it, loss=5.1249, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:43<13:30,  3.39s/it, loss=5.1230, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:46<13:33,  3.42s/it, loss=5.1322, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:49<12:30,  3.17s/it, loss=5.1288, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:51<10:49,  2.75s/it, loss=5.1274, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [00:52<09:27,  2.41s/it, loss=5.1170, tokens/sMax input_id: 31969\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [00:54<08:40,  2.23s/it, loss=5.1046, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [00:56<08:52,  2.28s/it, loss=5.1103, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [00:58<08:25,  2.18s/it, loss=5.1012, tokens/sMax input_id: 31977\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:02<09:48,  2.55s/it, loss=5.0986, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:08<13:54,  3.63s/it, loss=5.0941, tokens/sMax input_id: 31978\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:10<12:11,  3.20s/it, loss=5.0872, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:14<13:16,  3.49s/it, loss=5.0994, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:16<11:40,  3.09s/it, loss=5.0909, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:19<11:25,  3.03s/it, loss=5.0944, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:24<13:32,  3.61s/it, loss=5.0974, tokens/sMax input_id: 31978\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:31<17:06,  4.58s/it, loss=5.0972, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:34<14:40,  3.95s/it, loss=5.0966, tokens/sMax input_id: 31970\n",
      "Max target_input: 31988\n",
      "Max label: 31988\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [01:39<16:31,  4.47s/it, loss=5.1024, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [01:42<14:36,  3.96s/it, loss=5.1026, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [01:44<12:34,  3.43s/it, loss=5.0991, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [01:47<11:46,  3.23s/it, loss=5.1015, tokens/sMax input_id: 31958\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [01:54<15:25,  4.24s/it, loss=5.1022, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [01:57<14:52,  4.11s/it, loss=5.1046, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:00<13:03,  3.63s/it, loss=5.1072, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:03<12:32,  3.50s/it, loss=5.1117, tokens/sMax input_id: 31957\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:06<11:28,  3.22s/it, loss=5.1106, tokens/sMax input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:09<11:15,  3.17s/it, loss=5.1101, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:11<10:07,  2.87s/it, loss=5.1061, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:14<10:35,  3.01s/it, loss=5.1036, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:17<10:09,  2.90s/it, loss=5.1017, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:20<09:45,  2.80s/it, loss=5.1000, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:22<09:41,  2.79s/it, loss=5.0984, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:26<10:08,  2.94s/it, loss=5.1007, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:29<10:19,  3.01s/it, loss=5.0978, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [02:32<10:19,  3.02s/it, loss=5.0976, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [02:34<09:32,  2.81s/it, loss=5.0999, tokens/sMax input_id: 31963\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [02:37<09:27,  2.80s/it, loss=5.0992, tokens/sMax input_id: 31969\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [02:42<12:04,  3.59s/it, loss=5.0962, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [02:45<11:07,  3.32s/it, loss=5.0968, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [02:48<10:33,  3.17s/it, loss=5.1006, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [02:53<12:32,  3.78s/it, loss=5.1033, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [02:55<11:07,  3.37s/it, loss=5.1025, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [02:58<10:26,  3.18s/it, loss=5.0998, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:03<12:24,  3.80s/it, loss=5.1022, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:06<11:23,  3.51s/it, loss=5.1045, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:11<12:21,  3.82s/it, loss=5.1015, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:13<10:40,  3.32s/it, loss=5.0986, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:18<11:58,  3.74s/it, loss=5.0981, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:20<10:19,  3.24s/it, loss=5.0975, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [03:23<10:11,  3.22s/it, loss=5.0952, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [03:26<09:53,  3.14s/it, loss=5.0925, tokens/sMax input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [03:28<09:15,  2.96s/it, loss=5.0896, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [03:31<08:31,  2.74s/it, loss=5.0855, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [03:35<10:05,  3.26s/it, loss=5.0842, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [03:38<09:28,  3.07s/it, loss=5.0802, tokens/sMax input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [03:41<09:27,  3.08s/it, loss=5.0786, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [03:43<08:28,  2.78s/it, loss=5.0753, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [03:46<08:49,  2.91s/it, loss=5.0740, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [03:49<08:33,  2.84s/it, loss=5.0729, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [03:51<07:58,  2.66s/it, loss=5.0730, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [03:54<08:26,  2.83s/it, loss=5.0714, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [03:56<07:51,  2.65s/it, loss=5.0704, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [03:58<07:09,  2.43s/it, loss=5.0678, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:00<06:37,  2.26s/it, loss=5.0681, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [04:02<06:18,  2.16s/it, loss=5.0660, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [04:05<06:50,  2.36s/it, loss=5.0651, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [04:08<07:03,  2.45s/it, loss=5.0655, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [04:11<08:09,  2.84s/it, loss=5.0655, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [04:14<07:46,  2.73s/it, loss=5.0656, tokens/sMax input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [04:17<08:19,  2.94s/it, loss=5.0660, tokens/sMax input_id: 31959\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [04:19<07:35,  2.70s/it, loss=5.0653, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [04:23<08:11,  2.93s/it, loss=5.0639, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [04:27<08:55,  3.20s/it, loss=5.0626, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [04:30<08:58,  3.25s/it, loss=5.0606, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [04:33<08:28,  3.08s/it, loss=5.0590, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [04:35<07:52,  2.88s/it, loss=5.0547, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [04:37<07:02,  2.59s/it, loss=5.0535, tokens/sMax input_id: 31969\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [04:40<06:48,  2.52s/it, loss=5.0521, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [04:46<09:46,  3.64s/it, loss=5.0534, tokens/sMax input_id: 31958\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [04:48<08:18,  3.11s/it, loss=5.0524, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [04:51<08:40,  3.27s/it, loss=5.0510, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [04:54<08:13,  3.13s/it, loss=5.0499, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [04:57<08:11,  3.13s/it, loss=5.0510, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [04:59<06:56,  2.67s/it, loss=5.0475, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [05:01<06:42,  2.60s/it, loss=5.0494, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [05:03<06:08,  2.40s/it, loss=5.0459, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [05:05<05:55,  2.32s/it, loss=5.0446, tokens/sMax input_id: 31968\n",
      "Max target_input: 31967\n",
      "Max label: 31967\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [05:10<07:29,  2.96s/it, loss=5.0469, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [05:12<07:01,  2.79s/it, loss=5.0420, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [05:19<09:56,  3.98s/it, loss=5.0436, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [05:21<08:19,  3.35s/it, loss=5.0424, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [05:23<07:26,  3.02s/it, loss=5.0400, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [05:27<07:57,  3.25s/it, loss=5.0377, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [05:30<07:30,  3.09s/it, loss=5.0384, tokens/Max input_id: 31938\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [05:32<06:47,  2.81s/it, loss=5.0378, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [05:35<07:10,  2.99s/it, loss=5.0364, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [05:38<07:00,  2.94s/it, loss=5.0358, tokens/Max input_id: 31963\n",
      "Max target_input: 31998\n",
      "Max label: 31998\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [05:40<06:37,  2.80s/it, loss=5.0350, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [05:43<06:13,  2.65s/it, loss=5.0355, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [05:47<07:18,  3.13s/it, loss=5.0337, tokens/Max input_id: 31970\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [05:50<06:55,  2.99s/it, loss=5.0341, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [05:52<06:31,  2.84s/it, loss=5.0319, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [06:00<09:38,  4.23s/it, loss=5.0315, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [06:02<08:14,  3.63s/it, loss=5.0305, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [06:04<07:05,  3.15s/it, loss=5.0291, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [06:09<08:03,  3.61s/it, loss=5.0280, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [06:15<09:47,  4.42s/it, loss=5.0281, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [06:21<10:59,  5.00s/it, loss=5.0280, tokens/Max input_id: 31959\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [06:24<09:36,  4.40s/it, loss=5.0283, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [06:26<07:46,  3.59s/it, loss=5.0273, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [06:28<06:54,  3.21s/it, loss=5.0272, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [06:31<06:27,  3.03s/it, loss=5.0283, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [06:34<06:12,  2.94s/it, loss=5.0272, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [06:35<05:27,  2.60s/it, loss=5.0245, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [06:39<06:02,  2.90s/it, loss=5.0230, tokens/Max input_id: 31958\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [06:42<06:03,  2.93s/it, loss=5.0223, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [06:44<05:17,  2.58s/it, loss=5.0202, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [06:47<05:28,  2.69s/it, loss=5.0188, tokens/Max input_id: 31970\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [06:49<05:00,  2.48s/it, loss=5.0176, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [06:51<04:52,  2.44s/it, loss=5.0169, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [06:54<05:01,  2.53s/it, loss=5.0183, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [06:56<04:35,  2.34s/it, loss=5.0165, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [06:57<04:12,  2.16s/it, loss=5.0155, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [07:03<06:04,  3.14s/it, loss=5.0138, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [07:06<06:05,  3.18s/it, loss=5.0127, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [07:09<05:38,  2.97s/it, loss=5.0119, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [07:11<05:32,  2.94s/it, loss=5.0101, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [07:14<05:19,  2.85s/it, loss=5.0089, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [07:16<04:48,  2.60s/it, loss=5.0082, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [07:18<04:30,  2.46s/it, loss=5.0085, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [07:22<05:06,  2.81s/it, loss=5.0064, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [07:24<04:34,  2.54s/it, loss=5.0063, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [07:27<05:09,  2.89s/it, loss=5.0055, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [07:30<04:52,  2.76s/it, loss=5.0031, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [07:35<05:53,  3.37s/it, loss=5.0032, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [07:37<05:18,  3.06s/it, loss=5.0024, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [07:39<04:37,  2.70s/it, loss=5.0003, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [07:41<04:16,  2.52s/it, loss=5.0012, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [07:46<05:21,  3.19s/it, loss=5.0006, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [07:51<06:12,  3.73s/it, loss=4.9999, tokens/Max input_id: 31977\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [07:54<05:42,  3.46s/it, loss=5.0004, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [07:58<05:58,  3.66s/it, loss=4.9998, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [08:00<05:12,  3.22s/it, loss=4.9992, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [08:04<05:23,  3.37s/it, loss=4.9979, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [08:05<04:37,  2.92s/it, loss=4.9969, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [08:08<04:26,  2.83s/it, loss=4.9971, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [08:11<04:21,  2.82s/it, loss=4.9966, tokens/Max input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [08:14<04:16,  2.79s/it, loss=4.9984, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [08:16<04:13,  2.78s/it, loss=4.9978, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [08:19<04:07,  2.75s/it, loss=4.9975, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [08:26<05:48,  3.91s/it, loss=4.9970, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [08:29<05:15,  3.59s/it, loss=4.9973, tokens/Max input_id: 31963\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [08:30<04:26,  3.06s/it, loss=4.9955, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [08:33<04:01,  2.80s/it, loss=4.9942, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [08:36<04:05,  2.89s/it, loss=4.9936, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [08:39<04:05,  2.93s/it, loss=4.9932, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [08:41<03:52,  2.80s/it, loss=4.9915, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [08:44<03:54,  2.86s/it, loss=4.9919, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [08:46<03:23,  2.51s/it, loss=4.9905, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [08:49<03:25,  2.57s/it, loss=4.9897, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [08:56<05:19,  4.05s/it, loss=4.9871, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [08:58<04:23,  3.38s/it, loss=4.9865, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [09:01<04:10,  3.26s/it, loss=4.9873, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [09:03<03:39,  2.89s/it, loss=4.9868, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [09:05<03:12,  2.57s/it, loss=4.9866, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [09:08<03:21,  2.73s/it, loss=4.9859, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [09:10<03:08,  2.58s/it, loss=4.9860, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [09:12<02:53,  2.40s/it, loss=4.9850, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [09:14<02:51,  2.41s/it, loss=4.9849, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [09:17<02:48,  2.41s/it, loss=4.9845, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [09:19<02:35,  2.26s/it, loss=4.9828, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [09:25<03:55,  3.46s/it, loss=4.9808, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [09:27<03:28,  3.11s/it, loss=4.9800, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [09:30<03:24,  3.09s/it, loss=4.9787, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [09:32<03:01,  2.79s/it, loss=4.9784, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [09:36<03:15,  3.06s/it, loss=4.9772, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [09:38<02:46,  2.64s/it, loss=4.9761, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [09:40<02:44,  2.65s/it, loss=4.9746, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [09:43<02:43,  2.68s/it, loss=4.9734, tokens/Max input_id: 31964\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [09:50<03:49,  3.83s/it, loss=4.9725, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [09:53<03:29,  3.54s/it, loss=4.9725, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [09:55<03:06,  3.22s/it, loss=4.9709, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [09:58<02:50,  2.98s/it, loss=4.9708, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [10:02<03:07,  3.35s/it, loss=4.9701, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [10:04<02:45,  3.01s/it, loss=4.9694, tokens/Max input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [10:07<02:36,  2.91s/it, loss=4.9682, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [10:09<02:25,  2.75s/it, loss=4.9667, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [10:13<02:36,  3.02s/it, loss=4.9647, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [10:16<02:36,  3.06s/it, loss=4.9640, tokens/Max input_id: 31977\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [10:20<02:47,  3.36s/it, loss=4.9629, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [10:25<03:17,  4.03s/it, loss=4.9630, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [10:32<03:42,  4.63s/it, loss=4.9635, tokens/Max input_id: 31963\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [10:34<03:10,  4.06s/it, loss=4.9625, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [10:38<02:56,  3.85s/it, loss=4.9621, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [10:42<03:00,  4.02s/it, loss=4.9626, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [10:46<02:58,  4.07s/it, loss=4.9626, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [10:50<02:45,  3.85s/it, loss=4.9623, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [10:52<02:22,  3.40s/it, loss=4.9622, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [10:54<02:07,  3.11s/it, loss=4.9613, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [10:57<02:04,  3.12s/it, loss=4.9603, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [11:01<02:03,  3.17s/it, loss=4.9584, tokens/Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [11:04<01:58,  3.12s/it, loss=4.9572, tokens/Max input_id: 31977\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [11:06<01:44,  2.82s/it, loss=4.9565, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [11:08<01:37,  2.70s/it, loss=4.9561, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [11:10<01:24,  2.41s/it, loss=4.9542, tokens/Max input_id: 31970\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [11:13<01:29,  2.62s/it, loss=4.9539, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [11:18<01:46,  3.24s/it, loss=4.9527, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [11:21<01:40,  3.14s/it, loss=4.9517, tokens/Max input_id: 31959\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [11:23<01:31,  2.96s/it, loss=4.9507, tokens/Max input_id: 31957\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [11:26<01:25,  2.84s/it, loss=4.9510, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [11:29<01:23,  2.89s/it, loss=4.9499, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [11:31<01:17,  2.76s/it, loss=4.9483, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [11:34<01:14,  2.75s/it, loss=4.9474, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [11:37<01:14,  2.88s/it, loss=4.9477, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [11:39<01:06,  2.67s/it, loss=4.9465, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [11:42<01:06,  2.76s/it, loss=4.9437, tokens/Max input_id: 31977\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [11:44<00:55,  2.42s/it, loss=4.9419, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [11:46<00:49,  2.24s/it, loss=4.9403, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [11:49<00:51,  2.47s/it, loss=4.9396, tokens/Max input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [11:51<00:45,  2.26s/it, loss=4.9385, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [11:55<00:55,  2.90s/it, loss=4.9372, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [12:00<01:05,  3.63s/it, loss=4.9360, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [12:02<00:52,  3.11s/it, loss=4.9346, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [12:08<01:01,  3.86s/it, loss=4.9339, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [12:10<00:51,  3.43s/it, loss=4.9339, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [12:16<00:59,  4.23s/it, loss=4.9341, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [12:20<00:51,  3.98s/it, loss=4.9330, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [12:22<00:42,  3.57s/it, loss=4.9322, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [12:26<00:40,  3.66s/it, loss=4.9314, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [12:29<00:32,  3.27s/it, loss=4.9309, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [12:31<00:26,  2.93s/it, loss=4.9304, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [12:34<00:23,  2.92s/it, loss=4.9301, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [12:36<00:19,  2.76s/it, loss=4.9288, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [12:39<00:16,  2.74s/it, loss=4.9283, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [12:41<00:12,  2.54s/it, loss=4.9269, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [12:44<00:10,  2.63s/it, loss=4.9255, tokens/Max input_id: 31963\n",
      "Max target_input: 31986\n",
      "Max label: 31986\n",
      "Training:  99%|█████████▉| 247/250 [12:47<00:08,  2.75s/it, loss=4.9263, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training:  99%|█████████▉| 248/250 [12:49<00:05,  2.64s/it, loss=4.9262, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Training: 100%|█████████▉| 249/250 [12:52<00:02,  2.79s/it, loss=4.9266, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training: 100%|██████████| 250/250 [13:09<00:00,  3.16s/it, loss=4.9267, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:07<03:41,  7.13s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:08<01:52,  3.73s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:09<01:17,  2.68s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:10<00:54,  1.96s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:11<00:44,  1.66s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:13<00:38,  1.47s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:13<00:32,  1.29s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:15<00:33,  1.40s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:16<00:32,  1.40s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:17<00:26,  1.20s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:18<00:24,  1.16s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:19<00:20,  1.01s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:20<00:19,  1.05s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:21<00:17,  1.05it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:22<00:15,  1.09it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:22<00:14,  1.14it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:23<00:13,  1.07it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:24<00:12,  1.10it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:25<00:11,  1.09it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:26<00:10,  1.10it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:27<00:09,  1.21it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:28<00:08,  1.16it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:29<00:08,  1.07it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:30<00:08,  1.01s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:31<00:06,  1.01it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:32<00:06,  1.09s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:33<00:05,  1.03s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:47<00:00,  1.48s/it]\n",
      "Removed old checkpoint: model_epoch_2.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_2.pt\n",
      "Saved training results to training_results_20250511_163510.csv\n",
      "Train Loss: 4.9267\n",
      "Val Loss: 4.9472\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: this is a European Parliament to be a European Parliament.\n",
      "\n",
      "Epoch 3/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:10<42:16, 10.19s/it, loss=4.5400, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:14<28:06,  6.80s/it, loss=4.7626, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:16<19:01,  4.62s/it, loss=4.7800, tokens/s=Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:22<20:09,  4.92s/it, loss=4.7198, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:23<15:33,  3.81s/it, loss=4.7067, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:28<16:58,  4.18s/it, loss=4.6932, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:30<14:06,  3.48s/it, loss=4.6840, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:33<12:34,  3.12s/it, loss=4.6816, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:38<14:52,  3.70s/it, loss=4.6760, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:40<12:38,  3.16s/it, loss=4.6713, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:42<12:09,  3.05s/it, loss=4.6687, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:45<12:06,  3.05s/it, loss=4.6806, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:48<11:26,  2.90s/it, loss=4.6791, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:50<10:06,  2.57s/it, loss=4.6805, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [00:51<08:56,  2.28s/it, loss=4.6729, tokens/sMax input_id: 31969\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [00:53<08:09,  2.09s/it, loss=4.6621, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [00:56<09:23,  2.42s/it, loss=4.6715, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [00:58<08:48,  2.28s/it, loss=4.6646, tokens/sMax input_id: 31977\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:01<09:46,  2.54s/it, loss=4.6638, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:07<13:45,  3.59s/it, loss=4.6629, tokens/sMax input_id: 31978\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:10<12:12,  3.20s/it, loss=4.6576, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:12<11:42,  3.08s/it, loss=4.6710, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:15<10:37,  2.81s/it, loss=4.6657, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:17<10:19,  2.74s/it, loss=4.6694, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:22<12:15,  3.27s/it, loss=4.6719, tokens/sMax input_id: 31978\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:28<15:57,  4.27s/it, loss=4.6740, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:31<13:52,  3.73s/it, loss=4.6738, tokens/sMax input_id: 31970\n",
      "Max target_input: 31988\n",
      "Max label: 31988\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [01:38<17:37,  4.76s/it, loss=4.6803, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [01:41<15:30,  4.21s/it, loss=4.6802, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [01:43<13:13,  3.61s/it, loss=4.6776, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [01:46<12:19,  3.38s/it, loss=4.6818, tokens/sMax input_id: 31958\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [01:53<16:23,  4.51s/it, loss=4.6822, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [01:56<14:57,  4.14s/it, loss=4.6844, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:00<13:54,  3.86s/it, loss=4.6863, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:03<13:17,  3.71s/it, loss=4.6887, tokens/sMax input_id: 31957\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:05<11:54,  3.34s/it, loss=4.6887, tokens/sMax input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:09<11:35,  3.27s/it, loss=4.6886, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:11<10:24,  2.95s/it, loss=4.6857, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:14<10:46,  3.06s/it, loss=4.6841, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:17<10:16,  2.94s/it, loss=4.6819, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:19<09:48,  2.82s/it, loss=4.6797, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:22<09:46,  2.82s/it, loss=4.6796, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:26<11:14,  3.26s/it, loss=4.6817, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:29<10:15,  2.99s/it, loss=4.6788, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [02:32<10:47,  3.16s/it, loss=4.6799, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [02:35<10:40,  3.14s/it, loss=4.6820, tokens/sMax input_id: 31963\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [02:38<10:16,  3.04s/it, loss=4.6824, tokens/sMax input_id: 31969\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [02:44<13:07,  3.90s/it, loss=4.6787, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [02:47<11:57,  3.57s/it, loss=4.6790, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [02:50<11:21,  3.41s/it, loss=4.6835, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [02:55<13:14,  3.99s/it, loss=4.6871, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [02:58<11:36,  3.52s/it, loss=4.6867, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:01<11:06,  3.38s/it, loss=4.6839, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:06<13:09,  4.03s/it, loss=4.6866, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:09<11:57,  3.68s/it, loss=4.6876, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:15<13:35,  4.21s/it, loss=4.6843, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:17<11:30,  3.58s/it, loss=4.6816, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:21<12:23,  3.87s/it, loss=4.6813, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:23<10:35,  3.33s/it, loss=4.6810, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [03:27<11:00,  3.48s/it, loss=4.6789, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [03:30<10:29,  3.33s/it, loss=4.6760, tokens/sMax input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [03:33<09:39,  3.08s/it, loss=4.6723, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [03:35<08:49,  2.83s/it, loss=4.6683, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [03:41<11:30,  3.71s/it, loss=4.6678, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [03:43<10:24,  3.38s/it, loss=4.6629, tokens/sMax input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [03:47<10:45,  3.51s/it, loss=4.6616, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [03:50<10:11,  3.34s/it, loss=4.6587, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [03:52<09:20,  3.08s/it, loss=4.6572, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [03:55<09:10,  3.04s/it, loss=4.6567, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [03:58<08:25,  2.81s/it, loss=4.6573, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:01<09:14,  3.10s/it, loss=4.6565, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:04<08:22,  2.82s/it, loss=4.6560, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:05<07:29,  2.54s/it, loss=4.6533, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:07<06:56,  2.37s/it, loss=4.6536, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [04:09<06:31,  2.24s/it, loss=4.6516, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [04:12<06:58,  2.41s/it, loss=4.6512, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [04:15<07:02,  2.44s/it, loss=4.6518, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [04:19<08:16,  2.89s/it, loss=4.6524, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [04:21<07:54,  2.77s/it, loss=4.6534, tokens/sMax input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [04:25<08:28,  2.99s/it, loss=4.6540, tokens/sMax input_id: 31959\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [04:27<07:46,  2.76s/it, loss=4.6530, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [04:31<08:49,  3.15s/it, loss=4.6515, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [04:34<09:00,  3.24s/it, loss=4.6508, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [04:38<09:17,  3.36s/it, loss=4.6492, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [04:41<08:38,  3.14s/it, loss=4.6480, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [04:43<07:57,  2.91s/it, loss=4.6435, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [04:45<07:01,  2.59s/it, loss=4.6428, tokens/sMax input_id: 31969\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [04:47<06:46,  2.51s/it, loss=4.6413, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [04:54<09:53,  3.69s/it, loss=4.6430, tokens/sMax input_id: 31958\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [04:55<08:21,  3.14s/it, loss=4.6424, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [04:58<08:02,  3.03s/it, loss=4.6416, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [05:02<08:30,  3.23s/it, loss=4.6400, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [05:06<08:55,  3.41s/it, loss=4.6409, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [05:07<07:27,  2.87s/it, loss=4.6372, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [05:10<07:16,  2.82s/it, loss=4.6393, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [05:12<06:33,  2.55s/it, loss=4.6356, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [05:14<06:09,  2.42s/it, loss=4.6349, tokens/sMax input_id: 31968\n",
      "Max target_input: 31967\n",
      "Max label: 31967\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [05:18<07:35,  3.00s/it, loss=4.6376, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [05:21<07:01,  2.79s/it, loss=4.6332, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [05:28<10:07,  4.05s/it, loss=4.6354, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [05:30<08:28,  3.41s/it, loss=4.6342, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [05:33<08:13,  3.33s/it, loss=4.6319, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [05:36<08:06,  3.31s/it, loss=4.6298, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [05:39<07:44,  3.18s/it, loss=4.6309, tokens/Max input_id: 31938\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [05:41<06:56,  2.87s/it, loss=4.6306, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [05:45<07:46,  3.24s/it, loss=4.6295, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [05:48<07:28,  3.14s/it, loss=4.6291, tokens/Max input_id: 31963\n",
      "Max target_input: 31998\n",
      "Max label: 31998\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [05:51<06:57,  2.94s/it, loss=4.6287, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [05:53<06:26,  2.74s/it, loss=4.6294, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [05:57<07:14,  3.11s/it, loss=4.6276, tokens/Max input_id: 31970\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [06:00<06:57,  3.00s/it, loss=4.6285, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [06:02<06:30,  2.83s/it, loss=4.6268, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [06:11<10:25,  4.57s/it, loss=4.6271, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [06:13<08:49,  3.90s/it, loss=4.6259, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [06:15<07:28,  3.32s/it, loss=4.6245, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [06:18<07:18,  3.27s/it, loss=4.6234, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [06:24<09:07,  4.12s/it, loss=4.6235, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [06:31<10:35,  4.81s/it, loss=4.6238, tokens/Max input_id: 31959\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [06:34<09:19,  4.27s/it, loss=4.6246, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [06:35<07:36,  3.51s/it, loss=4.6240, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [06:38<06:50,  3.18s/it, loss=4.6246, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [06:41<06:58,  3.27s/it, loss=4.6259, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [06:45<07:14,  3.42s/it, loss=4.6251, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [06:47<06:11,  2.95s/it, loss=4.6226, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [06:50<06:28,  3.11s/it, loss=4.6216, tokens/Max input_id: 31958\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [06:53<06:15,  3.02s/it, loss=4.6211, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [06:55<05:25,  2.64s/it, loss=4.6191, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [06:58<05:27,  2.68s/it, loss=4.6179, tokens/Max input_id: 31970\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [07:00<04:58,  2.47s/it, loss=4.6171, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [07:02<04:52,  2.43s/it, loss=4.6167, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [07:05<04:54,  2.47s/it, loss=4.6182, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [07:07<04:33,  2.32s/it, loss=4.6163, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [07:08<04:10,  2.14s/it, loss=4.6153, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [07:15<06:40,  3.45s/it, loss=4.6142, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [07:18<06:39,  3.48s/it, loss=4.6133, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [07:21<05:59,  3.15s/it, loss=4.6129, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [07:23<05:19,  2.83s/it, loss=4.6116, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [07:25<05:08,  2.75s/it, loss=4.6105, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [07:27<04:40,  2.52s/it, loss=4.6101, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [07:30<04:23,  2.40s/it, loss=4.6107, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [07:32<04:33,  2.51s/it, loss=4.6087, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [07:34<04:12,  2.34s/it, loss=4.6090, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [07:37<04:26,  2.49s/it, loss=4.6085, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [07:40<04:24,  2.50s/it, loss=4.6065, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [07:46<06:24,  3.66s/it, loss=4.6065, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [07:48<05:38,  3.26s/it, loss=4.6059, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [07:50<04:53,  2.85s/it, loss=4.6039, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [07:52<04:24,  2.59s/it, loss=4.6049, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [07:55<04:25,  2.63s/it, loss=4.6044, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [08:00<05:26,  3.26s/it, loss=4.6041, tokens/Max input_id: 31977\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [08:02<05:06,  3.10s/it, loss=4.6049, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [08:06<05:29,  3.36s/it, loss=4.6047, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [08:08<04:51,  3.00s/it, loss=4.6043, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [08:15<06:15,  3.91s/it, loss=4.6034, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [08:16<05:13,  3.30s/it, loss=4.6025, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [08:19<04:58,  3.18s/it, loss=4.6030, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [08:22<04:42,  3.04s/it, loss=4.6025, tokens/Max input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [08:25<04:32,  2.97s/it, loss=4.6046, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [08:28<04:25,  2.92s/it, loss=4.6045, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [08:30<04:17,  2.86s/it, loss=4.6047, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [08:36<05:22,  3.62s/it, loss=4.6046, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [08:39<04:57,  3.38s/it, loss=4.6054, tokens/Max input_id: 31963\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [08:40<04:11,  2.89s/it, loss=4.6037, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [08:43<04:12,  2.94s/it, loss=4.6026, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [08:48<04:43,  3.33s/it, loss=4.6025, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [08:52<05:04,  3.62s/it, loss=4.6025, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [08:54<04:32,  3.28s/it, loss=4.6015, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [08:58<04:26,  3.25s/it, loss=4.6023, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [08:59<03:46,  2.79s/it, loss=4.6011, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [09:02<03:42,  2.78s/it, loss=4.6009, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [09:09<05:12,  3.95s/it, loss=4.5987, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [09:11<04:17,  3.30s/it, loss=4.5984, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [09:13<03:56,  3.08s/it, loss=4.5994, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [09:16<03:49,  3.02s/it, loss=4.5992, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [09:18<03:19,  2.66s/it, loss=4.5995, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [09:21<03:29,  2.83s/it, loss=4.5993, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [09:23<03:13,  2.65s/it, loss=4.5997, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [09:25<02:57,  2.46s/it, loss=4.5989, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [09:28<02:58,  2.52s/it, loss=4.5990, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [09:30<02:54,  2.49s/it, loss=4.5987, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [09:32<02:39,  2.32s/it, loss=4.5974, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [09:39<04:04,  3.60s/it, loss=4.5957, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [09:41<03:35,  3.21s/it, loss=4.5953, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [09:44<03:31,  3.20s/it, loss=4.5944, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [09:47<03:11,  2.95s/it, loss=4.5946, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [09:51<03:34,  3.35s/it, loss=4.5936, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [09:53<02:59,  2.85s/it, loss=4.5927, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [09:55<02:52,  2.79s/it, loss=4.5916, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [09:58<02:49,  2.78s/it, loss=4.5906, tokens/Max input_id: 31964\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [10:05<03:59,  4.00s/it, loss=4.5899, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [10:08<03:42,  3.77s/it, loss=4.5901, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [10:11<03:16,  3.39s/it, loss=4.5888, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [10:13<02:57,  3.11s/it, loss=4.5889, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [10:19<03:33,  3.81s/it, loss=4.5886, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [10:21<03:03,  3.35s/it, loss=4.5882, tokens/Max input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [10:23<02:48,  3.12s/it, loss=4.5873, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [10:26<02:32,  2.87s/it, loss=4.5860, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [10:29<02:39,  3.07s/it, loss=4.5843, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [10:33<02:41,  3.16s/it, loss=4.5838, tokens/Max input_id: 31977\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [10:37<03:03,  3.66s/it, loss=4.5829, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [10:44<03:37,  4.45s/it, loss=4.5834, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [10:50<04:01,  5.02s/it, loss=4.5842, tokens/Max input_id: 31963\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [10:54<03:37,  4.62s/it, loss=4.5835, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [10:56<03:05,  4.02s/it, loss=4.5832, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [11:01<03:14,  4.31s/it, loss=4.5840, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [11:05<03:00,  4.10s/it, loss=4.5842, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [11:09<02:55,  4.07s/it, loss=4.5844, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [11:11<02:27,  3.52s/it, loss=4.5845, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [11:14<02:10,  3.17s/it, loss=4.5840, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [11:18<02:20,  3.50s/it, loss=4.5834, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [11:22<02:26,  3.77s/it, loss=4.5817, tokens/Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [11:27<02:39,  4.20s/it, loss=4.5808, tokens/Max input_id: 31977\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [11:30<02:11,  3.56s/it, loss=4.5806, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [11:33<02:03,  3.44s/it, loss=4.5802, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [11:34<01:42,  2.93s/it, loss=4.5786, tokens/Max input_id: 31970\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [11:37<01:31,  2.70s/it, loss=4.5784, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [11:41<01:44,  3.17s/it, loss=4.5775, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [11:44<01:38,  3.08s/it, loss=4.5766, tokens/Max input_id: 31959\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [11:46<01:30,  2.91s/it, loss=4.5759, tokens/Max input_id: 31957\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [11:49<01:24,  2.80s/it, loss=4.5765, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [11:52<01:22,  2.85s/it, loss=4.5757, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [11:55<01:23,  2.98s/it, loss=4.5741, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [11:59<01:30,  3.33s/it, loss=4.5734, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [12:04<01:37,  3.75s/it, loss=4.5738, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [12:06<01:21,  3.27s/it, loss=4.5727, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [12:08<01:10,  2.93s/it, loss=4.5702, tokens/Max input_id: 31977\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [12:10<00:58,  2.54s/it, loss=4.5688, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [12:12<00:50,  2.32s/it, loss=4.5673, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [12:14<00:52,  2.49s/it, loss=4.5669, tokens/Max input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [12:16<00:45,  2.26s/it, loss=4.5659, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [12:20<00:49,  2.63s/it, loss=4.5649, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [12:26<01:05,  3.65s/it, loss=4.5640, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [12:29<00:58,  3.44s/it, loss=4.5630, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [12:35<01:09,  4.32s/it, loss=4.5623, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [12:37<00:56,  3.74s/it, loss=4.5626, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [12:44<01:03,  4.51s/it, loss=4.5633, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [12:46<00:50,  3.90s/it, loss=4.5625, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [12:49<00:41,  3.48s/it, loss=4.5621, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [12:53<00:39,  3.61s/it, loss=4.5617, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [12:55<00:32,  3.22s/it, loss=4.5612, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [12:58<00:28,  3.17s/it, loss=4.5609, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [13:02<00:26,  3.37s/it, loss=4.5609, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [13:05<00:22,  3.22s/it, loss=4.5598, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [13:08<00:18,  3.09s/it, loss=4.5593, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [13:10<00:13,  2.79s/it, loss=4.5584, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [13:13<00:12,  3.02s/it, loss=4.5573, tokens/Max input_id: 31963\n",
      "Max target_input: 31986\n",
      "Max label: 31986\n",
      "Training:  99%|█████████▉| 247/250 [13:17<00:09,  3.20s/it, loss=4.5582, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training:  99%|█████████▉| 248/250 [13:19<00:05,  2.95s/it, loss=4.5584, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Training: 100%|█████████▉| 249/250 [13:21<00:02,  2.75s/it, loss=4.5592, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training: 100%|██████████| 250/250 [13:38<00:00,  3.27s/it, loss=4.5596, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:07<03:45,  7.28s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:08<01:54,  3.83s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:10<01:18,  2.72s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:10<00:55,  1.99s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:12<00:45,  1.68s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:13<00:38,  1.49s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:14<00:32,  1.30s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:15<00:28,  1.19s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:16<00:28,  1.23s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:17<00:23,  1.09s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:18<00:22,  1.08s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:18<00:19,  1.04it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:20<00:23,  1.23s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:21<00:19,  1.08s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:22<00:17,  1.03s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:23<00:15,  1.06it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:24<00:14,  1.02it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:25<00:13,  1.05it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:26<00:12,  1.05it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:26<00:11,  1.08it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:27<00:09,  1.18it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:28<00:08,  1.12it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:29<00:08,  1.03it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:30<00:08,  1.04s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:31<00:07,  1.01s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:33<00:06,  1.10s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:34<00:05,  1.04s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:47<00:00,  1.48s/it]\n",
      "Removed old checkpoint: model_epoch_3.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_3.pt\n",
      "Saved training results to training_results_20250511_164938.csv\n",
      "Train Loss: 4.5596\n",
      "Val Loss: 4.7856\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: this is a European?\n",
      "\n",
      "Epoch 4/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:09<39:53,  9.61s/it, loss=4.2619, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:14<27:22,  6.62s/it, loss=4.4483, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:16<18:36,  4.52s/it, loss=4.4775, tokens/s=Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:21<20:04,  4.90s/it, loss=4.4230, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:24<16:46,  4.11s/it, loss=4.4028, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:27<15:24,  3.79s/it, loss=4.3945, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:29<13:02,  3.22s/it, loss=4.3887, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:31<11:51,  2.94s/it, loss=4.3815, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:36<13:23,  3.33s/it, loss=4.3741, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:37<11:31,  2.88s/it, loss=4.3694, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:40<11:33,  2.90s/it, loss=4.3655, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:43<11:38,  2.93s/it, loss=4.3752, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:46<11:04,  2.80s/it, loss=4.3786, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:48<09:47,  2.49s/it, loss=4.3811, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [00:50<09:40,  2.47s/it, loss=4.3725, tokens/sMax input_id: 31969\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [00:52<08:45,  2.24s/it, loss=4.3649, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [00:54<08:53,  2.29s/it, loss=4.3750, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [00:56<08:34,  2.22s/it, loss=4.3708, tokens/sMax input_id: 31977\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:00<09:47,  2.54s/it, loss=4.3698, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:06<13:43,  3.58s/it, loss=4.3698, tokens/sMax input_id: 31978\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:08<12:06,  3.17s/it, loss=4.3649, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:11<11:36,  3.06s/it, loss=4.3785, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:13<10:28,  2.77s/it, loss=4.3731, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:15<10:10,  2.70s/it, loss=4.3752, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:21<13:51,  3.69s/it, loss=4.3781, tokens/sMax input_id: 31978\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:28<17:04,  4.58s/it, loss=4.3820, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:30<14:38,  3.94s/it, loss=4.3816, tokens/sMax input_id: 31970\n",
      "Max target_input: 31988\n",
      "Max label: 31988\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [01:36<16:07,  4.36s/it, loss=4.3905, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [01:38<14:21,  3.90s/it, loss=4.3904, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [01:41<12:26,  3.39s/it, loss=4.3893, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [01:44<11:46,  3.23s/it, loss=4.3947, tokens/sMax input_id: 31958\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [01:50<15:28,  4.26s/it, loss=4.3953, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [01:54<14:50,  4.10s/it, loss=4.3978, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [01:57<13:07,  3.65s/it, loss=4.3998, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:00<12:52,  3.59s/it, loss=4.4007, tokens/sMax input_id: 31957\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:02<11:35,  3.25s/it, loss=4.4014, tokens/sMax input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:06<11:29,  3.24s/it, loss=4.4017, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:08<10:18,  2.92s/it, loss=4.3989, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:11<10:53,  3.10s/it, loss=4.3970, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:14<10:19,  2.95s/it, loss=4.3937, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:16<09:47,  2.81s/it, loss=4.3915, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:19<09:52,  2.85s/it, loss=4.3924, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:25<12:39,  3.67s/it, loss=4.3944, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:29<12:36,  3.67s/it, loss=4.3914, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [02:33<13:15,  3.88s/it, loss=4.3931, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [02:35<11:41,  3.44s/it, loss=4.3955, tokens/sMax input_id: 31963\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [02:39<11:37,  3.44s/it, loss=4.3957, tokens/sMax input_id: 31969\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [02:45<14:46,  4.39s/it, loss=4.3923, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [02:49<13:47,  4.12s/it, loss=4.3922, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [02:52<13:04,  3.92s/it, loss=4.3966, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [02:59<15:52,  4.79s/it, loss=4.4013, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:02<13:34,  4.11s/it, loss=4.4018, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:05<12:24,  3.78s/it, loss=4.3987, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:11<14:19,  4.39s/it, loss=4.4011, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:14<13:36,  4.19s/it, loss=4.4017, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:19<14:15,  4.41s/it, loss=4.3977, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:22<12:45,  3.97s/it, loss=4.3949, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:27<13:45,  4.30s/it, loss=4.3950, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:30<11:52,  3.73s/it, loss=4.3944, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [03:37<14:56,  4.72s/it, loss=4.3924, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [03:42<15:04,  4.78s/it, loss=4.3895, tokens/sMax input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [03:44<12:59,  4.14s/it, loss=4.3856, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [03:47<11:18,  3.63s/it, loss=4.3816, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [03:53<13:59,  4.51s/it, loss=4.3813, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [03:56<12:17,  3.99s/it, loss=4.3760, tokens/sMax input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [04:00<12:23,  4.04s/it, loss=4.3747, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [04:02<10:38,  3.49s/it, loss=4.3721, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [04:05<10:04,  3.32s/it, loss=4.3708, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [04:09<10:33,  3.50s/it, loss=4.3704, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [04:12<09:30,  3.17s/it, loss=4.3713, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:17<11:00,  3.69s/it, loss=4.3705, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:19<10:10,  3.43s/it, loss=4.3701, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:22<09:14,  3.13s/it, loss=4.3676, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:24<08:13,  2.80s/it, loss=4.3683, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [04:26<07:32,  2.58s/it, loss=4.3665, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [04:30<08:47,  3.03s/it, loss=4.3665, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [04:34<09:31,  3.30s/it, loss=4.3673, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [04:39<10:57,  3.82s/it, loss=4.3680, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [04:42<10:00,  3.51s/it, loss=4.3694, tokens/sMax input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [04:45<09:25,  3.33s/it, loss=4.3707, tokens/sMax input_id: 31959\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [04:47<08:27,  3.01s/it, loss=4.3699, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [04:51<09:10,  3.28s/it, loss=4.3686, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [04:55<10:12,  3.67s/it, loss=4.3684, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [05:00<10:58,  3.97s/it, loss=4.3665, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [05:03<09:51,  3.59s/it, loss=4.3649, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [05:05<09:00,  3.30s/it, loss=4.3610, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [05:08<08:04,  2.97s/it, loss=4.3604, tokens/sMax input_id: 31969\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [05:11<08:00,  2.97s/it, loss=4.3587, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [05:18<11:25,  4.26s/it, loss=4.3607, tokens/sMax input_id: 31958\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [05:20<09:26,  3.54s/it, loss=4.3605, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [05:24<09:48,  3.70s/it, loss=4.3599, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [05:27<09:02,  3.43s/it, loss=4.3584, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [05:30<09:00,  3.44s/it, loss=4.3598, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [05:32<07:31,  2.90s/it, loss=4.3557, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [05:34<07:07,  2.76s/it, loss=4.3581, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [05:36<06:31,  2.54s/it, loss=4.3550, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [05:38<06:09,  2.42s/it, loss=4.3547, tokens/sMax input_id: 31968\n",
      "Max target_input: 31967\n",
      "Max label: 31967\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [05:42<07:15,  2.86s/it, loss=4.3573, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [05:45<06:52,  2.73s/it, loss=4.3534, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [05:53<10:57,  4.38s/it, loss=4.3560, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [05:55<09:06,  3.67s/it, loss=4.3546, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [05:57<08:02,  3.26s/it, loss=4.3519, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [06:00<07:42,  3.15s/it, loss=4.3497, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [06:03<07:23,  3.04s/it, loss=4.3509, tokens/Max input_id: 31938\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [06:05<06:41,  2.77s/it, loss=4.3501, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [06:08<07:05,  2.96s/it, loss=4.3496, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [06:11<07:04,  2.97s/it, loss=4.3491, tokens/Max input_id: 31963\n",
      "Max target_input: 31998\n",
      "Max label: 31998\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [06:14<06:44,  2.85s/it, loss=4.3488, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [06:16<06:19,  2.70s/it, loss=4.3491, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [06:20<07:17,  3.12s/it, loss=4.3469, tokens/Max input_id: 31970\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [06:23<07:02,  3.04s/it, loss=4.3479, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [06:26<06:40,  2.91s/it, loss=4.3468, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [06:34<10:15,  4.49s/it, loss=4.3472, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [06:36<08:44,  3.85s/it, loss=4.3462, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [06:38<07:30,  3.34s/it, loss=4.3454, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [06:43<07:59,  3.58s/it, loss=4.3444, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [06:49<09:55,  4.48s/it, loss=4.3447, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [06:56<11:09,  5.07s/it, loss=4.3452, tokens/Max input_id: 31959\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [06:59<09:45,  4.47s/it, loss=4.3465, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [07:00<07:54,  3.65s/it, loss=4.3460, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [07:03<07:03,  3.28s/it, loss=4.3467, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [07:06<06:36,  3.10s/it, loss=4.3484, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [07:08<06:19,  2.99s/it, loss=4.3479, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [07:10<05:32,  2.64s/it, loss=4.3455, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [07:13<05:31,  2.65s/it, loss=4.3447, tokens/Max input_id: 31958\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [07:15<05:31,  2.68s/it, loss=4.3442, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [07:17<04:54,  2.39s/it, loss=4.3426, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [07:21<05:32,  2.73s/it, loss=4.3413, tokens/Max input_id: 31970\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [07:23<05:05,  2.53s/it, loss=4.3405, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [07:25<05:00,  2.50s/it, loss=4.3400, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [07:28<05:07,  2.59s/it, loss=4.3417, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [07:30<04:40,  2.38s/it, loss=4.3399, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [07:32<04:15,  2.18s/it, loss=4.3389, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [07:37<06:07,  3.17s/it, loss=4.3378, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [07:41<06:16,  3.27s/it, loss=4.3370, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [07:43<05:49,  3.06s/it, loss=4.3367, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [07:45<05:13,  2.77s/it, loss=4.3355, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [07:48<05:05,  2.73s/it, loss=4.3346, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [07:50<04:42,  2.54s/it, loss=4.3343, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [07:52<04:28,  2.44s/it, loss=4.3347, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [07:56<05:24,  2.98s/it, loss=4.3328, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [07:58<04:50,  2.69s/it, loss=4.3333, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [08:03<05:44,  3.22s/it, loss=4.3331, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [08:06<05:22,  3.05s/it, loss=4.3314, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [08:11<06:24,  3.66s/it, loss=4.3312, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [08:13<05:44,  3.31s/it, loss=4.3307, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [08:15<05:00,  2.92s/it, loss=4.3288, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [08:17<04:33,  2.68s/it, loss=4.3297, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [08:20<04:32,  2.69s/it, loss=4.3295, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [08:25<05:48,  3.48s/it, loss=4.3293, tokens/Max input_id: 31977\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [08:28<05:23,  3.27s/it, loss=4.3301, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [08:32<05:46,  3.53s/it, loss=4.3301, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [08:35<05:07,  3.17s/it, loss=4.3296, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [08:40<06:13,  3.89s/it, loss=4.3289, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [08:42<05:14,  3.31s/it, loss=4.3282, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [08:46<05:30,  3.52s/it, loss=4.3291, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [08:49<05:14,  3.38s/it, loss=4.3285, tokens/Max input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [08:52<04:56,  3.22s/it, loss=4.3305, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [08:55<04:46,  3.14s/it, loss=4.3308, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [08:58<04:34,  3.05s/it, loss=4.3312, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [09:03<05:34,  3.75s/it, loss=4.3313, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [09:06<05:10,  3.53s/it, loss=4.3324, tokens/Max input_id: 31963\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [09:08<04:24,  3.04s/it, loss=4.3307, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [09:10<04:03,  2.83s/it, loss=4.3296, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [09:14<04:24,  3.11s/it, loss=4.3299, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [09:19<04:58,  3.55s/it, loss=4.3300, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [09:22<04:44,  3.43s/it, loss=4.3292, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [09:26<04:51,  3.56s/it, loss=4.3303, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [09:28<04:04,  3.02s/it, loss=4.3293, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [09:31<04:08,  3.11s/it, loss=4.3292, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [09:38<05:36,  4.26s/it, loss=4.3271, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [09:40<04:36,  3.55s/it, loss=4.3265, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [09:42<04:12,  3.28s/it, loss=4.3274, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [09:44<03:42,  2.92s/it, loss=4.3272, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [09:46<03:14,  2.60s/it, loss=4.3278, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [09:49<03:17,  2.67s/it, loss=4.3275, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [09:51<03:07,  2.57s/it, loss=4.3282, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [09:54<02:56,  2.45s/it, loss=4.3274, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [09:57<03:05,  2.61s/it, loss=4.3278, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [09:59<03:01,  2.59s/it, loss=4.3280, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [10:01<02:45,  2.40s/it, loss=4.3268, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [10:08<04:13,  3.73s/it, loss=4.3254, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [10:10<03:42,  3.33s/it, loss=4.3254, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [10:13<03:18,  3.00s/it, loss=4.3246, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [10:15<02:59,  2.76s/it, loss=4.3248, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [10:18<03:03,  2.86s/it, loss=4.3241, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [10:20<02:37,  2.49s/it, loss=4.3233, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [10:22<02:35,  2.50s/it, loss=4.3224, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [10:25<02:38,  2.60s/it, loss=4.3217, tokens/Max input_id: 31964\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [10:32<03:54,  3.91s/it, loss=4.3212, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [10:35<03:33,  3.61s/it, loss=4.3216, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [10:38<03:15,  3.38s/it, loss=4.3205, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [10:41<03:09,  3.33s/it, loss=4.3209, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [10:46<03:31,  3.78s/it, loss=4.3207, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [10:48<03:03,  3.34s/it, loss=4.3204, tokens/Max input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [10:51<02:48,  3.11s/it, loss=4.3198, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [10:53<02:33,  2.89s/it, loss=4.3188, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [10:56<02:34,  2.96s/it, loss=4.3176, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [10:59<02:32,  2.99s/it, loss=4.3172, tokens/Max input_id: 31977\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [11:03<02:47,  3.34s/it, loss=4.3163, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [11:09<03:19,  4.06s/it, loss=4.3168, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [11:15<03:46,  4.72s/it, loss=4.3178, tokens/Max input_id: 31963\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [11:18<03:14,  4.15s/it, loss=4.3172, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [11:21<02:48,  3.67s/it, loss=4.3169, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [11:24<02:39,  3.54s/it, loss=4.3177, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [11:28<02:37,  3.57s/it, loss=4.3179, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [11:32<02:48,  3.91s/it, loss=4.3183, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [11:35<02:24,  3.44s/it, loss=4.3185, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [11:37<02:08,  3.13s/it, loss=4.3183, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [11:41<02:19,  3.48s/it, loss=4.3178, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [11:45<02:15,  3.47s/it, loss=4.3164, tokens/Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [11:48<02:06,  3.32s/it, loss=4.3155, tokens/Max input_id: 31977\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [11:50<01:50,  2.97s/it, loss=4.3152, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [11:52<01:41,  2.83s/it, loss=4.3151, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [11:54<01:27,  2.50s/it, loss=4.3136, tokens/Max input_id: 31970\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [11:56<01:21,  2.39s/it, loss=4.3138, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [12:00<01:28,  2.67s/it, loss=4.3131, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [12:04<01:38,  3.08s/it, loss=4.3123, tokens/Max input_id: 31959\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [12:06<01:32,  2.98s/it, loss=4.3117, tokens/Max input_id: 31957\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [12:09<01:26,  2.90s/it, loss=4.3124, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [12:13<01:29,  3.09s/it, loss=4.3116, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [12:15<01:20,  2.89s/it, loss=4.3102, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [12:18<01:19,  2.93s/it, loss=4.3096, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [12:22<01:21,  3.12s/it, loss=4.3102, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [12:24<01:11,  2.84s/it, loss=4.3091, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [12:26<01:03,  2.63s/it, loss=4.3067, tokens/Max input_id: 31977\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [12:28<00:53,  2.34s/it, loss=4.3052, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [12:29<00:48,  2.20s/it, loss=4.3041, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [12:32<00:49,  2.38s/it, loss=4.3037, tokens/Max input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [12:34<00:45,  2.27s/it, loss=4.3030, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [12:39<00:57,  3.01s/it, loss=4.3023, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [13:13<03:42, 12.35s/it, loss=4.3015, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [13:15<02:36,  9.22s/it, loss=4.3004, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [13:22<02:14,  8.41s/it, loss=4.3001, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [13:24<01:38,  6.59s/it, loss=4.3004, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [13:30<01:28,  6.35s/it, loss=4.3013, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [13:32<01:07,  5.18s/it, loss=4.3005, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [13:35<00:52,  4.34s/it, loss=4.3000, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [13:37<00:42,  3.90s/it, loss=4.2998, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [13:40<00:34,  3.41s/it, loss=4.2995, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [13:42<00:27,  3.02s/it, loss=4.2994, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [13:45<00:23,  2.95s/it, loss=4.2997, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [13:47<00:19,  2.84s/it, loss=4.2986, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [13:50<00:16,  2.80s/it, loss=4.2984, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [13:52<00:12,  2.57s/it, loss=4.2976, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [13:55<00:10,  2.62s/it, loss=4.2966, tokens/Max input_id: 31963\n",
      "Max target_input: 31986\n",
      "Max label: 31986\n",
      "Training:  99%|█████████▉| 247/250 [13:59<00:09,  3.12s/it, loss=4.2978, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training:  99%|█████████▉| 248/250 [14:01<00:05,  2.90s/it, loss=4.2982, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Training: 100%|█████████▉| 249/250 [14:04<00:02,  2.72s/it, loss=4.2990, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training: 100%|██████████| 250/250 [14:21<00:00,  3.44s/it, loss=4.2997, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:06<03:27,  6.68s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:08<01:45,  3.53s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:09<01:13,  2.52s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:10<00:52,  1.88s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:11<00:44,  1.65s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:12<00:39,  1.52s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:13<00:33,  1.32s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:14<00:28,  1.21s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:15<00:28,  1.25s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:16<00:24,  1.10s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:17<00:22,  1.09s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:18<00:19,  1.05it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:19<00:19,  1.00s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:20<00:16,  1.10it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:21<00:15,  1.10it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:21<00:13,  1.17it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:22<00:13,  1.07it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:23<00:12,  1.13it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:39<01:08,  5.30s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:40<00:47,  3.97s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:40<00:32,  2.97s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:41<00:23,  2.36s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:42<00:17,  2.00s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:44<00:13,  1.74s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:44<00:10,  1.48s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:46<00:08,  1.42s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:47<00:07,  1.43s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [01:01<00:00,  1.92s/it]\n",
      "Removed old checkpoint: model_epoch_4.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_4.pt\n",
      "Saved training results to training_results_20250511_170503.csv\n",
      "Train Loss: 4.2997\n",
      "Val Loss: 4.6950\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: ?\n",
      "\n",
      "Epoch 5/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:09<37:28,  9.03s/it, loss=4.0338, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:13<25:24,  6.15s/it, loss=4.2340, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:15<17:27,  4.24s/it, loss=4.2513, tokens/s=Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:19<18:17,  4.46s/it, loss=4.1844, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:21<14:25,  3.53s/it, loss=4.1657, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:38<32:23,  7.97s/it, loss=4.1650, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:40<24:29,  6.05s/it, loss=4.1601, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:43<19:59,  4.95s/it, loss=4.1548, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:49<21:39,  5.39s/it, loss=4.1421, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:51<17:14,  4.31s/it, loss=4.1271, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:54<15:17,  3.84s/it, loss=4.1213, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:57<14:08,  3.57s/it, loss=4.1291, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:59<12:45,  3.23s/it, loss=4.1362, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [01:01<10:57,  2.79s/it, loss=4.1399, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [01:02<09:32,  2.44s/it, loss=4.1296, tokens/sMax input_id: 31969\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [01:04<08:35,  2.20s/it, loss=4.1212, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [01:06<08:43,  2.25s/it, loss=4.1309, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:08<08:27,  2.19s/it, loss=4.1270, tokens/sMax input_id: 31977\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:12<09:27,  2.45s/it, loss=4.1260, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:18<14:08,  3.69s/it, loss=4.1259, tokens/sMax input_id: 31978\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:20<12:19,  3.23s/it, loss=4.1218, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [10:05<10:06:53, 159.71s/it, loss=4.1351, tokeMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [10:07<7:05:24, 112.44s/it, loss=4.1269, tokenMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [10:10<4:59:16, 79.45s/it, loss=4.1284, tokensMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [10:14<3:33:50, 57.02s/it, loss=4.1328, tokensMax input_id: 31978\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [10:21<2:36:51, 42.02s/it, loss=4.1368, tokensMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [10:24<1:51:55, 30.11s/it, loss=4.1370, tokensMax input_id: 31970\n",
      "Max target_input: 31988\n",
      "Max label: 31988\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [10:29<1:24:28, 22.83s/it, loss=4.1472, tokensMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [10:32<1:02:00, 16.84s/it, loss=4.1482, tokensMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [10:35<45:42, 12.47s/it, loss=4.1479, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [10:37<34:50,  9.55s/it, loss=4.1536, tokens/sMax input_id: 31958\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [10:45<32:34,  8.97s/it, loss=4.1522, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [10:48<25:51,  7.15s/it, loss=4.1548, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [10:50<20:41,  5.75s/it, loss=4.1578, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [10:54<17:50,  4.98s/it, loss=4.1589, tokens/sMax input_id: 31957\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [10:56<14:56,  4.19s/it, loss=4.1607, tokens/sMax input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [10:59<13:27,  3.79s/it, loss=4.1620, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [11:01<11:35,  3.28s/it, loss=4.1594, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [11:04<11:42,  3.33s/it, loss=4.1572, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [11:07<10:51,  3.10s/it, loss=4.1535, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [11:27<28:38,  8.22s/it, loss=4.1517, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [11:30<22:49,  6.58s/it, loss=4.1529, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [11:34<20:20,  5.89s/it, loss=4.1534, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [11:36<16:33,  4.82s/it, loss=4.1502, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [11:40<15:10,  4.44s/it, loss=4.1526, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [11:42<12:47,  3.76s/it, loss=4.1543, tokens/sMax input_id: 31963\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [11:45<11:39,  3.45s/it, loss=4.1557, tokens/sMax input_id: 31969\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [11:50<13:34,  4.03s/it, loss=4.1526, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [11:53<12:06,  3.62s/it, loss=4.1516, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [11:56<11:09,  3.35s/it, loss=4.1565, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [12:01<13:05,  3.95s/it, loss=4.1614, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [12:03<11:30,  3.49s/it, loss=4.1624, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [12:06<10:43,  3.27s/it, loss=4.1598, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [12:12<13:29,  4.13s/it, loss=4.1637, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [12:29<26:14,  8.07s/it, loss=4.1644, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [12:33<21:44,  6.73s/it, loss=4.1603, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [12:35<17:09,  5.33s/it, loss=4.1577, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [12:39<15:57,  4.99s/it, loss=4.1585, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [12:41<13:01,  4.09s/it, loss=4.1582, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [12:44<11:56,  3.77s/it, loss=4.1565, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [12:47<11:06,  3.52s/it, loss=4.1538, tokens/sMax input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [12:50<10:06,  3.22s/it, loss=4.1494, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [12:52<09:08,  2.94s/it, loss=4.1455, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [12:57<11:11,  3.61s/it, loss=4.1460, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [13:00<10:11,  3.30s/it, loss=4.1407, tokens/sMax input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [13:04<11:15,  3.67s/it, loss=4.1393, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [13:06<09:45,  3.20s/it, loss=4.1379, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [13:09<09:10,  3.02s/it, loss=4.1361, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [13:12<08:49,  2.93s/it, loss=4.1356, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [13:28<20:38,  6.88s/it, loss=4.1370, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [13:31<17:08,  5.74s/it, loss=4.1366, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [13:33<13:52,  4.67s/it, loss=4.1357, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [13:35<11:19,  3.84s/it, loss=4.1334, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [13:37<09:33,  3.26s/it, loss=4.1344, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [13:39<08:21,  2.86s/it, loss=4.1321, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [13:42<08:17,  2.86s/it, loss=4.1320, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [13:44<07:59,  2.77s/it, loss=4.1330, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [13:50<10:13,  3.56s/it, loss=4.1342, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [13:52<09:22,  3.29s/it, loss=4.1351, tokens/sMax input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [13:55<08:55,  3.15s/it, loss=4.1361, tokens/sMax input_id: 31959\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [13:58<08:08,  2.89s/it, loss=4.1347, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [14:01<08:16,  2.96s/it, loss=4.1328, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [14:04<08:25,  3.03s/it, loss=4.1326, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [14:08<09:03,  3.27s/it, loss=4.1306, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [14:10<08:33,  3.11s/it, loss=4.1296, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [14:13<08:05,  2.96s/it, loss=4.1257, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [14:29<18:27,  6.79s/it, loss=4.1249, tokens/sMax input_id: 31969\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [14:31<14:47,  5.48s/it, loss=4.1235, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [14:38<15:28,  5.76s/it, loss=4.1263, tokens/sMax input_id: 31958\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [14:39<12:11,  4.57s/it, loss=4.1264, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [14:43<11:03,  4.17s/it, loss=4.1260, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [14:45<09:56,  3.77s/it, loss=4.1244, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [14:49<09:45,  3.73s/it, loss=4.1261, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [14:51<08:07,  3.13s/it, loss=4.1221, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [14:53<07:39,  2.97s/it, loss=4.1240, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [14:55<06:55,  2.70s/it, loss=4.1209, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [14:58<06:33,  2.57s/it, loss=4.1208, tokens/sMax input_id: 31968\n",
      "Max target_input: 31967\n",
      "Max label: 31967\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [15:02<08:01,  3.17s/it, loss=4.1238, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [15:05<07:26,  2.96s/it, loss=4.1200, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [15:12<10:20,  4.14s/it, loss=4.1226, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [15:14<08:45,  3.53s/it, loss=4.1210, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [15:31<18:36,  7.55s/it, loss=4.1191, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [15:34<15:33,  6.35s/it, loss=4.1174, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [15:37<13:04,  5.37s/it, loss=4.1186, tokens/Max input_id: 31938\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [15:40<10:38,  4.40s/it, loss=4.1181, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [15:43<10:05,  4.20s/it, loss=4.1172, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [15:46<08:59,  3.77s/it, loss=4.1171, tokens/Max input_id: 31963\n",
      "Max target_input: 31998\n",
      "Max label: 31998\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [15:48<07:57,  3.36s/it, loss=4.1174, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [15:51<07:08,  3.04s/it, loss=4.1180, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [15:55<07:50,  3.36s/it, loss=4.1155, tokens/Max input_id: 31970\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [15:57<07:18,  3.15s/it, loss=4.1167, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [16:00<06:48,  2.96s/it, loss=4.1157, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [16:08<10:12,  4.47s/it, loss=4.1163, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [16:10<08:39,  3.82s/it, loss=4.1156, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [16:12<07:23,  3.29s/it, loss=4.1155, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [16:32<18:05,  8.10s/it, loss=4.1147, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [16:38<16:53,  7.62s/it, loss=4.1149, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [16:45<15:58,  7.26s/it, loss=4.1156, tokens/Max input_id: 31959\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [16:48<13:12,  6.05s/it, loss=4.1171, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [16:50<10:22,  4.79s/it, loss=4.1165, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [16:52<08:52,  4.12s/it, loss=4.1178, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [16:55<07:54,  3.71s/it, loss=4.1196, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [16:58<07:16,  3.44s/it, loss=4.1191, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [17:00<06:14,  2.97s/it, loss=4.1168, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [17:03<06:28,  3.11s/it, loss=4.1162, tokens/Max input_id: 31958\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [17:06<06:24,  3.10s/it, loss=4.1156, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [17:08<05:33,  2.71s/it, loss=4.1142, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [17:11<05:46,  2.84s/it, loss=4.1132, tokens/Max input_id: 31970\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [17:13<05:19,  2.64s/it, loss=4.1129, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [17:16<05:14,  2.62s/it, loss=4.1128, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [17:32<13:14,  6.68s/it, loss=4.1143, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [17:34<10:20,  5.26s/it, loss=4.1125, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [17:36<08:09,  4.18s/it, loss=4.1120, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [17:41<08:40,  4.48s/it, loss=4.1113, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [17:44<07:56,  4.15s/it, loss=4.1106, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [17:47<07:03,  3.72s/it, loss=4.1107, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [17:49<06:09,  3.27s/it, loss=4.1100, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [17:52<06:02,  3.24s/it, loss=4.1090, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [17:54<05:21,  2.90s/it, loss=4.1090, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [17:57<05:01,  2.74s/it, loss=4.1095, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [18:00<05:25,  2.98s/it, loss=4.1077, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [18:02<04:53,  2.71s/it, loss=4.1083, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [18:06<05:18,  2.98s/it, loss=4.1082, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [18:09<05:08,  2.91s/it, loss=4.1068, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [18:14<06:12,  3.55s/it, loss=4.1069, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [18:16<05:39,  3.26s/it, loss=4.1067, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [18:33<12:16,  7.15s/it, loss=4.1054, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [18:35<09:37,  5.66s/it, loss=4.1066, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [18:37<08:02,  4.78s/it, loss=4.1062, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [18:42<07:55,  4.76s/it, loss=4.1063, tokens/Max input_id: 31977\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [18:45<06:59,  4.23s/it, loss=4.1070, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [18:50<07:20,  4.50s/it, loss=4.1072, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [18:53<06:13,  3.85s/it, loss=4.1069, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [18:57<06:33,  4.10s/it, loss=4.1067, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [18:59<05:31,  3.49s/it, loss=4.1059, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [19:03<05:21,  3.42s/it, loss=4.1069, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [19:06<05:05,  3.28s/it, loss=4.1066, tokens/Max input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [19:09<04:55,  3.21s/it, loss=4.1089, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [19:12<04:51,  3.20s/it, loss=4.1093, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [19:15<04:46,  3.18s/it, loss=4.1097, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [19:21<06:10,  4.17s/it, loss=4.1100, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [19:26<06:16,  4.27s/it, loss=4.1114, tokens/Max input_id: 31963\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [19:28<05:15,  3.62s/it, loss=4.1100, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [19:31<04:48,  3.35s/it, loss=4.1091, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [19:36<05:23,  3.80s/it, loss=4.1095, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [19:39<05:13,  3.73s/it, loss=4.1097, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [19:42<04:52,  3.52s/it, loss=4.1090, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [19:46<04:54,  3.59s/it, loss=4.1102, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [19:48<04:15,  3.15s/it, loss=4.1091, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [19:51<04:14,  3.18s/it, loss=4.1092, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [19:59<06:09,  4.67s/it, loss=4.1073, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [20:02<05:07,  3.94s/it, loss=4.1067, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [20:05<04:47,  3.74s/it, loss=4.1075, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [20:08<04:16,  3.38s/it, loss=4.1077, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [20:10<03:48,  3.05s/it, loss=4.1087, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [20:13<03:50,  3.12s/it, loss=4.1084, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [20:16<03:39,  3.01s/it, loss=4.1091, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [20:18<03:27,  2.88s/it, loss=4.1085, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [20:21<03:25,  2.90s/it, loss=4.1092, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [20:24<03:21,  2.88s/it, loss=4.1092, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [20:27<03:08,  2.72s/it, loss=4.1083, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [20:34<04:41,  4.14s/it, loss=4.1070, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [20:37<04:20,  3.89s/it, loss=4.1069, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [20:40<04:00,  3.65s/it, loss=4.1062, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [20:43<03:37,  3.34s/it, loss=4.1067, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [20:48<03:56,  3.70s/it, loss=4.1062, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [20:50<03:21,  3.20s/it, loss=4.1052, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [20:53<03:24,  3.30s/it, loss=4.1044, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [20:58<03:55,  3.86s/it, loss=4.1038, tokens/Max input_id: 31964\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [21:06<04:58,  4.97s/it, loss=4.1033, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [21:11<04:50,  4.93s/it, loss=4.1036, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [21:15<04:32,  4.70s/it, loss=4.1025, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [21:19<04:17,  4.51s/it, loss=4.1027, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [21:24<04:17,  4.60s/it, loss=4.1026, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [21:28<04:04,  4.45s/it, loss=4.1024, tokens/Max input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [21:33<04:06,  4.56s/it, loss=4.1016, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [21:37<03:57,  4.47s/it, loss=4.1004, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [21:43<04:15,  4.92s/it, loss=4.0990, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [21:49<04:22,  5.15s/it, loss=4.0984, tokens/Max input_id: 31977\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [21:56<04:58,  5.97s/it, loss=4.0973, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [22:06<05:42,  7.00s/it, loss=4.0978, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [22:15<06:11,  7.74s/it, loss=4.0985, tokens/Max input_id: 31963\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [22:20<05:20,  6.82s/it, loss=4.0977, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [22:24<04:36,  6.01s/it, loss=4.0974, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [22:32<04:50,  6.46s/it, loss=4.0979, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [22:55<08:33, 11.68s/it, loss=4.0981, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [23:00<06:53,  9.61s/it, loss=4.0987, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [23:03<05:12,  7.44s/it, loss=4.0988, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [23:05<04:07,  6.03s/it, loss=4.0986, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [23:10<03:44,  5.60s/it, loss=4.0980, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [23:14<03:18,  5.09s/it, loss=4.0967, tokens/Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [23:17<02:52,  4.53s/it, loss=4.0955, tokens/Max input_id: 31977\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [23:19<02:21,  3.84s/it, loss=4.0952, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [23:22<02:04,  3.46s/it, loss=4.0952, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [23:24<01:46,  3.03s/it, loss=4.0938, tokens/Max input_id: 31970\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [23:27<01:41,  2.98s/it, loss=4.0938, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [23:32<02:02,  3.72s/it, loss=4.0934, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [23:36<01:58,  3.71s/it, loss=4.0928, tokens/Max input_id: 31959\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [23:39<01:47,  3.46s/it, loss=4.0922, tokens/Max input_id: 31957\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [23:42<01:38,  3.30s/it, loss=4.0929, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [23:45<01:36,  3.33s/it, loss=4.0922, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [23:48<01:29,  3.19s/it, loss=4.0908, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [23:51<01:26,  3.20s/it, loss=4.0903, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [23:56<01:33,  3.59s/it, loss=4.0908, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [23:58<01:21,  3.25s/it, loss=4.0899, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [24:01<01:11,  3.00s/it, loss=4.0875, tokens/Max input_id: 31977\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [24:03<01:02,  2.71s/it, loss=4.0862, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [24:05<01:00,  2.74s/it, loss=4.0849, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [24:11<01:13,  3.51s/it, loss=4.0846, tokens/Max input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [24:13<01:02,  3.11s/it, loss=4.0839, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [24:18<01:08,  3.63s/it, loss=4.0835, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [24:24<01:18,  4.39s/it, loss=4.0828, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [24:26<01:04,  3.81s/it, loss=4.0818, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [24:33<01:14,  4.65s/it, loss=4.0813, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [24:36<01:02,  4.15s/it, loss=4.0817, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [24:43<01:09,  4.95s/it, loss=4.0829, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [24:46<00:56,  4.38s/it, loss=4.0824, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [24:49<00:48,  4.03s/it, loss=4.0820, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [24:55<00:52,  4.75s/it, loss=4.0821, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [25:00<00:47,  4.79s/it, loss=4.0817, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [25:04<00:40,  4.53s/it, loss=4.0816, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [25:11<00:40,  5.07s/it, loss=4.0821, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [25:15<00:35,  5.01s/it, loss=4.0812, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [25:20<00:29,  4.96s/it, loss=4.0809, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [25:24<00:23,  4.61s/it, loss=4.0802, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [25:30<00:19,  4.91s/it, loss=4.0792, tokens/Max input_id: 31963\n",
      "Max target_input: 31986\n",
      "Max label: 31986\n",
      "Training:  99%|█████████▉| 247/250 [25:35<00:15,  5.15s/it, loss=4.0804, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training:  99%|█████████▉| 248/250 [25:40<00:09,  4.90s/it, loss=4.0805, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Training: 100%|█████████▉| 249/250 [25:44<00:04,  4.85s/it, loss=4.0812, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training: 100%|██████████| 250/250 [26:06<00:00,  6.27s/it, loss=4.0819, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size:Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      " 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:12<06:25, 12.43s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:14<03:14,  6.49s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:17<02:13,  4.60s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:18<01:35,  3.40s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:20<01:17,  2.89s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:22<01:06,  2.56s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:24<00:55,  2.23s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:25<00:49,  2.05s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:28<00:49,  2.17s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:29<00:42,  1.94s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:31<00:41,  1.99s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:33<00:35,  1.77s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:35<00:36,  1.90s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:36<00:32,  1.78s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:38<00:30,  1.81s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:40<00:27,  1.71s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:42<00:27,  1.86s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:43<00:25,  1.79s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:45<00:23,  1.81s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:47<00:21,  1.80s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:48<00:18,  1.69s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:51<00:18,  1.81s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:54<00:19,  2.21s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:56<00:18,  2.26s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:58<00:15,  2.15s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [01:01<00:13,  2.27s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [01:02<00:10,  2.12s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [01:18<00:00,  2.47s/it]\n",
      "Removed old checkpoint: model_epoch_5.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_5.pt\n",
      "Saved training results to training_results_20250511_173231.csv\n",
      "Train Loss: 4.0819\n",
      "Val Loss: 4.6384\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: this is the European Parliament?\n",
      "\n",
      "Epoch 6/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size:Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      " 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:17<1:11:31, 17.24s/it, loss=3.8244, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:24<46:07, 11.16s/it, loss=4.0225, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:27<31:32,  7.66s/it, loss=4.0171, tokens/s=Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:35<32:02,  7.81s/it, loss=3.9636, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:38<25:06,  6.15s/it, loss=3.9465, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:45<26:06,  6.42s/it, loss=3.9520, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:49<22:08,  5.47s/it, loss=3.9372, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:53<20:24,  5.06s/it, loss=3.9302, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [01:02<25:02,  6.24s/it, loss=3.9190, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [01:06<22:47,  5.70s/it, loss=3.9031, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [01:14<25:04,  6.30s/it, loss=3.8980, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [01:22<26:42,  6.74s/it, loss=3.9085, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [01:27<24:29,  6.20s/it, loss=3.9164, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [01:30<21:19,  5.42s/it, loss=3.9190, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [01:34<18:44,  4.78s/it, loss=3.9045, tokens/sMax input_id: 31969\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [01:37<17:16,  4.43s/it, loss=3.8981, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [01:42<17:35,  4.53s/it, loss=3.9067, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:46<17:09,  4.44s/it, loss=3.9044, tokens/sMax input_id: 31977\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:53<20:16,  5.26s/it, loss=3.9055, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [02:07<29:32,  7.70s/it, loss=3.9045, tokens/sMax input_id: 31978\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [02:11<24:53,  6.52s/it, loss=3.8992, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [02:16<24:00,  6.32s/it, loss=3.9126, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [02:20<20:28,  5.41s/it, loss=3.9042, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [02:24<18:59,  5.04s/it, loss=3.9051, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [02:30<19:47,  5.28s/it, loss=3.9103, tokens/sMax input_id: 31978\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [02:40<25:07,  6.73s/it, loss=3.9144, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [02:43<21:29,  5.78s/it, loss=3.9155, tokens/sMax input_id: 31970\n",
      "Max target_input: 31988\n",
      "Max label: 31988\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [02:52<24:02,  6.50s/it, loss=3.9266, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [02:57<22:53,  6.21s/it, loss=3.9273, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [03:01<19:52,  5.42s/it, loss=3.9276, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [03:06<19:10,  5.25s/it, loss=3.9338, tokens/sMax input_id: 31958\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [03:15<23:27,  6.45s/it, loss=3.9336, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [03:19<20:43,  5.73s/it, loss=3.9370, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [03:22<18:20,  5.09s/it, loss=3.9405, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [03:27<17:31,  4.89s/it, loss=3.9412, tokens/sMax input_id: 31957\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [03:30<16:01,  4.49s/it, loss=3.9428, tokens/sMax input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [03:34<15:27,  4.35s/it, loss=3.9444, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [03:38<14:12,  4.02s/it, loss=3.9411, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [03:44<16:04,  4.57s/it, loss=3.9389, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [03:48<16:08,  4.61s/it, loss=3.9357, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [03:52<15:06,  4.34s/it, loss=3.9338, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [03:56<14:50,  4.28s/it, loss=3.9359, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [04:02<16:21,  4.74s/it, loss=3.9365, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [04:05<14:56,  4.35s/it, loss=3.9328, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [04:10<14:42,  4.30s/it, loss=3.9364, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [04:13<13:40,  4.02s/it, loss=3.9383, tokens/sMax input_id: 31963\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [04:17<13:20,  3.94s/it, loss=3.9399, tokens/sMax input_id: 31969\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [04:24<16:54,  5.02s/it, loss=3.9383, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [04:30<17:32,  5.24s/it, loss=3.9392, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [04:36<18:03,  5.42s/it, loss=3.9432, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [04:44<20:25,  6.16s/it, loss=3.9493, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [04:47<17:39,  5.35s/it, loss=3.9512, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [04:51<16:20,  4.98s/it, loss=3.9487, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [04:59<18:28,  5.65s/it, loss=3.9528, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [05:03<16:49,  5.17s/it, loss=3.9531, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [05:07<15:54,  4.92s/it, loss=3.9487, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [05:10<14:11,  4.41s/it, loss=3.9452, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [05:16<15:46,  4.93s/it, loss=3.9467, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [05:20<14:29,  4.55s/it, loss=3.9466, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [05:27<16:20,  5.16s/it, loss=3.9444, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [05:32<16:10,  5.14s/it, loss=3.9422, tokens/sMax input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [05:35<14:51,  4.74s/it, loss=3.9384, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [05:39<13:34,  4.36s/it, loss=3.9349, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [05:46<16:19,  5.27s/it, loss=3.9362, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [05:50<15:12,  4.93s/it, loss=3.9311, tokens/sMax input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [05:57<16:34,  5.41s/it, loss=3.9303, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [06:00<14:27,  4.74s/it, loss=3.9291, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [06:04<13:22,  4.41s/it, loss=3.9273, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [06:08<13:15,  4.39s/it, loss=3.9268, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [06:12<13:06,  4.37s/it, loss=3.9287, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [06:18<14:20,  4.81s/it, loss=3.9279, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [06:22<13:04,  4.41s/it, loss=3.9266, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [06:25<11:47,  4.00s/it, loss=3.9245, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [06:28<10:49,  3.69s/it, loss=3.9261, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [06:31<10:08,  3.48s/it, loss=3.9235, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [06:37<12:16,  4.23s/it, loss=3.9235, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [06:41<12:09,  4.22s/it, loss=3.9241, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [06:47<14:00,  4.89s/it, loss=3.9252, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [06:52<13:32,  4.75s/it, loss=3.9266, tokens/sMax input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [06:58<14:30,  5.12s/it, loss=3.9277, tokens/sMax input_id: 31959\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [07:01<12:52,  4.57s/it, loss=3.9258, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [07:06<13:29,  4.82s/it, loss=3.9241, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [07:11<13:16,  4.77s/it, loss=3.9237, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [07:16<13:24,  4.85s/it, loss=3.9212, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [07:20<12:31,  4.55s/it, loss=3.9206, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [07:23<11:32,  4.22s/it, loss=3.9168, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [07:26<10:18,  3.79s/it, loss=3.9158, tokens/sMax input_id: 31969\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [07:30<09:51,  3.65s/it, loss=3.9146, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [07:38<13:50,  5.16s/it, loss=3.9174, tokens/sMax input_id: 31958\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [07:41<12:13,  4.58s/it, loss=3.9170, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [07:47<13:01,  4.92s/it, loss=3.9171, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [07:52<12:48,  4.87s/it, loss=3.9157, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [07:57<12:43,  4.86s/it, loss=3.9168, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [07:59<10:51,  4.17s/it, loss=3.9128, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [08:03<10:24,  4.03s/it, loss=3.9151, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [08:06<09:35,  3.74s/it, loss=3.9117, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [08:09<09:14,  3.63s/it, loss=3.9116, tokens/sMax input_id: 31968\n",
      "Max target_input: 31967\n",
      "Max label: 31967\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [08:15<11:00,  4.34s/it, loss=3.9147, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [08:19<10:25,  4.15s/it, loss=3.9116, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [08:29<14:20,  5.74s/it, loss=3.9141, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [08:32<12:34,  5.06s/it, loss=3.9122, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [08:37<12:12,  4.95s/it, loss=3.9096, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [08:42<12:06,  4.94s/it, loss=3.9074, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [08:46<11:33,  4.75s/it, loss=3.9087, tokens/Max input_id: 31938\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [08:49<10:31,  4.35s/it, loss=3.9087, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [08:55<11:37,  4.84s/it, loss=3.9076, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [09:00<11:12,  4.70s/it, loss=3.9070, tokens/Max input_id: 31963\n",
      "Max target_input: 31998\n",
      "Max label: 31998\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [09:04<10:30,  4.44s/it, loss=3.9071, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [09:07<09:49,  4.18s/it, loss=3.9075, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [09:14<11:22,  4.87s/it, loss=3.9047, tokens/Max input_id: 31970\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [09:18<11:11,  4.83s/it, loss=3.9056, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [09:23<11:01,  4.79s/it, loss=3.9045, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [09:32<14:01,  6.14s/it, loss=3.9050, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [09:36<12:24,  5.47s/it, loss=3.9042, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [09:39<10:45,  4.78s/it, loss=3.9041, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [09:45<11:16,  5.05s/it, loss=3.9034, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [09:54<13:27,  6.07s/it, loss=3.9037, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [10:03<15:30,  7.05s/it, loss=3.9043, tokens/Max input_id: 31959\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [10:08<13:50,  6.34s/it, loss=3.9059, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [10:11<11:33,  5.33s/it, loss=3.9055, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [10:15<10:50,  5.04s/it, loss=3.9065, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [10:19<10:17,  4.82s/it, loss=3.9083, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [10:24<09:58,  4.72s/it, loss=3.9078, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [10:27<08:39,  4.12s/it, loss=3.9056, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [10:31<08:48,  4.23s/it, loss=3.9052, tokens/Max input_id: 31958\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [10:35<08:37,  4.18s/it, loss=3.9050, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [10:38<07:48,  3.81s/it, loss=3.9036, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [10:42<08:06,  3.99s/it, loss=3.9025, tokens/Max input_id: 31970\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [10:45<07:25,  3.68s/it, loss=3.9021, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [10:49<07:08,  3.57s/it, loss=3.9021, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [10:53<07:27,  3.76s/it, loss=3.9036, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [10:56<07:12,  3.67s/it, loss=3.9016, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [10:59<06:33,  3.36s/it, loss=3.9009, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [11:06<08:47,  4.55s/it, loss=3.9001, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [11:11<08:57,  4.68s/it, loss=3.8994, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [11:15<08:21,  4.40s/it, loss=3.8991, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [11:18<07:29,  3.97s/it, loss=3.8986, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [11:22<07:12,  3.86s/it, loss=3.8974, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [11:25<06:40,  3.61s/it, loss=3.8970, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [11:28<06:24,  3.50s/it, loss=3.8977, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [11:33<07:25,  4.08s/it, loss=3.8961, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [11:37<06:57,  3.87s/it, loss=3.8962, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [11:43<08:02,  4.51s/it, loss=3.8961, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [11:46<07:35,  4.30s/it, loss=3.8948, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [11:53<08:37,  4.93s/it, loss=3.8951, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [11:56<07:48,  4.51s/it, loss=3.8951, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [11:59<06:57,  4.05s/it, loss=3.8936, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [12:02<06:21,  3.74s/it, loss=3.8946, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [12:06<06:19,  3.76s/it, loss=3.8943, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [12:14<08:17,  4.98s/it, loss=3.8946, tokens/Max input_id: 31977\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [12:18<07:48,  4.74s/it, loss=3.8953, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [12:24<08:23,  5.14s/it, loss=3.8955, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [12:28<07:23,  4.57s/it, loss=3.8950, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [12:33<07:54,  4.94s/it, loss=3.8949, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [12:37<06:59,  4.41s/it, loss=3.8940, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [12:40<06:38,  4.24s/it, loss=3.8948, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [12:44<06:29,  4.19s/it, loss=3.8942, tokens/Max input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [12:48<06:17,  4.10s/it, loss=3.8963, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [12:53<06:31,  4.30s/it, loss=3.8966, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [12:58<06:44,  4.49s/it, loss=3.8976, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [13:05<07:49,  5.28s/it, loss=3.8979, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [13:09<07:17,  4.97s/it, loss=3.8993, tokens/Max input_id: 31963\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [13:12<06:17,  4.34s/it, loss=3.8979, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [13:16<05:47,  4.04s/it, loss=3.8972, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [13:20<06:01,  4.25s/it, loss=3.8977, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [13:25<05:59,  4.28s/it, loss=3.8978, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [13:28<05:41,  4.11s/it, loss=3.8972, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [13:33<05:41,  4.16s/it, loss=3.8983, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [13:35<05:02,  3.74s/it, loss=3.8972, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [13:41<05:33,  4.17s/it, loss=3.8972, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [13:49<07:12,  5.47s/it, loss=3.8955, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [13:52<06:02,  4.65s/it, loss=3.8949, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [13:55<05:33,  4.34s/it, loss=3.8958, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [13:58<04:58,  3.93s/it, loss=3.8959, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [14:01<04:25,  3.54s/it, loss=3.8971, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [14:05<04:25,  3.59s/it, loss=3.8970, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [14:08<04:16,  3.51s/it, loss=3.8977, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [14:11<03:58,  3.31s/it, loss=3.8975, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [14:15<04:03,  3.43s/it, loss=3.8984, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [14:19<04:14,  3.63s/it, loss=3.8985, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [14:22<03:52,  3.37s/it, loss=3.8973, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [14:30<05:36,  4.95s/it, loss=3.8965, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [14:33<04:56,  4.42s/it, loss=3.8966, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [14:37<04:33,  4.14s/it, loss=3.8959, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [14:40<04:05,  3.78s/it, loss=3.8966, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [14:44<04:08,  3.88s/it, loss=3.8965, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [14:46<03:36,  3.44s/it, loss=3.8957, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [14:50<03:36,  3.49s/it, loss=3.8949, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [14:54<03:37,  3.56s/it, loss=3.8942, tokens/Max input_id: 31964\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [15:04<05:38,  5.63s/it, loss=3.8938, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [15:09<05:11,  5.27s/it, loss=3.8942, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [15:12<04:38,  4.79s/it, loss=3.8930, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [15:16<04:11,  4.42s/it, loss=3.8931, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [15:20<04:03,  4.35s/it, loss=3.8930, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [15:23<03:39,  4.00s/it, loss=3.8927, tokens/Max input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [15:27<03:31,  3.92s/it, loss=3.8918, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [15:30<03:19,  3.77s/it, loss=3.8908, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [15:34<03:22,  3.89s/it, loss=3.8895, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [15:40<03:50,  4.52s/it, loss=3.8892, tokens/Max input_id: 31977\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [15:47<04:22,  5.24s/it, loss=3.8882, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [15:55<04:48,  5.88s/it, loss=3.8887, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [16:02<05:04,  6.34s/it, loss=3.8895, tokens/Max input_id: 31963\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [16:06<04:25,  5.64s/it, loss=3.8885, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [16:10<03:52,  5.05s/it, loss=3.8878, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [16:14<03:36,  4.81s/it, loss=3.8884, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [16:18<03:22,  4.61s/it, loss=3.8886, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [16:22<03:14,  4.52s/it, loss=3.8894, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [16:26<02:54,  4.16s/it, loss=3.8896, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [16:30<02:49,  4.14s/it, loss=3.8896, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [16:36<03:05,  4.63s/it, loss=3.8889, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [16:42<03:16,  5.03s/it, loss=3.8874, tokens/Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [16:46<03:08,  4.96s/it, loss=3.8862, tokens/Max input_id: 31977\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [16:49<02:41,  4.36s/it, loss=3.8857, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [16:53<02:28,  4.14s/it, loss=3.8857, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [16:56<02:09,  3.70s/it, loss=3.8845, tokens/Max input_id: 31970\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [16:59<02:00,  3.55s/it, loss=3.8842, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [17:04<02:08,  3.88s/it, loss=3.8838, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [17:08<02:11,  4.10s/it, loss=3.8833, tokens/Max input_id: 31959\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [17:13<02:09,  4.19s/it, loss=3.8828, tokens/Max input_id: 31957\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [17:16<02:00,  4.01s/it, loss=3.8834, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [17:21<02:04,  4.28s/it, loss=3.8828, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [17:25<01:53,  4.06s/it, loss=3.8813, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [17:29<01:48,  4.03s/it, loss=3.8807, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [17:33<01:51,  4.28s/it, loss=3.8813, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [17:37<01:41,  4.05s/it, loss=3.8802, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [17:40<01:30,  3.78s/it, loss=3.8779, tokens/Max input_id: 31977\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [17:43<01:17,  3.38s/it, loss=3.8763, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [17:46<01:13,  3.34s/it, loss=3.8751, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [17:51<01:20,  3.82s/it, loss=3.8752, tokens/Max input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [17:53<01:09,  3.47s/it, loss=3.8743, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [17:59<01:17,  4.09s/it, loss=3.8739, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [18:06<01:31,  5.06s/it, loss=3.8735, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [18:09<01:14,  4.38s/it, loss=3.8728, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [18:16<01:22,  5.13s/it, loss=3.8724, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [18:19<01:09,  4.65s/it, loss=3.8729, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [18:27<01:16,  5.47s/it, loss=3.8742, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [18:31<01:05,  5.05s/it, loss=3.8738, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [18:35<00:58,  4.84s/it, loss=3.8737, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [18:42<00:58,  5.31s/it, loss=3.8741, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [18:45<00:47,  4.75s/it, loss=3.8739, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [18:48<00:38,  4.27s/it, loss=3.8738, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [18:53<00:34,  4.31s/it, loss=3.8745, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [18:56<00:28,  4.03s/it, loss=3.8737, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [19:00<00:23,  3.95s/it, loss=3.8735, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [19:03<00:18,  3.70s/it, loss=3.8729, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [19:07<00:15,  3.91s/it, loss=3.8721, tokens/Max input_id: 31963\n",
      "Max target_input: 31986\n",
      "Max label: 31986\n",
      "Training:  99%|█████████▉| 247/250 [19:12<00:12,  4.01s/it, loss=3.8732, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training:  99%|█████████▉| 248/250 [19:15<00:07,  3.98s/it, loss=3.8733, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Training: 100%|█████████▉| 249/250 [19:19<00:03,  3.97s/it, loss=3.8741, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training: 100%|██████████| 250/250 [19:38<00:00,  4.71s/it, loss=3.8747, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:06<03:19,  6.45s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:07<01:43,  3.44s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:09<01:11,  2.47s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:09<00:50,  1.81s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:11<00:42,  1.57s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:12<00:36,  1.42s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:13<00:31,  1.26s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:14<00:29,  1.23s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:16<00:32,  1.40s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:17<00:30,  1.38s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:19<00:31,  1.51s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:20<00:30,  1.53s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:22<00:29,  1.54s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:23<00:24,  1.38s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:24<00:22,  1.34s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:25<00:19,  1.25s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:27<00:20,  1.34s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:28<00:18,  1.30s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:29<00:16,  1.29s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:30<00:15,  1.26s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:31<00:12,  1.17s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:33<00:11,  1.20s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:34<00:11,  1.33s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:36<00:11,  1.44s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:37<00:09,  1.38s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:39<00:09,  1.53s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:40<00:07,  1.51s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:55<00:00,  1.74s/it]\n",
      "Removed old checkpoint: model_epoch_6.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_6.pt\n",
      "Saved training results to training_results_20250511_175307.csv\n",
      "Train Loss: 3.8747\n",
      "Val Loss: 4.6204\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: this is the European Parliament?\n",
      "\n",
      "Epoch 7/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:08<37:11,  8.96s/it, loss=3.6673, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:13<25:45,  6.23s/it, loss=3.8557, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:15<17:35,  4.27s/it, loss=3.8359, tokens/s=Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:22<21:49,  5.32s/it, loss=3.7944, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:24<17:51,  4.37s/it, loss=3.7701, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:30<19:08,  4.71s/it, loss=3.7726, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:33<17:01,  4.20s/it, loss=3.7537, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:36<16:06,  3.99s/it, loss=3.7477, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:43<18:42,  4.66s/it, loss=3.7421, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:45<16:13,  4.06s/it, loss=3.7232, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:49<15:48,  3.97s/it, loss=3.7202, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:53<16:19,  4.11s/it, loss=3.7297, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:57<16:03,  4.07s/it, loss=3.7371, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [01:01<15:03,  3.83s/it, loss=3.7412, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [01:03<13:18,  3.40s/it, loss=3.7256, tokens/sMax input_id: 31969\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [01:05<12:04,  3.10s/it, loss=3.7164, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [01:09<12:22,  3.19s/it, loss=3.7226, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:12<11:54,  3.08s/it, loss=3.7197, tokens/sMax input_id: 31977\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:17<14:09,  3.68s/it, loss=3.7161, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:24<18:42,  4.88s/it, loss=3.7157, tokens/sMax input_id: 31978\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:27<16:30,  4.32s/it, loss=3.7104, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:32<16:04,  4.23s/it, loss=3.7248, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:35<15:23,  4.07s/it, loss=3.7160, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:40<15:49,  4.20s/it, loss=3.7156, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:48<20:26,  5.45s/it, loss=3.7192, tokens/sMax input_id: 31978\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:56<23:31,  6.30s/it, loss=3.7246, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:59<19:19,  5.20s/it, loss=3.7261, tokens/sMax input_id: 31970\n",
      "Max target_input: 31988\n",
      "Max label: 31988\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [02:06<20:56,  5.66s/it, loss=3.7376, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [02:10<18:52,  5.13s/it, loss=3.7393, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [02:12<15:35,  4.25s/it, loss=3.7407, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [02:15<14:02,  3.85s/it, loss=3.7472, tokens/sMax input_id: 31958\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [02:21<17:06,  4.71s/it, loss=3.7470, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [02:24<15:08,  4.19s/it, loss=3.7494, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:27<13:14,  3.68s/it, loss=3.7518, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:30<12:29,  3.49s/it, loss=3.7510, tokens/sMax input_id: 31957\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:33<12:10,  3.42s/it, loss=3.7529, tokens/sMax input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:36<11:30,  3.24s/it, loss=3.7542, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:38<10:18,  2.92s/it, loss=3.7512, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:42<10:42,  3.04s/it, loss=3.7489, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:44<10:18,  2.94s/it, loss=3.7464, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:47<09:52,  2.83s/it, loss=3.7436, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:50<09:52,  2.85s/it, loss=3.7438, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:53<10:36,  3.07s/it, loss=3.7454, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:56<10:30,  3.06s/it, loss=3.7423, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [02:59<10:21,  3.03s/it, loss=3.7446, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [03:02<09:35,  2.82s/it, loss=3.7473, tokens/sMax input_id: 31963\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [03:04<09:28,  2.80s/it, loss=3.7485, tokens/sMax input_id: 31969\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [03:10<11:49,  3.51s/it, loss=3.7452, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [03:12<10:59,  3.28s/it, loss=3.7450, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [03:15<10:30,  3.15s/it, loss=3.7500, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [03:22<14:06,  4.25s/it, loss=3.7560, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:24<12:15,  3.72s/it, loss=3.7567, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:27<11:15,  3.43s/it, loss=3.7545, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:32<12:33,  3.84s/it, loss=3.7579, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:35<11:28,  3.53s/it, loss=3.7572, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:38<10:53,  3.37s/it, loss=3.7522, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:40<09:39,  3.00s/it, loss=3.7474, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:45<11:36,  3.63s/it, loss=3.7493, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:47<10:01,  3.15s/it, loss=3.7489, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [03:51<10:52,  3.43s/it, loss=3.7467, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [03:54<10:23,  3.30s/it, loss=3.7453, tokens/sMax input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [03:57<09:36,  3.07s/it, loss=3.7410, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [03:59<08:47,  2.82s/it, loss=3.7365, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [04:04<11:07,  3.59s/it, loss=3.7379, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [04:07<10:09,  3.29s/it, loss=3.7326, tokens/sMax input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [04:12<11:55,  3.89s/it, loss=3.7309, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [04:14<10:10,  3.34s/it, loss=3.7301, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [04:17<09:13,  3.04s/it, loss=3.7276, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [04:19<08:44,  2.90s/it, loss=3.7278, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [04:21<08:08,  2.72s/it, loss=3.7298, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:25<08:25,  2.83s/it, loss=3.7288, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:27<07:52,  2.66s/it, loss=3.7276, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:29<07:11,  2.44s/it, loss=3.7256, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:31<07:16,  2.48s/it, loss=3.7273, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [04:33<06:47,  2.33s/it, loss=3.7244, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [04:36<07:06,  2.45s/it, loss=3.7243, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [04:39<07:08,  2.48s/it, loss=3.7248, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [04:42<07:53,  2.76s/it, loss=3.7262, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [04:44<07:38,  2.68s/it, loss=3.7273, tokens/sMax input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [04:47<07:33,  2.67s/it, loss=3.7289, tokens/sMax input_id: 31959\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [04:50<07:40,  2.73s/it, loss=3.7269, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [04:53<07:49,  2.80s/it, loss=3.7250, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [04:56<07:59,  2.87s/it, loss=3.7253, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [04:59<08:28,  3.06s/it, loss=3.7234, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [05:02<08:06,  2.95s/it, loss=3.7224, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [05:05<07:37,  2.79s/it, loss=3.7181, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [05:06<06:45,  2.49s/it, loss=3.7164, tokens/sMax input_id: 31969\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [05:09<06:36,  2.45s/it, loss=3.7146, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [05:15<10:02,  3.74s/it, loss=3.7176, tokens/sMax input_id: 31958\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [05:17<08:27,  3.17s/it, loss=3.7170, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [05:20<08:02,  3.04s/it, loss=3.7168, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [05:23<07:38,  2.90s/it, loss=3.7154, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [05:25<07:34,  2.90s/it, loss=3.7164, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [05:27<06:28,  2.49s/it, loss=3.7119, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [05:29<06:19,  2.45s/it, loss=3.7145, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [05:32<06:34,  2.56s/it, loss=3.7112, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [05:34<06:08,  2.41s/it, loss=3.7105, tokens/sMax input_id: 31968\n",
      "Max target_input: 31967\n",
      "Max label: 31967\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [05:39<07:56,  3.14s/it, loss=3.7136, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [05:41<07:17,  2.90s/it, loss=3.7112, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [05:48<10:00,  4.00s/it, loss=3.7138, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [05:50<08:24,  3.39s/it, loss=3.7114, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [05:52<07:30,  3.05s/it, loss=3.7096, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [05:55<07:04,  2.89s/it, loss=3.7078, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [05:58<07:29,  3.08s/it, loss=3.7091, tokens/Max input_id: 31938\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [06:00<06:46,  2.81s/it, loss=3.7085, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [06:05<07:44,  3.22s/it, loss=3.7077, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [06:07<07:24,  3.11s/it, loss=3.7075, tokens/Max input_id: 31963\n",
      "Max target_input: 31998\n",
      "Max label: 31998\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [06:10<06:52,  2.91s/it, loss=3.7079, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [06:12<06:23,  2.72s/it, loss=3.7087, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [06:17<07:33,  3.24s/it, loss=3.7054, tokens/Max input_id: 31970\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [06:19<07:08,  3.08s/it, loss=3.7067, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [06:23<07:10,  3.12s/it, loss=3.7057, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [06:30<09:48,  4.29s/it, loss=3.7066, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [06:32<08:21,  3.69s/it, loss=3.7060, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [06:34<07:12,  3.21s/it, loss=3.7058, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [06:37<07:05,  3.18s/it, loss=3.7052, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [06:43<08:40,  3.91s/it, loss=3.7057, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [06:49<10:16,  4.67s/it, loss=3.7061, tokens/Max input_id: 31959\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [06:53<09:47,  4.49s/it, loss=3.7078, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [06:55<07:56,  3.66s/it, loss=3.7073, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [06:57<07:04,  3.29s/it, loss=3.7085, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [07:00<06:41,  3.13s/it, loss=3.7104, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [07:03<06:38,  3.14s/it, loss=3.7100, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [07:05<05:46,  2.75s/it, loss=3.7077, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [07:08<05:49,  2.79s/it, loss=3.7070, tokens/Max input_id: 31958\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [07:11<06:12,  3.00s/it, loss=3.7070, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [07:13<05:22,  2.62s/it, loss=3.7051, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [07:16<05:27,  2.68s/it, loss=3.7039, tokens/Max input_id: 31970\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [07:18<05:00,  2.48s/it, loss=3.7036, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [07:20<04:51,  2.43s/it, loss=3.7033, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [07:23<04:53,  2.47s/it, loss=3.7048, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [07:25<04:30,  2.29s/it, loss=3.7025, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [07:27<04:08,  2.13s/it, loss=3.7012, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [07:33<06:35,  3.41s/it, loss=3.7007, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [07:36<06:22,  3.32s/it, loss=3.6998, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [07:38<05:47,  3.05s/it, loss=3.6993, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [07:40<05:09,  2.73s/it, loss=3.6985, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [07:43<04:57,  2.66s/it, loss=3.6967, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [07:45<04:36,  2.49s/it, loss=3.6961, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [07:47<04:20,  2.36s/it, loss=3.6964, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [07:50<04:31,  2.49s/it, loss=3.6947, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [07:53<04:37,  2.57s/it, loss=3.6947, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [07:56<04:44,  2.66s/it, loss=3.6948, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [07:58<04:36,  2.61s/it, loss=3.6936, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [08:04<06:10,  3.53s/it, loss=3.6939, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [08:06<05:31,  3.19s/it, loss=3.6936, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [08:08<04:49,  2.81s/it, loss=3.6917, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [08:10<04:23,  2.59s/it, loss=3.6924, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [08:14<04:50,  2.88s/it, loss=3.6922, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [08:18<05:44,  3.45s/it, loss=3.6922, tokens/Max input_id: 31977\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [08:21<05:17,  3.21s/it, loss=3.6927, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [08:25<05:46,  3.54s/it, loss=3.6926, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [08:28<05:03,  3.13s/it, loss=3.6918, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [08:31<05:08,  3.21s/it, loss=3.6918, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [08:33<04:26,  2.81s/it, loss=3.6908, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [08:36<04:41,  3.00s/it, loss=3.6916, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [08:39<04:32,  2.93s/it, loss=3.6909, tokens/Max input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [08:42<04:25,  2.88s/it, loss=3.6931, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [08:45<04:20,  2.86s/it, loss=3.6936, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [08:47<04:13,  2.82s/it, loss=3.6949, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [08:53<05:15,  3.55s/it, loss=3.6953, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [08:56<05:00,  3.42s/it, loss=3.6965, tokens/Max input_id: 31963\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [08:58<04:16,  2.95s/it, loss=3.6952, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [09:01<04:19,  3.01s/it, loss=3.6948, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [09:04<04:28,  3.15s/it, loss=3.6954, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [09:07<04:25,  3.16s/it, loss=3.6954, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [09:10<04:07,  2.98s/it, loss=3.6951, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [09:13<04:06,  3.00s/it, loss=3.6959, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [09:15<03:31,  2.62s/it, loss=3.6948, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [09:17<03:32,  2.66s/it, loss=3.6950, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [09:24<05:01,  3.81s/it, loss=3.6935, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [09:27<04:29,  3.46s/it, loss=3.6930, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [09:29<04:09,  3.24s/it, loss=3.6939, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [09:31<03:38,  2.88s/it, loss=3.6943, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [09:33<03:12,  2.57s/it, loss=3.6954, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [09:36<03:14,  2.63s/it, loss=3.6954, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [09:38<03:05,  2.54s/it, loss=3.6965, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [09:40<02:52,  2.39s/it, loss=3.6959, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [09:43<02:50,  2.41s/it, loss=3.6969, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [09:46<03:02,  2.60s/it, loss=3.6974, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [09:48<02:46,  2.41s/it, loss=3.6962, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [09:54<04:04,  3.59s/it, loss=3.6951, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [09:57<03:36,  3.23s/it, loss=3.6952, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [09:59<03:13,  2.93s/it, loss=3.6946, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [10:01<02:54,  2.68s/it, loss=3.6954, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [10:04<02:53,  2.71s/it, loss=3.6954, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [10:06<02:48,  2.67s/it, loss=3.6941, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [10:09<02:46,  2.68s/it, loss=3.6935, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [10:12<02:44,  2.69s/it, loss=3.6930, tokens/Max input_id: 31964\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [10:18<03:50,  3.84s/it, loss=3.6923, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [10:21<03:28,  3.54s/it, loss=3.6924, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [10:24<03:07,  3.23s/it, loss=3.6914, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [10:26<02:51,  3.00s/it, loss=3.6912, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [10:30<03:02,  3.25s/it, loss=3.6910, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [10:32<02:42,  2.95s/it, loss=3.6905, tokens/Max input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [10:35<02:33,  2.84s/it, loss=3.6899, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [10:37<02:23,  2.70s/it, loss=3.6888, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [10:40<02:27,  2.84s/it, loss=3.6874, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [10:43<02:29,  2.93s/it, loss=3.6871, tokens/Max input_id: 31977\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [10:47<02:43,  3.27s/it, loss=3.6860, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [10:53<03:07,  3.83s/it, loss=3.6865, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [11:00<03:53,  4.87s/it, loss=3.6873, tokens/Max input_id: 31963\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [11:03<03:17,  4.21s/it, loss=3.6863, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [11:05<02:49,  3.68s/it, loss=3.6857, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [11:08<02:36,  3.47s/it, loss=3.6865, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [11:11<02:25,  3.32s/it, loss=3.6868, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [11:14<02:18,  3.22s/it, loss=3.6876, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [11:16<02:03,  2.95s/it, loss=3.6876, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [11:19<02:04,  3.03s/it, loss=3.6877, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [11:23<02:03,  3.09s/it, loss=3.6871, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [11:26<02:08,  3.29s/it, loss=3.6857, tokens/Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [11:30<02:03,  3.24s/it, loss=3.6846, tokens/Max input_id: 31977\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [11:32<01:46,  2.89s/it, loss=3.6843, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [11:34<01:39,  2.75s/it, loss=3.6841, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [11:36<01:25,  2.45s/it, loss=3.6832, tokens/Max input_id: 31970\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [11:39<01:27,  2.59s/it, loss=3.6833, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [11:42<01:30,  2.76s/it, loss=3.6828, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [11:45<01:28,  2.75s/it, loss=3.6823, tokens/Max input_id: 31959\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [11:47<01:22,  2.67s/it, loss=3.6820, tokens/Max input_id: 31957\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [11:50<01:18,  2.61s/it, loss=3.6831, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [11:53<01:18,  2.72s/it, loss=3.6826, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [11:55<01:13,  2.63s/it, loss=3.6812, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [11:58<01:11,  2.65s/it, loss=3.6805, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [12:03<01:31,  3.50s/it, loss=3.6814, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [12:05<01:17,  3.10s/it, loss=3.6806, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [12:07<01:06,  2.79s/it, loss=3.6782, tokens/Max input_id: 31977\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [12:09<00:55,  2.43s/it, loss=3.6768, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [12:11<00:49,  2.25s/it, loss=3.6758, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [12:14<00:54,  2.59s/it, loss=3.6758, tokens/Max input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [12:16<00:47,  2.35s/it, loss=3.6745, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [12:19<00:49,  2.58s/it, loss=3.6743, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [12:26<01:07,  3.77s/it, loss=3.6743, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [12:28<00:54,  3.21s/it, loss=3.6735, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [12:33<01:02,  3.88s/it, loss=3.6729, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [12:35<00:51,  3.45s/it, loss=3.6733, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [12:42<00:59,  4.27s/it, loss=3.6746, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [12:44<00:48,  3.73s/it, loss=3.6743, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [12:47<00:40,  3.33s/it, loss=3.6740, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [12:52<00:42,  3.89s/it, loss=3.6744, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [12:54<00:34,  3.42s/it, loss=3.6741, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [12:56<00:27,  3.05s/it, loss=3.6740, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [12:59<00:24,  3.05s/it, loss=3.6748, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [13:02<00:19,  2.84s/it, loss=3.6742, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [13:04<00:16,  2.80s/it, loss=3.6741, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [13:06<00:12,  2.58s/it, loss=3.6736, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [13:10<00:11,  2.93s/it, loss=3.6727, tokens/Max input_id: 31963\n",
      "Max target_input: 31986\n",
      "Max label: 31986\n",
      "Training:  99%|█████████▉| 247/250 [13:14<00:09,  3.26s/it, loss=3.6741, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training:  99%|█████████▉| 248/250 [13:17<00:05,  3.00s/it, loss=3.6743, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Training: 100%|█████████▉| 249/250 [13:19<00:02,  2.78s/it, loss=3.6750, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training: 100%|██████████| 250/250 [13:35<00:00,  3.26s/it, loss=3.6760, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:07<04:05,  7.92s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:09<02:02,  4.08s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:10<01:21,  2.81s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:11<00:57,  2.04s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:12<00:46,  1.71s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:13<00:38,  1.50s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:14<00:32,  1.30s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:15<00:28,  1.18s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:16<00:28,  1.22s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:17<00:23,  1.08s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:18<00:22,  1.07s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:20<00:23,  1.17s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:21<00:22,  1.18s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:22<00:19,  1.07s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:22<00:17,  1.02s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:23<00:15,  1.02it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:24<00:15,  1.02s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:25<00:13,  1.03it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:26<00:12,  1.03it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:27<00:11,  1.07it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:28<00:09,  1.17it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:29<00:09,  1.10it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:30<00:08,  1.00it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:32<00:10,  1.30s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:33<00:08,  1.20s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:34<00:07,  1.24s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:35<00:05,  1.14s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:48<00:00,  1.53s/it]\n",
      "Removed old checkpoint: model_epoch_7.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_7.pt\n",
      "Saved training results to training_results_20250511_180734.csv\n",
      "Train Loss: 3.6760\n",
      "Val Loss: 4.6163\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: Parliament?\n",
      "\n",
      "Epoch 8/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:10<43:25, 10.46s/it, loss=3.5088, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:15<29:29,  7.13s/it, loss=3.6349, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:17<19:56,  4.84s/it, loss=3.6300, tokens/s=Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:23<21:12,  5.17s/it, loss=3.5831, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:25<17:41,  4.33s/it, loss=3.5687, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:30<17:26,  4.29s/it, loss=3.5786, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:32<14:53,  3.68s/it, loss=3.5626, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:35<14:11,  3.52s/it, loss=3.5553, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:42<17:44,  4.42s/it, loss=3.5458, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:44<14:38,  3.66s/it, loss=3.5258, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:47<14:16,  3.58s/it, loss=3.5204, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:50<13:54,  3.51s/it, loss=3.5323, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:53<12:39,  3.20s/it, loss=3.5389, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:55<11:55,  3.03s/it, loss=3.5478, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [00:57<10:19,  2.64s/it, loss=3.5311, tokens/sMax input_id: 31969\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [00:59<09:13,  2.36s/it, loss=3.5222, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [01:01<09:18,  2.40s/it, loss=3.5290, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:03<08:47,  2.28s/it, loss=3.5247, tokens/sMax input_id: 31977\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:08<11:30,  2.99s/it, loss=3.5226, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:14<15:25,  4.02s/it, loss=3.5231, tokens/sMax input_id: 31978\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:17<13:16,  3.48s/it, loss=3.5186, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:19<12:22,  3.26s/it, loss=3.5323, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:22<11:19,  3.00s/it, loss=3.5237, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:25<11:53,  3.16s/it, loss=3.5253, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:31<14:25,  3.85s/it, loss=3.5305, tokens/sMax input_id: 31978\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:38<18:20,  4.91s/it, loss=3.5363, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:41<15:47,  4.25s/it, loss=3.5372, tokens/sMax input_id: 31970\n",
      "Max target_input: 31988\n",
      "Max label: 31988\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [01:48<19:02,  5.15s/it, loss=3.5503, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [01:51<16:40,  4.53s/it, loss=3.5514, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [01:53<14:05,  3.84s/it, loss=3.5537, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [01:56<12:51,  3.52s/it, loss=3.5612, tokens/sMax input_id: 31958\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [02:03<16:19,  4.49s/it, loss=3.5599, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [02:07<15:21,  4.25s/it, loss=3.5629, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:09<13:25,  3.73s/it, loss=3.5642, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:13<13:03,  3.64s/it, loss=3.5630, tokens/sMax input_id: 31957\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:15<11:40,  3.28s/it, loss=3.5652, tokens/sMax input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:18<11:33,  3.25s/it, loss=3.5660, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:21<11:06,  3.14s/it, loss=3.5631, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:25<11:53,  3.38s/it, loss=3.5619, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:28<11:00,  3.15s/it, loss=3.5592, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:30<10:17,  2.95s/it, loss=3.5568, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:34<11:10,  3.22s/it, loss=3.5564, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:39<12:44,  3.69s/it, loss=3.5585, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:41<11:09,  3.25s/it, loss=3.5549, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [02:44<10:51,  3.18s/it, loss=3.5577, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [02:46<09:52,  2.90s/it, loss=3.5588, tokens/sMax input_id: 31963\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [02:50<10:25,  3.08s/it, loss=3.5604, tokens/sMax input_id: 31969\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [02:56<13:26,  3.99s/it, loss=3.5568, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [02:59<12:06,  3.61s/it, loss=3.5574, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [03:01<11:16,  3.38s/it, loss=3.5621, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [03:07<13:10,  3.97s/it, loss=3.5688, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:10<12:29,  3.79s/it, loss=3.5697, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:13<11:55,  3.63s/it, loss=3.5665, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:19<13:59,  4.28s/it, loss=3.5701, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:22<12:27,  3.83s/it, loss=3.5691, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:25<11:26,  3.54s/it, loss=3.5641, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:27<10:01,  3.11s/it, loss=3.5597, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:32<12:13,  3.82s/it, loss=3.5620, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:35<10:32,  3.31s/it, loss=3.5625, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [03:38<10:49,  3.42s/it, loss=3.5608, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [03:41<10:22,  3.29s/it, loss=3.5595, tokens/sMax input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [03:44<09:41,  3.10s/it, loss=3.5550, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [03:47<09:42,  3.11s/it, loss=3.5507, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [03:53<12:26,  4.01s/it, loss=3.5527, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [03:56<11:07,  3.61s/it, loss=3.5481, tokens/sMax input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [03:59<10:41,  3.49s/it, loss=3.5459, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [04:01<09:21,  3.07s/it, loss=3.5448, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [04:04<09:27,  3.12s/it, loss=3.5425, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [04:07<09:10,  3.04s/it, loss=3.5428, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [04:10<08:27,  2.82s/it, loss=3.5442, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:14<09:43,  3.26s/it, loss=3.5445, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:16<08:44,  2.95s/it, loss=3.5446, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:19<08:24,  2.85s/it, loss=3.5424, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:21<07:29,  2.56s/it, loss=3.5453, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [04:22<06:53,  2.36s/it, loss=3.5426, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [04:26<08:01,  2.77s/it, loss=3.5434, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [04:29<07:46,  2.70s/it, loss=3.5440, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [04:35<10:31,  3.67s/it, loss=3.5455, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [04:37<09:40,  3.40s/it, loss=3.5474, tokens/sMax input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [04:40<09:03,  3.20s/it, loss=3.5487, tokens/sMax input_id: 31959\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [04:42<08:06,  2.88s/it, loss=3.5463, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [04:45<08:07,  2.90s/it, loss=3.5442, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [04:48<08:09,  2.93s/it, loss=3.5447, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [04:54<10:32,  3.81s/it, loss=3.5430, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [04:57<09:33,  3.47s/it, loss=3.5418, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [04:59<08:40,  3.17s/it, loss=3.5373, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [05:01<07:30,  2.76s/it, loss=3.5357, tokens/sMax input_id: 31969\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [05:03<07:06,  2.63s/it, loss=3.5337, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [05:11<11:28,  4.27s/it, loss=3.5369, tokens/sMax input_id: 31958\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [05:13<09:34,  3.59s/it, loss=3.5362, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [05:16<08:56,  3.38s/it, loss=3.5359, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [05:19<08:20,  3.17s/it, loss=3.5343, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [05:22<08:10,  3.12s/it, loss=3.5348, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [05:25<07:37,  2.93s/it, loss=3.5306, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [05:27<07:13,  2.79s/it, loss=3.5333, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [05:29<06:31,  2.54s/it, loss=3.5295, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [05:31<06:07,  2.41s/it, loss=3.5287, tokens/sMax input_id: 31968\n",
      "Max target_input: 31967\n",
      "Max label: 31967\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [05:36<08:08,  3.21s/it, loss=3.5317, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [05:39<07:28,  2.97s/it, loss=3.5288, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [05:46<11:05,  4.44s/it, loss=3.5315, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [05:48<09:07,  3.67s/it, loss=3.5294, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [05:51<08:02,  3.26s/it, loss=3.5263, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [05:53<07:28,  3.05s/it, loss=3.5240, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [05:56<07:22,  3.03s/it, loss=3.5249, tokens/Max input_id: 31938\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [05:59<07:00,  2.90s/it, loss=3.5242, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [06:03<07:40,  3.20s/it, loss=3.5229, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [06:05<07:18,  3.07s/it, loss=3.5226, tokens/Max input_id: 31963\n",
      "Max target_input: 31998\n",
      "Max label: 31998\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [06:08<06:55,  2.93s/it, loss=3.5229, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [06:10<06:26,  2.74s/it, loss=3.5235, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [06:16<08:23,  3.60s/it, loss=3.5199, tokens/Max input_id: 31970\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [06:19<07:42,  3.33s/it, loss=3.5213, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [06:21<07:03,  3.07s/it, loss=3.5202, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [06:28<09:35,  4.20s/it, loss=3.5214, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [06:30<08:15,  3.64s/it, loss=3.5207, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [06:33<07:46,  3.45s/it, loss=3.5206, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [06:38<08:25,  3.78s/it, loss=3.5194, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [06:44<09:54,  4.47s/it, loss=3.5202, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [06:50<11:14,  5.11s/it, loss=3.5210, tokens/Max input_id: 31959\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [06:54<09:55,  4.54s/it, loss=3.5226, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [06:56<08:39,  4.00s/it, loss=3.5219, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [06:59<07:50,  3.65s/it, loss=3.5231, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [07:03<07:46,  3.64s/it, loss=3.5251, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [07:06<07:37,  3.61s/it, loss=3.5250, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [07:08<06:31,  3.11s/it, loss=3.5225, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [07:13<07:30,  3.61s/it, loss=3.5219, tokens/Max input_id: 31958\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [07:17<07:55,  3.83s/it, loss=3.5214, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [07:19<06:35,  3.22s/it, loss=3.5198, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [07:23<06:42,  3.30s/it, loss=3.5189, tokens/Max input_id: 31970\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [07:25<05:52,  2.91s/it, loss=3.5194, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [07:27<05:27,  2.73s/it, loss=3.5192, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [07:31<06:13,  3.14s/it, loss=3.5208, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [07:33<05:27,  2.78s/it, loss=3.5185, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [07:35<04:50,  2.48s/it, loss=3.5172, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [07:41<06:47,  3.52s/it, loss=3.5167, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [07:44<06:44,  3.52s/it, loss=3.5152, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [07:48<06:37,  3.49s/it, loss=3.5144, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [07:50<05:45,  3.06s/it, loss=3.5133, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [07:53<05:49,  3.12s/it, loss=3.5115, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [07:55<05:12,  2.82s/it, loss=3.5109, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [07:58<05:09,  2.82s/it, loss=3.5108, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [08:03<06:08,  3.38s/it, loss=3.5092, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [08:05<05:19,  2.96s/it, loss=3.5094, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [08:09<06:14,  3.50s/it, loss=3.5093, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [08:12<05:44,  3.25s/it, loss=3.5077, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [08:17<06:32,  3.74s/it, loss=3.5076, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [08:20<06:20,  3.66s/it, loss=3.5069, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [08:22<05:27,  3.17s/it, loss=3.5054, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [08:25<05:00,  2.94s/it, loss=3.5062, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [08:28<05:11,  3.08s/it, loss=3.5059, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [08:34<06:12,  3.73s/it, loss=3.5058, tokens/Max input_id: 31977\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [08:37<06:15,  3.80s/it, loss=3.5060, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [08:45<07:57,  4.87s/it, loss=3.5056, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [08:47<06:40,  4.13s/it, loss=3.5047, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [08:53<07:10,  4.48s/it, loss=3.5046, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [08:54<05:52,  3.71s/it, loss=3.5033, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [08:58<05:36,  3.58s/it, loss=3.5040, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [09:01<05:14,  3.38s/it, loss=3.5034, tokens/Max input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [09:04<05:00,  3.27s/it, loss=3.5052, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [09:09<05:45,  3.80s/it, loss=3.5054, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [09:13<05:51,  3.91s/it, loss=3.5065, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [09:19<06:38,  4.48s/it, loss=3.5073, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [09:22<06:05,  4.15s/it, loss=3.5089, tokens/Max input_id: 31963\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [09:24<05:00,  3.45s/it, loss=3.5074, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [09:26<04:26,  3.10s/it, loss=3.5069, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [09:30<04:43,  3.33s/it, loss=3.5076, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [09:36<05:51,  4.18s/it, loss=3.5077, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [09:39<05:22,  3.89s/it, loss=3.5075, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [09:44<05:27,  3.99s/it, loss=3.5086, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [09:45<04:30,  3.34s/it, loss=3.5075, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [09:50<04:44,  3.56s/it, loss=3.5077, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [09:58<06:27,  4.90s/it, loss=3.5064, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [10:00<05:32,  4.26s/it, loss=3.5058, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [10:04<05:08,  4.01s/it, loss=3.5068, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [10:06<04:23,  3.47s/it, loss=3.5074, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [10:08<03:44,  3.00s/it, loss=3.5087, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [10:12<04:09,  3.38s/it, loss=3.5090, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [10:14<03:42,  3.04s/it, loss=3.5101, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [10:17<03:19,  2.77s/it, loss=3.5099, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [10:20<03:27,  2.93s/it, loss=3.5112, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [10:22<03:14,  2.78s/it, loss=3.5118, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [10:24<02:54,  2.53s/it, loss=3.5102, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [10:31<04:18,  3.81s/it, loss=3.5090, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [10:33<03:46,  3.39s/it, loss=3.5092, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [10:36<03:20,  3.05s/it, loss=3.5088, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [10:39<03:17,  3.04s/it, loss=3.5091, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [10:43<03:47,  3.55s/it, loss=3.5086, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [10:45<03:08,  2.99s/it, loss=3.5075, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [10:48<03:00,  2.90s/it, loss=3.5071, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [10:51<02:54,  2.86s/it, loss=3.5066, tokens/Max input_id: 31964\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [10:58<04:20,  4.33s/it, loss=3.5059, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [11:01<03:51,  3.93s/it, loss=3.5056, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [11:04<03:24,  3.53s/it, loss=3.5044, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [11:06<03:03,  3.22s/it, loss=3.5040, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [11:10<02:58,  3.19s/it, loss=3.5040, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [11:12<02:40,  2.92s/it, loss=3.5034, tokens/Max input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [11:15<02:46,  3.08s/it, loss=3.5026, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [11:18<02:33,  2.89s/it, loss=3.5015, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [11:22<02:53,  3.33s/it, loss=3.5002, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [11:26<02:54,  3.42s/it, loss=3.4995, tokens/Max input_id: 31977\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [11:30<03:06,  3.73s/it, loss=3.4985, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [11:37<03:42,  4.55s/it, loss=3.4989, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [11:44<04:25,  5.53s/it, loss=3.4995, tokens/Max input_id: 31963\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [11:47<03:42,  4.73s/it, loss=3.4990, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [11:50<03:07,  4.07s/it, loss=3.4989, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [11:54<02:57,  3.96s/it, loss=3.4999, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [11:56<02:41,  3.66s/it, loss=3.5000, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [12:00<02:31,  3.52s/it, loss=3.5007, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [12:03<02:23,  3.42s/it, loss=3.5009, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [12:05<02:08,  3.14s/it, loss=3.5009, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [12:10<02:22,  3.57s/it, loss=3.5002, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [12:14<02:28,  3.81s/it, loss=3.4989, tokens/Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [12:18<02:22,  3.75s/it, loss=3.4978, tokens/Max input_id: 31977\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [12:20<02:00,  3.26s/it, loss=3.4974, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [12:24<02:03,  3.43s/it, loss=3.4972, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [12:26<01:42,  2.92s/it, loss=3.4960, tokens/Max input_id: 31970\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [12:28<01:34,  2.79s/it, loss=3.4957, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [12:33<01:48,  3.30s/it, loss=3.4955, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [12:36<01:42,  3.20s/it, loss=3.4951, tokens/Max input_id: 31959\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [12:38<01:32,  3.00s/it, loss=3.4947, tokens/Max input_id: 31957\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [12:42<01:41,  3.40s/it, loss=3.4958, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [12:47<01:47,  3.71s/it, loss=3.4953, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [12:49<01:33,  3.33s/it, loss=3.4940, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [12:52<01:26,  3.20s/it, loss=3.4937, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [12:56<01:26,  3.33s/it, loss=3.4948, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [12:58<01:14,  2.98s/it, loss=3.4941, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [13:01<01:11,  3.00s/it, loss=3.4919, tokens/Max input_id: 31977\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [13:03<00:59,  2.60s/it, loss=3.4904, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [13:05<00:52,  2.38s/it, loss=3.4893, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [13:08<00:59,  2.82s/it, loss=3.4891, tokens/Max input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [13:10<00:50,  2.52s/it, loss=3.4881, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [13:15<00:58,  3.07s/it, loss=3.4879, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [13:22<01:17,  4.31s/it, loss=3.4874, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [13:24<01:01,  3.61s/it, loss=3.4862, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [13:29<01:07,  4.23s/it, loss=3.4856, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [13:32<00:55,  3.67s/it, loss=3.4860, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [13:38<01:02,  4.46s/it, loss=3.4874, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [13:41<00:50,  3.88s/it, loss=3.4869, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [13:43<00:41,  3.45s/it, loss=3.4862, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [13:49<00:45,  4.11s/it, loss=3.4868, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [13:51<00:36,  3.64s/it, loss=3.4866, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [13:54<00:29,  3.24s/it, loss=3.4865, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [13:56<00:24,  3.11s/it, loss=3.4875, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [13:59<00:20,  2.88s/it, loss=3.4870, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [14:01<00:16,  2.82s/it, loss=3.4865, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [14:04<00:14,  2.85s/it, loss=3.4860, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [14:08<00:12,  3.07s/it, loss=3.4856, tokens/Max input_id: 31963\n",
      "Max target_input: 31986\n",
      "Max label: 31986\n",
      "Training:  99%|█████████▉| 247/250 [14:12<00:10,  3.44s/it, loss=3.4867, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training:  99%|█████████▉| 248/250 [14:15<00:06,  3.11s/it, loss=3.4867, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Training: 100%|█████████▉| 249/250 [14:17<00:02,  2.87s/it, loss=3.4874, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training: 100%|██████████| 250/250 [14:34<00:00,  3.50s/it, loss=3.4885, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:07<03:40,  7.10s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:08<01:52,  3.76s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:09<01:17,  2.68s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:10<00:55,  1.97s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:12<00:52,  1.95s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:13<00:43,  1.68s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:14<00:35,  1.44s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:15<00:30,  1.27s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:17<00:29,  1.28s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:17<00:25,  1.14s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:18<00:23,  1.13s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:19<00:19,  1.00it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:21<00:23,  1.26s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:22<00:19,  1.09s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:23<00:17,  1.03s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:23<00:15,  1.05it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:24<00:14,  1.01it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:25<00:13,  1.06it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:26<00:12,  1.07it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:27<00:10,  1.10it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:28<00:09,  1.20it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:29<00:08,  1.16it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:31<00:10,  1.18s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:32<00:09,  1.19s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:33<00:07,  1.12s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:34<00:07,  1.19s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:35<00:05,  1.11s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:49<00:00,  1.54s/it]\n",
      "Saved checkpoint to checkpoints/model_epoch_8.pt\n",
      "Saved training results to training_results_20250511_182258.csv\n",
      "Train Loss: 3.4885\n",
      "Val Loss: 4.6554\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: ?\n",
      "\n",
      "Epoch 9/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:10<42:37, 10.27s/it, loss=3.3027, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:13<25:34,  6.19s/it, loss=3.4483, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:16<19:58,  4.85s/it, loss=3.4299, tokens/s=Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:22<21:17,  5.19s/it, loss=3.3974, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:24<16:23,  4.01s/it, loss=3.4004, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:27<14:58,  3.68s/it, loss=3.3980, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:29<12:47,  3.16s/it, loss=3.3783, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:31<11:43,  2.91s/it, loss=3.3691, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:36<14:12,  3.54s/it, loss=3.3552, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:40<13:40,  3.42s/it, loss=3.3373, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:44<14:23,  3.61s/it, loss=3.3369, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:47<14:13,  3.58s/it, loss=3.3496, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:50<12:48,  3.24s/it, loss=3.3584, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:51<11:02,  2.81s/it, loss=3.3632, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [00:54<10:41,  2.73s/it, loss=3.3405, tokens/sMax input_id: 31969\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [00:56<09:27,  2.43s/it, loss=3.3312, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [00:58<09:31,  2.45s/it, loss=3.3382, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:00<09:06,  2.35s/it, loss=3.3382, tokens/sMax input_id: 31977\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:05<11:31,  2.99s/it, loss=3.3385, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:11<14:59,  3.91s/it, loss=3.3364, tokens/sMax input_id: 31978\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:14<14:06,  3.70s/it, loss=3.3324, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:18<13:59,  3.68s/it, loss=3.3474, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:20<12:14,  3.23s/it, loss=3.3424, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:23<11:43,  3.11s/it, loss=3.3417, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:27<13:29,  3.60s/it, loss=3.3483, tokens/sMax input_id: 31978\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:34<17:01,  4.56s/it, loss=3.3561, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:38<15:40,  4.22s/it, loss=3.3555, tokens/sMax input_id: 31970\n",
      "Max target_input: 31988\n",
      "Max label: 31988\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [01:44<18:09,  4.91s/it, loss=3.3703, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [01:47<15:58,  4.34s/it, loss=3.3696, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [01:49<13:37,  3.72s/it, loss=3.3717, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [01:52<12:35,  3.45s/it, loss=3.3774, tokens/sMax input_id: 31958\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [01:59<16:34,  4.56s/it, loss=3.3747, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [02:03<15:47,  4.37s/it, loss=3.3762, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:06<13:41,  3.80s/it, loss=3.3782, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:10<13:49,  3.86s/it, loss=3.3786, tokens/sMax input_id: 31957\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:12<12:13,  3.43s/it, loss=3.3799, tokens/sMax input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:15<11:52,  3.34s/it, loss=3.3812, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:18<10:39,  3.02s/it, loss=3.3803, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:21<10:55,  3.11s/it, loss=3.3804, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:25<11:21,  3.25s/it, loss=3.3766, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:27<10:43,  3.08s/it, loss=3.3726, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:32<12:28,  3.60s/it, loss=3.3727, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:38<15:01,  4.36s/it, loss=3.3756, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:41<13:52,  4.04s/it, loss=3.3713, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [02:47<15:37,  4.57s/it, loss=3.3750, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [02:50<13:51,  4.07s/it, loss=3.3770, tokens/sMax input_id: 31963\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [02:54<13:36,  4.02s/it, loss=3.3795, tokens/sMax input_id: 31969\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [03:00<15:04,  4.48s/it, loss=3.3757, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [03:02<13:14,  3.95s/it, loss=3.3780, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [03:05<12:01,  3.61s/it, loss=3.3831, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [03:11<13:50,  4.17s/it, loss=3.3886, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:13<12:01,  3.65s/it, loss=3.3892, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:16<11:05,  3.38s/it, loss=3.3866, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:21<12:58,  3.97s/it, loss=3.3903, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:24<12:11,  3.75s/it, loss=3.3883, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:28<11:48,  3.65s/it, loss=3.3836, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:30<10:17,  3.20s/it, loss=3.3787, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:35<11:31,  3.60s/it, loss=3.3814, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:37<09:56,  3.12s/it, loss=3.3814, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [03:40<09:50,  3.11s/it, loss=3.3792, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [03:43<09:37,  3.06s/it, loss=3.3778, tokens/sMax input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [03:45<09:04,  2.90s/it, loss=3.3725, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [03:47<08:24,  2.70s/it, loss=3.3687, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [03:52<09:54,  3.19s/it, loss=3.3698, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [03:54<09:14,  3.00s/it, loss=3.3647, tokens/sMax input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [03:58<09:52,  3.22s/it, loss=3.3621, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [04:00<08:45,  2.87s/it, loss=3.3612, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [04:02<08:15,  2.72s/it, loss=3.3594, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [04:05<08:11,  2.72s/it, loss=3.3605, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [04:07<07:46,  2.59s/it, loss=3.3629, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:10<08:10,  2.74s/it, loss=3.3629, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:13<07:42,  2.60s/it, loss=3.3635, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:15<07:05,  2.40s/it, loss=3.3616, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:16<06:33,  2.23s/it, loss=3.3637, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [04:19<06:25,  2.20s/it, loss=3.3604, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [04:22<07:12,  2.48s/it, loss=3.3609, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [04:24<07:16,  2.52s/it, loss=3.3621, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [04:29<08:54,  3.11s/it, loss=3.3637, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [04:31<08:18,  2.92s/it, loss=3.3658, tokens/sMax input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [04:34<08:01,  2.84s/it, loss=3.3670, tokens/sMax input_id: 31959\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [04:36<07:22,  2.62s/it, loss=3.3648, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [04:39<07:43,  2.76s/it, loss=3.3626, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [04:42<07:50,  2.82s/it, loss=3.3627, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [04:45<08:04,  2.92s/it, loss=3.3607, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [04:48<08:12,  2.98s/it, loss=3.3591, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [04:51<07:43,  2.83s/it, loss=3.3546, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [04:53<06:49,  2.51s/it, loss=3.3527, tokens/sMax input_id: 31969\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [04:55<06:51,  2.54s/it, loss=3.3510, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [05:02<10:07,  3.77s/it, loss=3.3548, tokens/sMax input_id: 31958\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [05:04<08:31,  3.20s/it, loss=3.3539, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [05:07<08:14,  3.11s/it, loss=3.3540, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [05:09<07:55,  3.01s/it, loss=3.3526, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [05:13<08:11,  3.13s/it, loss=3.3532, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [05:14<06:55,  2.66s/it, loss=3.3483, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [05:17<06:56,  2.69s/it, loss=3.3509, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [05:20<07:08,  2.79s/it, loss=3.3467, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [05:23<07:08,  2.80s/it, loss=3.3462, tokens/sMax input_id: 31968\n",
      "Max target_input: 31967\n",
      "Max label: 31967\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [05:28<08:26,  3.34s/it, loss=3.3495, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [05:30<07:37,  3.03s/it, loss=3.3468, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [05:37<10:28,  4.19s/it, loss=3.3495, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [05:39<08:43,  3.51s/it, loss=3.3475, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [05:41<07:44,  3.14s/it, loss=3.3442, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [05:45<08:08,  3.32s/it, loss=3.3415, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [05:48<08:00,  3.29s/it, loss=3.3422, tokens/Max input_id: 31938\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [05:50<07:13,  2.99s/it, loss=3.3413, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [05:55<08:10,  3.41s/it, loss=3.3394, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [05:58<07:45,  3.26s/it, loss=3.3393, tokens/Max input_id: 31963\n",
      "Max target_input: 31998\n",
      "Max label: 31998\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [06:00<07:08,  3.02s/it, loss=3.3401, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [06:03<07:14,  3.08s/it, loss=3.3408, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [06:09<09:02,  3.88s/it, loss=3.3380, tokens/Max input_id: 31970\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [06:12<08:25,  3.63s/it, loss=3.3394, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [06:15<07:34,  3.30s/it, loss=3.3380, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [06:22<10:14,  4.48s/it, loss=3.3398, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [06:24<08:41,  3.83s/it, loss=3.3396, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [06:27<08:04,  3.59s/it, loss=3.3400, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [06:31<08:22,  3.75s/it, loss=3.3395, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [06:38<09:58,  4.50s/it, loss=3.3401, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [06:44<11:14,  5.11s/it, loss=3.3411, tokens/Max input_id: 31959\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [06:47<09:47,  4.49s/it, loss=3.3431, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [06:49<07:56,  3.66s/it, loss=3.3420, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [06:52<07:44,  3.60s/it, loss=3.3433, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [06:55<07:05,  3.32s/it, loss=3.3455, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [06:58<06:48,  3.21s/it, loss=3.3449, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [07:00<05:55,  2.82s/it, loss=3.3422, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [07:03<05:53,  2.82s/it, loss=3.3416, tokens/Max input_id: 31958\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [07:05<05:47,  2.81s/it, loss=3.3418, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [07:08<05:34,  2.72s/it, loss=3.3392, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [07:11<05:39,  2.78s/it, loss=3.3383, tokens/Max input_id: 31970\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [07:13<05:11,  2.58s/it, loss=3.3391, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [07:15<04:58,  2.49s/it, loss=3.3390, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [07:18<05:01,  2.53s/it, loss=3.3404, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [07:20<04:36,  2.34s/it, loss=3.3382, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [07:22<04:43,  2.43s/it, loss=3.3369, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [07:28<06:27,  3.34s/it, loss=3.3359, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [07:31<06:24,  3.34s/it, loss=3.3344, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [07:34<05:51,  3.09s/it, loss=3.3336, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [07:36<05:14,  2.78s/it, loss=3.3325, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [07:39<05:31,  2.96s/it, loss=3.3302, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [07:41<04:57,  2.68s/it, loss=3.3294, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [07:43<04:37,  2.52s/it, loss=3.3295, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [07:46<04:46,  2.63s/it, loss=3.3278, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [07:48<04:21,  2.42s/it, loss=3.3273, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [07:51<04:46,  2.67s/it, loss=3.3267, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [07:55<05:03,  2.86s/it, loss=3.3251, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [08:00<06:07,  3.50s/it, loss=3.3247, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [08:02<05:31,  3.19s/it, loss=3.3238, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [08:04<04:49,  2.81s/it, loss=3.3225, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [08:06<04:23,  2.59s/it, loss=3.3234, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [08:10<04:54,  2.91s/it, loss=3.3229, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [08:15<06:02,  3.63s/it, loss=3.3225, tokens/Max input_id: 31977\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [08:18<05:32,  3.36s/it, loss=3.3230, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [08:21<05:34,  3.41s/it, loss=3.3228, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [08:24<04:55,  3.05s/it, loss=3.3218, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [08:27<04:59,  3.12s/it, loss=3.3219, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [08:30<04:44,  3.00s/it, loss=3.3210, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [08:33<04:41,  2.99s/it, loss=3.3221, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [08:35<04:32,  2.93s/it, loss=3.3210, tokens/Max input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [08:38<04:28,  2.92s/it, loss=3.3228, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [08:41<04:25,  2.92s/it, loss=3.3228, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [08:45<04:39,  3.11s/it, loss=3.3240, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [08:50<05:39,  3.82s/it, loss=3.3247, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [08:53<05:13,  3.56s/it, loss=3.3262, tokens/Max input_id: 31963\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [08:55<04:24,  3.04s/it, loss=3.3249, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [08:57<04:01,  2.81s/it, loss=3.3243, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [09:01<04:11,  2.96s/it, loss=3.3250, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [09:05<04:56,  3.53s/it, loss=3.3254, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [09:08<04:31,  3.28s/it, loss=3.3249, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [09:12<04:43,  3.46s/it, loss=3.3261, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [09:14<03:58,  2.95s/it, loss=3.3249, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [09:17<03:53,  2.92s/it, loss=3.3254, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [09:23<05:16,  4.01s/it, loss=3.3239, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [09:26<04:42,  3.62s/it, loss=3.3233, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [09:29<04:20,  3.39s/it, loss=3.3242, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [09:31<03:46,  2.98s/it, loss=3.3247, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [09:33<03:18,  2.65s/it, loss=3.3261, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [09:36<03:24,  2.76s/it, loss=3.3259, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [09:38<03:14,  2.66s/it, loss=3.3265, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [09:41<03:14,  2.70s/it, loss=3.3260, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [09:43<03:06,  2.63s/it, loss=3.3272, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [09:46<03:01,  2.59s/it, loss=3.3274, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [09:48<02:45,  2.39s/it, loss=3.3255, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [09:54<04:05,  3.61s/it, loss=3.3245, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [09:57<03:37,  3.25s/it, loss=3.3244, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [10:00<03:31,  3.20s/it, loss=3.3239, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [10:02<03:07,  2.88s/it, loss=3.3243, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [10:06<03:23,  3.17s/it, loss=3.3242, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [10:07<02:51,  2.73s/it, loss=3.3230, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [10:10<02:53,  2.80s/it, loss=3.3228, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [10:14<03:06,  3.06s/it, loss=3.3220, tokens/Max input_id: 31964\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [10:21<04:13,  4.22s/it, loss=3.3214, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [10:24<03:45,  3.83s/it, loss=3.3209, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [10:26<03:19,  3.44s/it, loss=3.3195, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [10:29<02:59,  3.14s/it, loss=3.3192, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [10:32<02:51,  3.06s/it, loss=3.3187, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [10:35<02:50,  3.10s/it, loss=3.3180, tokens/Max input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [10:37<02:38,  2.94s/it, loss=3.3175, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [10:40<02:26,  2.76s/it, loss=3.3168, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [10:44<02:40,  3.09s/it, loss=3.3154, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [10:49<03:13,  3.79s/it, loss=3.3147, tokens/Max input_id: 31977\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [10:54<03:29,  4.19s/it, loss=3.3138, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [11:00<03:54,  4.78s/it, loss=3.3143, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [11:07<04:11,  5.25s/it, loss=3.3149, tokens/Max input_id: 31963\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [11:10<03:32,  4.52s/it, loss=3.3147, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [11:14<03:20,  4.36s/it, loss=3.3142, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [11:18<03:23,  4.52s/it, loss=3.3149, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [11:22<03:00,  4.11s/it, loss=3.3151, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [11:25<02:43,  3.81s/it, loss=3.3158, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [11:27<02:21,  3.37s/it, loss=3.3159, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [11:29<02:06,  3.08s/it, loss=3.3162, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [11:34<02:21,  3.53s/it, loss=3.3157, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [11:39<02:33,  3.94s/it, loss=3.3146, tokens/Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [11:42<02:22,  3.76s/it, loss=3.3132, tokens/Max input_id: 31977\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [11:44<02:00,  3.25s/it, loss=3.3127, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [11:47<01:49,  3.03s/it, loss=3.3124, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [11:49<01:32,  2.65s/it, loss=3.3113, tokens/Max input_id: 31970\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [11:52<01:33,  2.75s/it, loss=3.3112, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [11:56<01:45,  3.20s/it, loss=3.3111, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [11:59<01:46,  3.34s/it, loss=3.3110, tokens/Max input_id: 31959\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [12:02<01:35,  3.09s/it, loss=3.3108, tokens/Max input_id: 31957\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [12:05<01:28,  2.95s/it, loss=3.3119, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [12:08<01:26,  3.00s/it, loss=3.3110, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [12:11<01:26,  3.09s/it, loss=3.3095, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [12:15<01:27,  3.25s/it, loss=3.3091, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [12:19<01:36,  3.71s/it, loss=3.3101, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [12:22<01:21,  3.25s/it, loss=3.3093, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [12:24<01:09,  2.91s/it, loss=3.3071, tokens/Max input_id: 31977\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [12:25<00:58,  2.52s/it, loss=3.3058, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [12:28<00:56,  2.56s/it, loss=3.3051, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [12:32<01:01,  2.95s/it, loss=3.3049, tokens/Max input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [12:34<00:52,  2.60s/it, loss=3.3036, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [12:38<01:00,  3.17s/it, loss=3.3032, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [12:44<01:09,  3.87s/it, loss=3.3023, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [12:46<00:55,  3.28s/it, loss=3.3014, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [12:52<01:09,  4.36s/it, loss=3.3005, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [12:55<00:56,  3.79s/it, loss=3.3009, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [13:01<01:02,  4.47s/it, loss=3.3023, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [13:04<00:50,  3.92s/it, loss=3.3016, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [13:06<00:43,  3.59s/it, loss=3.3010, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [13:13<00:48,  4.37s/it, loss=3.3016, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [13:15<00:38,  3.82s/it, loss=3.3012, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [13:17<00:29,  3.33s/it, loss=3.3012, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [13:20<00:25,  3.21s/it, loss=3.3024, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [13:23<00:20,  2.99s/it, loss=3.3016, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [13:25<00:17,  2.90s/it, loss=3.3012, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [13:28<00:14,  2.91s/it, loss=3.3004, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [13:33<00:13,  3.35s/it, loss=3.2998, tokens/Max input_id: 31963\n",
      "Max target_input: 31986\n",
      "Max label: 31986\n",
      "Training:  99%|█████████▉| 247/250 [13:37<00:10,  3.64s/it, loss=3.3010, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training:  99%|█████████▉| 248/250 [13:39<00:06,  3.26s/it, loss=3.3011, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Training: 100%|█████████▉| 249/250 [13:42<00:02,  2.99s/it, loss=3.3014, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training: 100%|██████████| 250/250 [13:58<00:00,  3.36s/it, loss=3.3025, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:07<03:39,  7.07s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:08<01:52,  3.74s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:10<01:19,  2.74s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:11<01:04,  2.31s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:12<00:51,  1.92s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:14<00:43,  1.66s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:14<00:35,  1.40s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:15<00:29,  1.25s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:17<00:29,  1.28s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:18<00:24,  1.14s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:19<00:23,  1.12s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:20<00:24,  1.23s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:21<00:23,  1.23s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:22<00:20,  1.15s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:23<00:18,  1.11s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:24<00:16,  1.03s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:25<00:16,  1.09s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:26<00:14,  1.03s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:28<00:16,  1.27s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:29<00:13,  1.16s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:30<00:11,  1.02s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:31<00:10,  1.03s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:32<00:10,  1.13s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:33<00:09,  1.18s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:34<00:07,  1.13s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:36<00:08,  1.42s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:37<00:06,  1.27s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:51<00:00,  1.60s/it]\n",
      "Saved checkpoint to checkpoints/model_epoch_9.pt\n",
      "Saved training results to training_results_20250511_183750.csv\n",
      "Train Loss: 3.3025\n",
      "Val Loss: 4.7082\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: ????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n",
      "\n",
      "Epoch 10/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:09<39:56,  9.63s/it, loss=3.1629, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:14<27:42,  6.70s/it, loss=3.2885, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:17<20:41,  5.03s/it, loss=3.2585, tokens/s=Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:23<21:44,  5.30s/it, loss=3.2065, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:24<16:38,  4.08s/it, loss=3.2074, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:29<16:36,  4.09s/it, loss=3.2051, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:31<13:54,  3.43s/it, loss=3.1809, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:35<15:25,  3.83s/it, loss=3.1717, tokens/s=Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:41<17:36,  4.38s/it, loss=3.1656, tokens/s=Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:43<14:38,  3.66s/it, loss=3.1497, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:47<14:45,  3.71s/it, loss=3.1392, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:51<15:29,  3.90s/it, loss=3.1483, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:56<16:28,  4.17s/it, loss=3.1527, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:58<13:36,  3.46s/it, loss=3.1563, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [00:59<11:24,  2.91s/it, loss=3.1326, tokens/sMax input_id: 31969\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [01:01<10:05,  2.59s/it, loss=3.1293, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [01:04<09:55,  2.56s/it, loss=3.1434, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:06<09:16,  2.40s/it, loss=3.1412, tokens/sMax input_id: 31977\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:12<13:14,  3.44s/it, loss=3.1408, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:18<16:55,  4.42s/it, loss=3.1417, tokens/sMax input_id: 31978\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:21<14:28,  3.79s/it, loss=3.1374, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:24<13:51,  3.65s/it, loss=3.1549, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:26<12:09,  3.21s/it, loss=3.1496, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:30<12:24,  3.29s/it, loss=3.1478, tokens/sMax input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:35<14:57,  3.99s/it, loss=3.1548, tokens/sMax input_id: 31978\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:42<18:28,  4.95s/it, loss=3.1651, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:45<15:38,  4.21s/it, loss=3.1640, tokens/sMax input_id: 31970\n",
      "Max target_input: 31988\n",
      "Max label: 31988\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [01:51<17:35,  4.75s/it, loss=3.1796, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [01:54<15:42,  4.26s/it, loss=3.1798, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [01:57<14:18,  3.90s/it, loss=3.1829, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [02:01<13:58,  3.83s/it, loss=3.1889, tokens/sMax input_id: 31958\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [02:08<17:34,  4.84s/it, loss=3.1842, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [02:11<15:26,  4.27s/it, loss=3.1867, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:13<13:27,  3.74s/it, loss=3.1896, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:19<15:42,  4.38s/it, loss=3.1889, tokens/sMax input_id: 31957\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:22<13:38,  3.83s/it, loss=3.1912, tokens/sMax input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:25<12:52,  3.63s/it, loss=3.1916, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:27<11:17,  3.20s/it, loss=3.1912, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:31<11:58,  3.40s/it, loss=3.1918, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:34<11:03,  3.16s/it, loss=3.1882, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:37<11:35,  3.33s/it, loss=3.1835, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:41<12:15,  3.54s/it, loss=3.1843, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:46<13:17,  3.85s/it, loss=3.1874, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:48<11:40,  3.40s/it, loss=3.1825, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [02:51<11:12,  3.28s/it, loss=3.1861, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [02:54<10:10,  2.99s/it, loss=3.1869, tokens/sMax input_id: 31963\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [02:58<11:29,  3.40s/it, loss=3.1907, tokens/sMax input_id: 31969\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [03:04<13:56,  4.14s/it, loss=3.1867, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [03:07<12:27,  3.72s/it, loss=3.1888, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [03:10<12:02,  3.61s/it, loss=3.1935, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [03:16<14:17,  4.31s/it, loss=3.1993, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:19<13:23,  4.06s/it, loss=3.1998, tokens/sMax input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:24<13:25,  4.09s/it, loss=3.1977, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:30<15:22,  4.71s/it, loss=3.2017, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:32<13:25,  4.13s/it, loss=3.2004, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:36<12:25,  3.84s/it, loss=3.1964, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:38<10:46,  3.35s/it, loss=3.1933, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:44<13:15,  4.15s/it, loss=3.1956, tokens/sMax input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:46<11:24,  3.58s/it, loss=3.1960, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [03:50<11:32,  3.65s/it, loss=3.1947, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [03:53<11:11,  3.55s/it, loss=3.1939, tokens/sMax input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [03:56<10:10,  3.25s/it, loss=3.1887, tokens/sMax input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [03:58<09:08,  2.93s/it, loss=3.1842, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [04:05<13:10,  4.25s/it, loss=3.1849, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [04:08<11:41,  3.79s/it, loss=3.1787, tokens/sMax input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [04:12<11:36,  3.78s/it, loss=3.1759, tokens/sMax input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [04:14<09:59,  3.27s/it, loss=3.1764, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [04:16<09:06,  3.00s/it, loss=3.1742, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [04:20<09:29,  3.15s/it, loss=3.1748, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [04:22<08:44,  2.91s/it, loss=3.1770, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:27<10:05,  3.39s/it, loss=3.1764, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:29<09:06,  3.07s/it, loss=3.1761, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:31<08:08,  2.76s/it, loss=3.1753, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:34<07:58,  2.72s/it, loss=3.1778, tokens/sMax input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [04:35<07:13,  2.48s/it, loss=3.1743, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [04:39<07:58,  2.75s/it, loss=3.1745, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [04:41<07:49,  2.71s/it, loss=3.1757, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [04:46<09:28,  3.31s/it, loss=3.1778, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [04:50<09:31,  3.34s/it, loss=3.1802, tokens/sMax input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [04:54<10:01,  3.54s/it, loss=3.1811, tokens/sMax input_id: 31959\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [04:56<08:52,  3.15s/it, loss=3.1787, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [05:00<09:29,  3.39s/it, loss=3.1762, tokens/sMax input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [05:03<09:13,  3.31s/it, loss=3.1762, tokens/sMax input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [05:09<11:24,  4.12s/it, loss=3.1745, tokens/sMax input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [05:12<10:21,  3.77s/it, loss=3.1732, tokens/sMax input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [05:14<09:16,  3.40s/it, loss=3.1685, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [05:16<07:55,  2.92s/it, loss=3.1665, tokens/sMax input_id: 31969\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [05:19<07:27,  2.76s/it, loss=3.1652, tokens/sMax input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [05:25<10:40,  3.98s/it, loss=3.1692, tokens/sMax input_id: 31958\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [05:28<09:38,  3.62s/it, loss=3.1680, tokens/sMax input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [05:32<09:50,  3.71s/it, loss=3.1677, tokens/sMax input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [05:35<09:31,  3.61s/it, loss=3.1660, tokens/sMax input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [05:39<09:08,  3.50s/it, loss=3.1665, tokens/sMax input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [05:40<07:37,  2.93s/it, loss=3.1616, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [05:43<07:09,  2.77s/it, loss=3.1638, tokens/sMax input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [05:46<07:09,  2.79s/it, loss=3.1594, tokens/sMax input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [05:48<06:36,  2.59s/it, loss=3.1578, tokens/sMax input_id: 31968\n",
      "Max target_input: 31967\n",
      "Max label: 31967\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [05:52<08:11,  3.23s/it, loss=3.1617, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [05:55<07:35,  3.02s/it, loss=3.1596, tokens/sMax input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [06:02<10:34,  4.23s/it, loss=3.1625, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [06:05<09:29,  3.82s/it, loss=3.1599, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [06:07<08:26,  3.42s/it, loss=3.1562, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [06:10<08:05,  3.30s/it, loss=3.1535, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [06:13<07:48,  3.21s/it, loss=3.1549, tokens/Max input_id: 31938\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [06:16<07:04,  2.93s/it, loss=3.1546, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [06:21<08:45,  3.65s/it, loss=3.1526, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [06:24<08:16,  3.47s/it, loss=3.1521, tokens/Max input_id: 31963\n",
      "Max target_input: 31998\n",
      "Max label: 31998\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [06:26<07:29,  3.17s/it, loss=3.1529, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [06:29<06:49,  2.91s/it, loss=3.1545, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [06:33<07:43,  3.31s/it, loss=3.1515, tokens/Max input_id: 31970\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [06:36<07:19,  3.16s/it, loss=3.1526, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [06:39<07:22,  3.21s/it, loss=3.1512, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [06:46<10:00,  4.38s/it, loss=3.1529, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [06:49<08:32,  3.77s/it, loss=3.1527, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [06:51<07:19,  3.26s/it, loss=3.1532, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [06:54<07:12,  3.23s/it, loss=3.1524, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [07:02<10:07,  4.57s/it, loss=3.1531, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [07:08<11:20,  5.16s/it, loss=3.1543, tokens/Max input_id: 31959\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [07:11<09:55,  4.55s/it, loss=3.1570, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [07:13<08:02,  3.71s/it, loss=3.1563, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [07:15<07:05,  3.30s/it, loss=3.1584, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [07:18<06:34,  3.08s/it, loss=3.1608, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [07:23<07:35,  3.59s/it, loss=3.1602, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [07:25<06:28,  3.08s/it, loss=3.1579, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [07:28<06:39,  3.19s/it, loss=3.1577, tokens/Max input_id: 31958\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [07:31<06:21,  3.07s/it, loss=3.1585, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [07:33<05:32,  2.71s/it, loss=3.1557, tokens/Max input_id: 31959\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [07:36<06:04,  2.99s/it, loss=3.1552, tokens/Max input_id: 31970\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [07:38<05:28,  2.71s/it, loss=3.1559, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [07:41<05:13,  2.62s/it, loss=3.1561, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [07:43<05:14,  2.64s/it, loss=3.1574, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [07:45<04:44,  2.41s/it, loss=3.1550, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [07:47<04:20,  2.22s/it, loss=3.1532, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [07:54<06:49,  3.53s/it, loss=3.1521, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [07:57<06:32,  3.41s/it, loss=3.1517, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [07:59<05:56,  3.13s/it, loss=3.1508, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [08:01<05:18,  2.82s/it, loss=3.1498, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [08:04<05:06,  2.74s/it, loss=3.1473, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [08:06<04:41,  2.54s/it, loss=3.1457, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [08:09<04:54,  2.68s/it, loss=3.1452, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [08:12<05:15,  2.89s/it, loss=3.1436, tokens/Max input_id: 31969\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [08:14<04:41,  2.61s/it, loss=3.1425, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [08:19<05:31,  3.09s/it, loss=3.1413, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [08:21<05:14,  2.97s/it, loss=3.1399, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [08:27<06:54,  3.94s/it, loss=3.1398, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [08:30<06:00,  3.47s/it, loss=3.1397, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [08:32<05:09,  3.00s/it, loss=3.1379, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [08:34<04:37,  2.72s/it, loss=3.1389, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [08:37<04:34,  2.72s/it, loss=3.1377, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [08:41<05:28,  3.28s/it, loss=3.1379, tokens/Max input_id: 31977\n",
      "Max target_input: 31990\n",
      "Max label: 31990\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [08:45<05:34,  3.38s/it, loss=3.1382, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [08:50<06:31,  4.00s/it, loss=3.1384, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [08:52<05:36,  3.47s/it, loss=3.1380, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [08:57<06:02,  3.78s/it, loss=3.1384, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [08:59<05:06,  3.23s/it, loss=3.1372, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [09:02<05:12,  3.32s/it, loss=3.1378, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [09:06<05:06,  3.29s/it, loss=3.1366, tokens/Max input_id: 31963\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [09:09<05:06,  3.33s/it, loss=3.1385, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [09:13<05:07,  3.38s/it, loss=3.1382, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [09:15<04:50,  3.23s/it, loss=3.1391, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [09:21<05:46,  3.89s/it, loss=3.1397, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [09:26<06:10,  4.21s/it, loss=3.1414, tokens/Max input_id: 31963\n",
      "Max target_input: 31977\n",
      "Max label: 31977\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [09:28<05:04,  3.50s/it, loss=3.1403, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [09:30<04:29,  3.13s/it, loss=3.1398, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [09:35<05:03,  3.57s/it, loss=3.1405, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [09:38<05:00,  3.57s/it, loss=3.1404, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [09:42<04:53,  3.53s/it, loss=3.1398, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [09:46<05:15,  3.85s/it, loss=3.1409, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [09:48<04:21,  3.22s/it, loss=3.1396, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [09:52<04:32,  3.41s/it, loss=3.1397, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [09:59<05:50,  4.43s/it, loss=3.1385, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [10:01<05:05,  3.92s/it, loss=3.1379, tokens/Max input_id: 31959\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [10:04<04:38,  3.61s/it, loss=3.1382, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [10:06<03:59,  3.15s/it, loss=3.1386, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [10:08<03:27,  2.76s/it, loss=3.1400, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [10:12<03:48,  3.09s/it, loss=3.1396, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [10:14<03:31,  2.89s/it, loss=3.1406, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [10:17<03:28,  2.90s/it, loss=3.1397, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [10:20<03:19,  2.81s/it, loss=3.1406, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [10:22<03:09,  2.70s/it, loss=3.1412, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [10:24<02:51,  2.48s/it, loss=3.1393, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [10:31<04:22,  3.86s/it, loss=3.1383, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [10:35<04:12,  3.76s/it, loss=3.1384, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [10:37<03:39,  3.32s/it, loss=3.1376, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [10:40<03:15,  3.01s/it, loss=3.1378, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [10:44<03:41,  3.46s/it, loss=3.1375, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [10:46<03:04,  2.93s/it, loss=3.1357, tokens/Max input_id: 31977\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [10:50<03:23,  3.28s/it, loss=3.1355, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [10:53<03:21,  3.31s/it, loss=3.1349, tokens/Max input_id: 31964\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [11:00<04:27,  4.46s/it, loss=3.1345, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [11:03<03:54,  3.97s/it, loss=3.1339, tokens/Max input_id: 31970\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [11:07<03:40,  3.81s/it, loss=3.1324, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [11:09<03:17,  3.47s/it, loss=3.1320, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [11:14<03:33,  3.81s/it, loss=3.1318, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [11:16<03:04,  3.35s/it, loss=3.1313, tokens/Max input_id: 31970\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [11:19<02:49,  3.13s/it, loss=3.1309, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [11:21<02:33,  2.89s/it, loss=3.1299, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [11:26<03:06,  3.59s/it, loss=3.1285, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [11:31<03:21,  3.96s/it, loss=3.1277, tokens/Max input_id: 31977\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [11:36<03:34,  4.28s/it, loss=3.1264, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [11:42<03:59,  4.89s/it, loss=3.1270, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [11:50<04:37,  5.78s/it, loss=3.1278, tokens/Max input_id: 31963\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [11:53<03:50,  4.89s/it, loss=3.1274, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [11:56<03:11,  4.17s/it, loss=3.1268, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [11:59<03:02,  4.05s/it, loss=3.1274, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [12:02<02:44,  3.73s/it, loss=3.1275, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [12:08<03:07,  4.35s/it, loss=3.1287, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [12:11<02:38,  3.77s/it, loss=3.1289, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [12:13<02:21,  3.46s/it, loss=3.1296, tokens/Max input_id: 31958\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [12:17<02:26,  3.66s/it, loss=3.1288, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [12:22<02:31,  3.90s/it, loss=3.1276, tokens/Max input_id: 31958\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [12:27<02:44,  4.34s/it, loss=3.1263, tokens/Max input_id: 31977\n",
      "Max target_input: 31953\n",
      "Max label: 31953\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [12:29<02:16,  3.68s/it, loss=3.1259, tokens/Max input_id: 31977\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [12:32<02:01,  3.36s/it, loss=3.1259, tokens/Max input_id: 31963\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [12:34<01:40,  2.87s/it, loss=3.1248, tokens/Max input_id: 31970\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [12:36<01:30,  2.66s/it, loss=3.1250, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [12:41<01:54,  3.48s/it, loss=3.1250, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [12:45<01:54,  3.58s/it, loss=3.1249, tokens/Max input_id: 31959\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [12:48<01:40,  3.25s/it, loss=3.1245, tokens/Max input_id: 31957\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [12:50<01:31,  3.04s/it, loss=3.1257, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [12:54<01:31,  3.16s/it, loss=3.1249, tokens/Max input_id: 31977\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [12:57<01:29,  3.20s/it, loss=3.1234, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [13:01<01:31,  3.37s/it, loss=3.1233, tokens/Max input_id: 31970\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [13:06<01:39,  3.82s/it, loss=3.1249, tokens/Max input_id: 31963\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [13:08<01:22,  3.31s/it, loss=3.1241, tokens/Max input_id: 31977\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [13:10<01:10,  2.94s/it, loss=3.1219, tokens/Max input_id: 31977\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [13:12<00:59,  2.59s/it, loss=3.1207, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [13:14<00:58,  2.64s/it, loss=3.1201, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [13:18<01:03,  3.03s/it, loss=3.1199, tokens/Max input_id: 31963\n",
      "Max target_input: 31957\n",
      "Max label: 31957\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [13:20<00:53,  2.67s/it, loss=3.1185, tokens/Max input_id: 31963\n",
      "Max target_input: 31959\n",
      "Max label: 31959\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [13:25<01:01,  3.24s/it, loss=3.1184, tokens/Max input_id: 31970\n",
      "Max target_input: 31962\n",
      "Max label: 31962\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [13:32<01:19,  4.43s/it, loss=3.1181, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [13:34<01:02,  3.66s/it, loss=3.1172, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [13:39<01:08,  4.26s/it, loss=3.1164, tokens/Max input_id: 31958\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [13:42<00:55,  3.71s/it, loss=3.1168, tokens/Max input_id: 31978\n",
      "Max target_input: 31978\n",
      "Max label: 31978\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [13:48<01:02,  4.43s/it, loss=3.1184, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [13:51<00:53,  4.15s/it, loss=3.1178, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [13:54<00:44,  3.73s/it, loss=3.1171, tokens/Max input_id: 31970\n",
      "Max target_input: 31969\n",
      "Max label: 31969\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [13:59<00:44,  4.01s/it, loss=3.1179, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [14:01<00:35,  3.54s/it, loss=3.1177, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [14:03<00:28,  3.14s/it, loss=3.1175, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [14:08<00:29,  3.63s/it, loss=3.1187, tokens/Max input_id: 31963\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [14:11<00:23,  3.33s/it, loss=3.1179, tokens/Max input_id: 31963\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [14:14<00:19,  3.31s/it, loss=3.1172, tokens/Max input_id: 31963\n",
      "Max target_input: 31975\n",
      "Max label: 31975\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [14:16<00:14,  2.98s/it, loss=3.1167, tokens/Max input_id: 31970\n",
      "Max target_input: 31958\n",
      "Max label: 31958\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [14:20<00:12,  3.20s/it, loss=3.1160, tokens/Max input_id: 31963\n",
      "Max target_input: 31986\n",
      "Max label: 31986\n",
      "Training:  99%|█████████▉| 247/250 [14:26<00:11,  3.92s/it, loss=3.1175, tokens/Max input_id: 31963\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training:  99%|█████████▉| 248/250 [14:28<00:07,  3.55s/it, loss=3.1175, tokens/Max input_id: 31970\n",
      "Max target_input: 31970\n",
      "Max label: 31970\n",
      "Training: 100%|█████████▉| 249/250 [14:31<00:03,  3.19s/it, loss=3.1178, tokens/Max input_id: 31970\n",
      "Max target_input: 31963\n",
      "Max label: 31963\n",
      "Training: 100%|██████████| 250/250 [14:48<00:00,  3.55s/it, loss=3.1191, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size:Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      " 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:07<03:57,  7.68s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:09<01:59,  3.98s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:10<01:20,  2.78s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:11<00:56,  2.03s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:12<00:46,  1.73s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:14<00:46,  1.78s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:15<00:37,  1.48s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:16<00:31,  1.32s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:17<00:30,  1.34s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:18<00:25,  1.18s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:19<00:24,  1.16s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:20<00:20,  1.03s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:22<00:24,  1.29s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:22<00:20,  1.14s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:23<00:18,  1.09s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:24<00:16,  1.01s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:25<00:15,  1.03s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:26<00:13,  1.00it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:27<00:12,  1.00it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:29<00:14,  1.18s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:30<00:11,  1.03s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:31<00:10,  1.03s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:32<00:09,  1.07s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:33<00:08,  1.12s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:34<00:07,  1.08s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:36<00:08,  1.37s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:37<00:06,  1.22s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:50<00:00,  1.58s/it]\n",
      "Removed old checkpoint: model_epoch_10.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_10.pt\n",
      "Saved training results to training_results_20250511_185336.csv\n",
      "Train Loss: 3.1191\n",
      "Val Loss: 4.7265\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: ?\n"
     ]
    }
   ],
   "source": [
    "# tokenizer with train/test split\n",
    "\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Training new tokenizer...\n",
      "Train: 8000, Val: 1000, Test: 1000\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: de-en/europarl-v7.de-en.de\n",
      "  input: de-en/europarl-v7.de-en.en\n",
      "  input_format: \n",
      "  model_prefix: translation_tokenizer\n",
      "  model_type: BPE\n",
      "  vocab_size: 32000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: [DE]\n",
      "  user_defined_symbols: [EN]\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 1\n",
      "  bos_id: 2\n",
      "  eos_id: 3\n",
      "  pad_id: 0\n",
      "  unk_piece: [UNK]\n",
      "  bos_piece: [BOS]\n",
      "  eos_piece: [EOS]\n",
      "  pad_piece: [PAD]\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: de-en/europarl-v7.de-en.de\n",
      "trainer_interface.cc(147) LOG(INFO) Loaded 1000000 lines\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: de-en/europarl-v7.de-en.en\n",
      "trainer_interface.cc(147) LOG(INFO) Loaded 2000000 lines\n",
      "trainer_interface.cc(147) LOG(INFO) Loaded 3000000 lines\n",
      "trainer_interface.cc(124) LOG(WARNING) Too many sentences are loaded! (3829129), which may slow down training.\n",
      "trainer_interface.cc(126) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n",
      "trainer_interface.cc(129) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 3829129 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: [PAD]\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: [UNK]\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: [BOS]\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: [EOS]\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: [DE]\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: [EN]\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=609672380\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 100% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=302\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 3829129 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 3829129\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 871555\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14051866 min_freq=4158\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3310946 size=20 all=6763 active=2554 piece=an\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2013678 size=40 all=8491 active=4282 piece=▁un\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1358869 size=60 all=9898 active=5689 piece=▁A\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=959414 size=80 all=12040 active=7831 piece=icht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=799303 size=100 all=14485 active=10276 piece=ve\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=785312 min_freq=66313\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=682230 size=120 all=16267 active=2690 piece=▁den\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=552621 size=140 all=18304 active=4727 piece=▁im\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=455119 size=160 all=19836 active=6259 piece=est\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=397176 size=180 all=21520 active=7943 piece=ommission\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=342764 size=200 all=22835 active=9258 piece=sp\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=341942 min_freq=50995\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=307705 size=220 all=24733 active=2872 piece=end\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=285753 size=240 all=26646 active=4785 piece=▁all\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=255923 size=260 all=28662 active=6801 piece=▁auch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=237233 size=280 all=30661 active=8800 piece=▁me\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=215910 size=300 all=32924 active=11063 piece=olit\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=215134 min_freq=30497\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=204381 size=320 all=34978 active=3641 piece=ische\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=188226 size=340 all=36510 active=5173 piece=▁i\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=174853 size=360 all=37790 active=6453 piece=räs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=164015 size=380 all=39985 active=8648 piece=▁sie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=153982 size=400 all=41457 active=10120 piece=▁there\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=153602 min_freq=21645\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=144384 size=420 all=43006 active=3612 piece=ther\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=136159 size=440 all=45513 active=6119 piece=▁Ent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=128129 size=460 all=46692 active=7298 piece=anz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=122110 size=480 all=48296 active=8902 piece=▁Ge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=117949 size=500 all=50064 active=10670 piece=elt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=117855 min_freq=16467\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=114051 size=520 all=51358 active=3617 piece=▁you\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=108565 size=540 all=52701 active=4960 piece=▁more\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=102348 size=560 all=53989 active=6248 piece=oll\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=98250 size=580 all=55592 active=7851 piece=▁like\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=93418 size=600 all=56543 active=8802 piece=▁cons\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=93240 min_freq=13695\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=91194 size=620 all=57796 active=4063 piece=iert\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=88121 size=640 all=59174 active=5441 piece=▁eff\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=84736 size=660 all=60184 active=6451 piece=▁ges\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81782 size=680 all=61540 active=7807 piece=▁Men\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77979 size=700 all=62782 active=9049 piece=ject\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=77790 min_freq=11616\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=75298 size=720 all=63744 active=4065 piece=ated\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72674 size=740 all=65095 active=5416 piece=etzt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=69987 size=760 all=66705 active=7026 piece=ever\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=67679 size=780 all=67539 active=7860 piece=nung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66171 size=800 all=69025 active=9346 piece=ider\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=66000 min_freq=9985\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=63702 size=820 all=70651 active=4975 piece=fl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61351 size=840 all=72542 active=6866 piece=▁Zusammen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=59779 size=860 all=73571 active=7895 piece=▁ins\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58345 size=880 all=74529 active=8853 piece=▁bereit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56865 size=900 all=75271 active=9595 piece=pon\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=56865 min_freq=8593\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55472 size=920 all=76481 active=4922 piece=tre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54063 size=940 all=77908 active=6349 piece=▁Änder\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53121 size=960 all=79098 active=7539 piece=äl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52076 size=980 all=80396 active=8837 piece=hn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50027 size=1000 all=81499 active=9940 piece=▁gibt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=50015 min_freq=7610\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48897 size=1020 all=82790 active=5366 piece=▁keine\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47703 size=1040 all=83735 active=6311 piece=enden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46381 size=1060 all=84579 active=7155 piece=▁jedoch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45009 size=1080 all=86225 active=8801 piece=els\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44091 size=1100 all=87711 active=10287 piece=itiz\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=44029 min_freq=6825\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42705 size=1120 all=88560 active=5218 piece=kl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41794 size=1140 all=89786 active=6444 piece=wn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40922 size=1160 all=90514 active=7172 piece=▁There\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40105 size=1180 all=91347 active=8005 piece=▁ac\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39304 size=1200 all=92324 active=8982 piece=▁bring\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=39268 min_freq=6261\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38625 size=1220 all=93164 active=5448 piece=ffent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37849 size=1240 all=93946 active=6230 piece=▁two\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37353 size=1260 all=94412 active=6696 piece=▁cannot\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36828 size=1280 all=95542 active=7826 piece=▁same\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36279 size=1300 all=96689 active=8973 piece=▁unserer\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=36267 min_freq=5775\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35675 size=1320 all=97803 active=5949 piece=▁most\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34778 size=1340 all=98807 active=6953 piece=▁techn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34192 size=1360 all=99465 active=7611 piece=▁letz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33585 size=1380 all=100459 active=8605 piece=vernment\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33167 size=1400 all=101230 active=9376 piece=▁sozial\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=33129 min_freq=5282\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32319 size=1420 all=101876 active=5679 piece=▁world\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31664 size=1440 all=102403 active=6206 piece=▁both\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31020 size=1460 all=102917 active=6720 piece=▁Community\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30382 size=1480 all=103533 active=7336 piece=▁get\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29960 size=1500 all=104210 active=8013 piece=▁Zusammenarbeit\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=29870 min_freq=4946\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29499 size=1520 all=104880 active=5880 piece=▁last\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29073 size=1540 all=105777 active=6777 piece=ster\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28663 size=1560 all=106872 active=7872 piece=▁gut\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28304 size=1580 all=107548 active=8548 piece=▁einige\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27900 size=1600 all=108272 active=9272 piece=reaty\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=27899 min_freq=4625\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27416 size=1620 all=108998 active=6135 piece=ade\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27031 size=1640 all=109921 active=7058 piece=▁Unternehmen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26680 size=1660 all=110902 active=8039 piece=ules\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26306 size=1680 all=111941 active=9078 piece=▁Q\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25937 size=1700 all=113309 active=10446 piece=▁allow\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=25911 min_freq=4291\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25524 size=1720 all=114215 active=6566 piece=markt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25214 size=1740 all=114981 active=7332 piece=▁Ha\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24916 size=1760 all=115679 active=8030 piece=▁Is\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24454 size=1780 all=116331 active=8682 piece=▁differ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24116 size=1800 all=117067 active=9418 piece=stimmung\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24114 min_freq=4024\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23708 size=1820 all=118253 active=7001 piece=▁Verbrauch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23508 size=1840 all=118892 active=7640 piece=▁Frauen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23153 size=1860 all=119855 active=8603 piece=▁Minister\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22901 size=1880 all=120289 active=9037 piece=riften\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22675 size=1900 all=120652 active=9400 piece=sequ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22649 min_freq=3820\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22406 size=1920 all=121457 active=6814 piece=vorsch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22136 size=1940 all=122296 active=7653 piece=▁med\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21791 size=1960 all=122709 active=8066 piece=▁Fort\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21536 size=1980 all=123539 active=8896 piece=▁Gebie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21222 size=2000 all=124245 active=9602 piece=zept\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=21194 min_freq=3640\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20861 size=2020 all=125062 active=6984 piece=▁Aussprache\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20631 size=2040 all=125761 active=7683 piece=▁colle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20370 size=2060 all=126582 active=8504 piece=▁But\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20057 size=2080 all=127444 active=9366 piece=▁Schw\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19812 size=2100 all=128582 active=10504 piece=▁whole\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=19803 min_freq=3409\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19470 size=2120 all=129316 active=7163 piece=ising\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19233 size=2140 all=130004 active=7851 piece=000\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19020 size=2160 all=130413 active=8260 piece=blick\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18813 size=2180 all=131046 active=8893 piece=hält\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18680 size=2200 all=131875 active=9722 piece=▁three\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18676 min_freq=3246\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18476 size=2220 all=132753 active=7467 piece=▁Weise\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18317 size=2240 all=133080 active=7794 piece=arante\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18110 size=2260 all=133505 active=8219 piece=ustrie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17948 size=2280 all=134458 active=9172 piece=▁drei\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17780 size=2300 all=135182 active=9896 piece=▁specific\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17778 min_freq=3083\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17562 size=2320 all=136081 active=7653 piece=ierte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17388 size=2340 all=136501 active=8073 piece=▁Stra\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17201 size=2360 all=137004 active=8576 piece=▁Beispiel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17076 size=2380 all=137605 active=9177 piece=▁Jahre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16939 size=2400 all=138142 active=9714 piece=▁Änderungsantrag\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16938 min_freq=2942\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16773 size=2420 all=138609 active=7375 piece=rech\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16616 size=2440 all=139561 active=8327 piece=aussch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16443 size=2460 all=140087 active=8853 piece=armon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16302 size=2480 all=140786 active=9552 piece=▁activ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16150 size=2500 all=141272 active=10038 piece=▁responsibility\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16139 min_freq=2822\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15979 size=2520 all=142098 active=7890 piece=lein\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15726 size=2540 all=142979 active=8771 piece=▁12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15552 size=2560 all=143525 active=9317 piece=▁großen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15362 size=2580 all=144237 active=10029 piece=raum\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15258 size=2600 all=144934 active=10726 piece=▁dr\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15258 min_freq=2678\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15133 size=2620 all=145333 active=7619 piece=oten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14969 size=2640 all=146339 active=8625 piece=▁Ihr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14808 size=2660 all=146660 active=8946 piece=stehen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14698 size=2680 all=146972 active=9258 piece=▁Uns\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14573 size=2700 all=147828 active=10114 piece=▁je\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14566 min_freq=2572\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14439 size=2720 all=148144 active=7694 piece=▁Verantwortung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14329 size=2740 all=148477 active=8027 piece=▁strong\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14206 size=2760 all=149023 active=8573 piece=zen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14078 size=2780 all=149597 active=9147 piece=züglich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13979 size=2800 all=150103 active=9653 piece=gang\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13945 min_freq=2489\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13797 size=2820 all=150698 active=8013 piece=gent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13665 size=2840 all=151404 active=8719 piece=▁werde\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13588 size=2860 all=151827 active=9142 piece=▁Institutionen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13485 size=2880 all=152365 active=9680 piece=kes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13386 size=2900 all=153066 active=10381 piece=cen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13368 min_freq=2386\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13256 size=2920 all=153775 active=8283 piece=▁Dank\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13139 size=2940 all=154600 active=9108 piece=▁beispiel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13016 size=2960 all=155438 active=9946 piece=▁educ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12870 size=2980 all=155990 active=10498 piece=▁för\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12761 size=3000 all=156317 active=10825 piece=▁emphas\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12759 min_freq=2289\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12681 size=3020 all=156924 active=8417 piece=▁Verpflicht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12586 size=3040 all=157570 active=9063 piece=▁disk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12468 size=3060 all=158076 active=9569 piece=ultur\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12299 size=3080 all=158925 active=10418 piece=▁verschiedenen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12200 size=3100 all=159197 active=10690 piece=verfahren\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12198 min_freq=2193\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12108 size=3120 all=159997 active=8589 piece=▁Parte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11999 size=3140 all=160473 active=9065 piece=ning\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11925 size=3160 all=160879 active=9471 piece=▁pass\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11818 size=3180 all=161236 active=9828 piece=itionen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11720 size=3200 all=161884 active=10476 piece=▁ear\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11716 min_freq=2121\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11632 size=3220 all=162491 active=8691 piece=orted\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11550 size=3240 all=162853 active=9053 piece=▁Prior\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11458 size=3260 all=163452 active=9652 piece=▁erklär\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11389 size=3280 all=163915 active=10115 piece=▁demon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11281 size=3300 all=164216 active=10416 piece=▁experien\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11280 min_freq=2050\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11182 size=3320 all=164522 active=8513 piece=▁hon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11064 size=3340 all=165085 active=9076 piece=▁exc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10984 size=3360 all=165792 active=9783 piece=inge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10877 size=3380 all=166686 active=10677 piece=▁Heraus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10801 size=3400 all=167160 active=11151 piece=arbeiten\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10799 min_freq=1981\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10712 size=3420 all=167659 active=8755 piece=▁Kosovo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10619 size=3440 all=167944 active=9040 piece=▁Präsidentschaft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10551 size=3460 all=168788 active=9884 piece=▁Fortschritte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10461 size=3480 all=169435 active=10531 piece=folgen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10383 size=3500 all=170105 active=11201 piece=fre\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10383 min_freq=1906\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10279 size=3520 all=171065 active=9215 piece=▁Hier\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10198 size=3540 all=171699 active=9849 piece=▁begrüße\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10125 size=3560 all=172383 active=10533 piece=▁Initiative\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10040 size=3580 all=172694 active=10844 piece=▁fördern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9979 size=3600 all=173150 active=11300 piece=part\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9978 min_freq=1839\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9906 size=3620 all=173606 active=8972 piece=ides\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9839 size=3640 all=174025 active=9391 piece=ände\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9750 size=3660 all=174710 active=10076 piece=▁Pe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9675 size=3680 all=175287 active=10653 piece=▁ph\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9629 size=3700 all=175820 active=11186 piece=▁sustainable\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9617 min_freq=1778\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9538 size=3720 all=176437 active=9408 piece=wan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9467 size=3740 all=177082 active=10053 piece=▁vorgesehen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9350 size=3760 all=177538 active=10509 piece=ingt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9298 size=3780 all=178095 active=11066 piece=itim\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9245 size=3800 all=178865 active=11836 piece=▁schnell\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9243 min_freq=1726\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9206 size=3820 all=179560 active=9624 piece=▁Eng\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9154 size=3840 all=179945 active=10009 piece=ott\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9097 size=3860 all=180711 active=10775 piece=mitteln\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9017 size=3880 all=181439 active=11503 piece=missions\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8944 size=3900 all=182074 active=12138 piece=▁illegal\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8929 min_freq=1670\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8874 size=3920 all=182484 active=9507 piece=▁Nicht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8794 size=3940 all=182972 active=9995 piece=alu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8710 size=3960 all=183251 active=10274 piece=▁Secondly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8616 size=3980 all=183587 active=10610 piece=heben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8577 size=4000 all=184756 active=11779 piece=▁fünf\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8574 min_freq=1620\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8502 size=4020 all=185165 active=9632 piece=▁Nov\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8450 size=4040 all=185657 active=10124 piece=▁elections\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8393 size=4060 all=185943 active=10410 piece=abkommen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8336 size=4080 all=186626 active=11093 piece=arent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8282 size=4100 all=187346 active=11813 piece=▁Ergebnisse\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8278 min_freq=1567\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8223 size=4120 all=187813 active=9835 piece=arbeitet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8177 size=4140 all=188063 active=10085 piece=inne\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8121 size=4160 all=188617 active=10639 piece=▁corre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8067 size=4180 all=189234 active=11256 piece=▁gele\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8033 size=4200 all=189716 active=11738 piece=produ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8033 min_freq=1517\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7983 size=4220 all=190199 active=9733 piece=▁solchen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7924 size=4240 all=190704 active=10238 piece=ested\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7872 size=4260 all=191440 active=10974 piece=ending\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7836 size=4280 all=191882 active=11416 piece=würd\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7786 size=4300 all=192684 active=12218 piece=sterdam\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7784 min_freq=1470\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7743 size=4320 all=193035 active=9972 piece=▁Amsterdam\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7693 size=4340 all=193442 active=10379 piece=▁closed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7635 size=4360 all=193780 active=10717 piece=▁value\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7593 size=4380 all=194427 active=11364 piece=▁relig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7545 size=4400 all=194750 active=11687 piece=▁nature\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7542 min_freq=1430\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7489 size=4420 all=195269 active=10255 piece=▁Vertreter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7431 size=4440 all=195504 active=10490 piece=▁unabhäng\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7391 size=4460 all=195751 active=10737 piece=isieren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7345 size=4480 all=196311 active=11297 piece=▁purs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7298 size=4500 all=197246 active=12232 piece=▁Qualität\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7295 min_freq=1390\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7244 size=4520 all=197870 active=10481 piece=▁task\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7197 size=4540 all=198482 active=11093 piece=achten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7154 size=4560 all=198923 active=11534 piece=▁emer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7122 size=4580 all=199584 active=12195 piece=▁Prä\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7086 size=4600 all=200030 active=12641 piece=▁Änderungen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7083 min_freq=1344\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7040 size=4620 all=200424 active=10395 piece=▁legitim\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7000 size=4640 all=200748 active=10719 piece=zeichne\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6955 size=4660 all=201122 active=11093 piece=▁eingehen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6925 size=4680 all=201427 active=11398 piece=üng\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6910 size=4700 all=201758 active=11729 piece=▁Portugal\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6909 min_freq=1313\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6864 size=4720 all=201999 active=10328 piece=▁Ress\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6821 size=4740 all=202250 active=10579 piece=▁Balk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6786 size=4760 all=202672 active=11001 piece=▁partnership\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6764 size=4780 all=203159 active=11488 piece=▁Nie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6717 size=4800 all=203539 active=11868 piece=▁folgt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6713 min_freq=1283\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6658 size=4820 all=203873 active=10511 piece=▁completely\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6603 size=4840 all=204331 active=10969 piece=▁Zivil\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6567 size=4860 all=204677 active=11315 piece=ests\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6516 size=4880 all=205363 active=12001 piece=äus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6486 size=4900 all=205882 active=12520 piece=▁diejenigen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6485 min_freq=1252\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6452 size=4920 all=206171 active=10584 piece=werk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6423 size=4940 all=206705 active=11118 piece=▁applied\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6399 size=4960 all=207148 active=11561 piece=ulf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6377 size=4980 all=207759 active=12172 piece=▁CO\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6328 size=5000 all=208072 active=12485 piece=▁behind\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6327 min_freq=1220\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6299 size=5020 all=208733 active=11063 piece=▁ensuring\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6253 size=5040 all=209055 active=11385 piece=▁Dezember\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6209 size=5060 all=209316 active=11646 piece=igran\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6181 size=5080 all=209956 active=12286 piece=troll\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6134 size=5100 all=210611 active=12941 piece=▁derart\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6132 min_freq=1188\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6105 size=5120 all=211188 active=11103 piece=▁Barroso\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6076 size=5140 all=211368 active=11283 piece=▁Reformen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6042 size=5160 all=211869 active=11784 piece=▁adoption\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6003 size=5180 all=212098 active=12013 piece=ume\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5971 size=5200 all=212412 active=12327 piece=▁ermög\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5971 min_freq=1162\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5944 size=5220 all=213020 active=11227 piece=ij\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5911 size=5240 all=213716 active=11923 piece=▁plann\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5878 size=5260 all=214141 active=12348 piece=▁ill\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5850 size=5280 all=214417 active=12624 piece=▁trying\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5817 size=5300 all=214911 active=13118 piece=uption\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5815 min_freq=1133\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5802 size=5320 all=215486 active=11312 piece=▁prüfen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5773 size=5340 all=215928 active=11754 piece=▁occas\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5749 size=5360 all=216243 active=12069 piece=ourn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5719 size=5380 all=216473 active=12299 piece=▁Drit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5694 size=5400 all=217204 active=13030 piece=unch\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5692 min_freq=1103\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5659 size=5420 all=217452 active=11078 piece=▁bar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5621 size=5440 all=217777 active=11403 piece=iko\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5589 size=5460 all=218072 active=11698 piece=okraten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5568 size=5480 all=218429 active=12055 piece=▁wrong\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5531 size=5500 all=218827 active=12453 piece=▁nationale\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5530 min_freq=1080\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5491 size=5520 all=219020 active=11134 piece=▁participation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5460 size=5540 all=219323 active=11437 piece=▁Gesprä\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5439 size=5560 all=219553 active=11667 piece=▁purpose\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5399 size=5580 all=219942 active=12056 piece=gef\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5357 size=5600 all=220688 active=12802 piece=▁feststellen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5354 min_freq=1057\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5328 size=5620 all=221021 active=11368 piece=mand\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5300 size=5640 all=221659 active=12006 piece=▁closely\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5277 size=5660 all=221921 active=12268 piece=icherung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5254 size=5680 all=222589 active=12936 piece=▁urgent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5227 size=5700 all=222896 active=13243 piece=▁jede\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5227 min_freq=1034\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5207 size=5720 all=223349 active=11598 piece=cement\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5178 size=5740 all=223765 active=12014 piece=▁Ky\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5153 size=5760 all=224367 active=12616 piece=▁Abschluss\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5130 size=5780 all=224727 active=12976 piece=▁beein\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5105 size=5800 all=225184 active=13433 piece=kung\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5105 min_freq=1007\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5080 size=5820 all=225647 active=11704 piece=▁equality\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5055 size=5840 all=226029 active=12086 piece=▁Gebieten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5030 size=5860 all=226402 active=12459 piece=iddle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5001 size=5880 all=226642 active=12699 piece=▁supporting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4974 size=5900 all=227149 active=13206 piece=lüsse\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4972 min_freq=986\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4960 size=5920 all=227374 active=11570 piece=▁Spe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4936 size=5940 all=227853 active=12049 piece=▁extens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4914 size=5960 all=228060 active=12256 piece=igher\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4889 size=5980 all=228503 active=12699 piece=▁Haushaltsplan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4870 size=6000 all=228971 active=13167 piece=▁opposition\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4870 min_freq=968\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4848 size=6020 all=229298 active=11771 piece=▁discussing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4833 size=6040 all=229783 active=12256 piece=ired\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4807 size=6060 all=230193 active=12666 piece=▁trag\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4781 size=6080 all=230498 active=12971 piece=▁South\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4763 size=6100 all=230958 active=13431 piece=▁Security\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4760 min_freq=946\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4733 size=6120 all=231210 active=11799 piece=ournal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4707 size=6140 all=231415 active=12004 piece=▁depend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4684 size=6160 all=231749 active=12338 piece=▁Ro\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4659 size=6180 all=232103 active=12692 piece=▁check\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4642 size=6200 all=232497 active=13086 piece=▁Spanish\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4641 min_freq=926\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4623 size=6220 all=233193 active=12321 piece=▁offensichtlich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4591 size=6240 all=233636 active=12764 piece=body\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4571 size=6260 all=233793 active=12921 piece=▁Empfehlungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4552 size=6280 all=233983 active=13111 piece=▁Tour\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4529 size=6300 all=234339 active=13467 piece=1)\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4526 min_freq=908\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4506 size=6320 all=234838 active=12169 piece=▁recognise\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4488 size=6340 all=235311 active=12642 piece=rated\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4474 size=6360 all=235684 active=13015 piece=▁recognition\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4457 size=6380 all=235951 active=13282 piece=▁einver\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4439 size=6400 all=236271 active=13602 piece=▁lässt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4439 min_freq=890\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4422 size=6420 all=236498 active=12041 piece=▁pointed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4406 size=6440 all=236937 active=12480 piece=atlant\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4382 size=6460 all=237457 active=13000 piece=▁asking\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4349 size=6480 all=237777 active=13320 piece=▁Hil\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4335 size=6500 all=237994 active=13537 piece=istics\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4333 min_freq=872\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4307 size=6520 all=238477 active=12375 piece=▁initial\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4286 size=6540 all=238697 active=12595 piece=iell\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4263 size=6560 all=239230 active=13128 piece=ufact\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4251 size=6580 all=239735 active=13633 piece=▁strongly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4230 size=6600 all=240370 active=14268 piece=▁BSE\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4229 min_freq=853\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4213 size=6620 all=241077 active=12714 piece=▁sicherstellen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4196 size=6640 all=241533 active=13170 piece=▁loss\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4159 size=6660 all=241843 active=13480 piece=ypr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4145 size=6680 all=242451 active=14088 piece=möglich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4129 size=6700 all=242794 active=14431 piece=▁transfer\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4126 min_freq=833\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4112 size=6720 all=243184 active=12520 piece=▁fallen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4094 size=6740 all=243478 active=12814 piece=▁New\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4073 size=6760 all=243600 active=12936 piece=/98\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4059 size=6780 all=244101 active=13437 piece=▁Charter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4036 size=6800 all=244745 active=14081 piece=▁beteiligt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4034 min_freq=817\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4021 size=6820 all=245221 active=12713 piece=▁Veränderungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4000 size=6840 all=245537 active=13029 piece=▁Europol\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3989 size=6860 all=246011 active=13503 piece=▁excess\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3965 size=6880 all=246343 active=13835 piece=handlungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3947 size=6900 all=246658 active=14150 piece=▁Zuständigkeit\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3946 min_freq=800\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3931 size=6920 all=247063 active=12735 piece=va\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3914 size=6940 all=247540 active=13212 piece=▁persons\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3899 size=6960 all=247831 active=13503 piece=des\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3879 size=6980 all=248326 active=13998 piece=▁Klimawandel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3865 size=7000 all=248684 active=14356 piece=oke\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3865 min_freq=784\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3844 size=7020 all=248863 active=12591 piece=iode\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3827 size=7040 all=249008 active=12736 piece=Str\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3811 size=7060 all=249398 active=13126 piece=▁Bo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3798 size=7080 all=249913 active=13641 piece=▁28\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3785 size=7100 all=250418 active=14146 piece=▁guarantees\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3782 min_freq=769\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3765 size=7120 all=250707 active=12810 piece=▁occup\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3751 size=7140 all=251149 active=13252 piece=▁Überzeugung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3737 size=7160 all=251547 active=13650 piece=▁Ausführungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3719 size=7180 all=252099 active=14202 piece=ürk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3704 size=7200 all=252331 active=14434 piece=▁related\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3704 min_freq=756\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3689 size=7220 all=252616 active=12902 piece=▁structure\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3675 size=7240 all=252984 active=13270 piece=▁treaty\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3660 size=7260 all=253139 active=13425 piece=▁Accord\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3646 size=7280 all=253456 active=13742 piece=▁weshalb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3631 size=7300 all=253778 active=14064 piece=▁families\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3630 min_freq=745\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3613 size=7320 all=254077 active=12988 piece=istr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3595 size=7340 all=254326 active=13237 piece=▁vielmehr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3581 size=7360 all=254657 active=13568 piece=▁Vergleich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3568 size=7380 all=254949 active=13860 piece=▁target\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3554 size=7400 all=255160 active=14071 piece=cker\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3554 min_freq=733\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3542 size=7420 all=255566 active=13043 piece=Ber\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3529 size=7440 all=256123 active=13600 piece=▁moder\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3515 size=7460 all=256508 active=13985 piece=▁granted\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3496 size=7480 all=256746 active=14223 piece=▁mil\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3476 size=7500 all=257042 active=14519 piece=ada\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3476 min_freq=721\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3463 size=7520 all=257561 active=13308 piece=▁round\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3452 size=7540 all=258114 active=13861 piece=▁Charta\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3439 size=7560 all=258689 active=14436 piece=▁Sweden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3429 size=7580 all=259025 active=14772 piece=LAF\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3411 size=7600 all=259486 active=15233 piece=▁July\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3410 min_freq=706\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3396 size=7620 all=260179 active=13668 piece=▁Rumänien\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3375 size=7640 all=260387 active=13876 piece=▁Verfassungs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3361 size=7660 all=260500 active=13989 piece=kräfte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3351 size=7680 all=260727 active=14216 piece=▁changed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3342 size=7700 all=261071 active=14560 piece=▁range\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3342 min_freq=694\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3329 size=7720 all=261315 active=13294 piece=▁pol\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3314 size=7740 all=261637 active=13616 piece=zwungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3296 size=7760 all=261900 active=13879 piece=af\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3284 size=7780 all=262482 active=14461 piece=▁won\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3274 size=7800 all=262928 active=14907 piece=▁schwed\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3274 min_freq=682\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3262 size=7820 all=263194 active=13408 piece=▁leiden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3250 size=7840 all=263511 active=13725 piece=verletz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3236 size=7860 all=263780 active=13994 piece=▁Budgets\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3225 size=7880 all=264023 active=14237 piece=fare\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3211 size=7900 all=264387 active=14601 piece=roh\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3210 min_freq=673\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3198 size=7920 all=264920 active=13701 piece=▁otherwise\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3179 size=7940 all=265147 active=13928 piece=öhn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3170 size=7960 all=265475 active=14256 piece=finanz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3158 size=7980 all=266254 active=15035 piece=▁hours\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3143 size=8000 all=266533 active=15314 piece=▁darunter\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3143 min_freq=662\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3132 size=8020 all=267002 active=13793 piece=▁exec\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3119 size=8040 all=267124 active=13915 piece=▁inspect\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3107 size=8060 all=267680 active=14471 piece=▁Politiker\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3094 size=8080 all=267775 active=14566 piece=▁lautet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3083 size=8100 all=268127 active=14918 piece=▁factors\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3083 min_freq=652\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3071 size=8120 all=268297 active=13577 piece=▁Schaden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3056 size=8140 all=268593 active=13873 piece=▁Binnenmarktes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3043 size=8160 all=269145 active=14425 piece=▁Bulgaria\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3025 size=8180 all=269400 active=14680 piece=allel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3014 size=8200 all=269718 active=14998 piece=ox\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3014 min_freq=642\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3003 size=8220 all=270028 active=13703 piece=▁wichtigste\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2983 size=8240 all=270313 active=13988 piece=ungsbe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2972 size=8260 all=270938 active=14613 piece=▁zurückge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2957 size=8280 all=271491 active=15166 piece=▁Bestandteil\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2947 size=8300 all=271647 active=15322 piece=zwischen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2947 min_freq=631\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2937 size=8320 all=271801 active=13709 piece=▁insist\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2927 size=8340 all=271970 active=13878 piece=staatlichen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2916 size=8360 all=272424 active=14332 piece=mbudsman\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2901 size=8380 all=272719 active=14627 piece=▁impose\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2892 size=8400 all=272853 active=14761 piece=▁Formen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2892 min_freq=622\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2881 size=8420 all=273059 active=13848 piece=▁Stability\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2868 size=8440 all=273266 active=14055 piece=nüp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2856 size=8460 all=273504 active=14293 piece=▁dahin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2848 size=8480 all=273905 active=14694 piece=indungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2840 size=8500 all=274207 active=14996 piece=▁Mart\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2840 min_freq=612\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2828 size=8520 all=274714 active=14201 piece=▁customs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2818 size=8540 all=274999 active=14486 piece=▁attach\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2804 size=8560 all=275384 active=14871 piece=▁anstatt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2797 size=8580 all=276132 active=15619 piece=▁mission\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2788 size=8600 all=276340 active=15827 piece=▁ernsthaft\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2788 min_freq=600\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2778 size=8620 all=276534 active=14009 piece=▁rechtlichen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2768 size=8640 all=276919 active=14394 piece=▁Gespräche\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2754 size=8660 all=277082 active=14557 piece=▁Erwartungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2744 size=8680 all=277390 active=14865 piece=▁Umweltfragen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2732 size=8700 all=277923 active=15398 piece=▁Arzneimittel\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2731 min_freq=588\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2724 size=8720 all=278279 active=14223 piece=▁Straßburg\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2712 size=8740 all=278463 active=14407 piece=▁phys\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2700 size=8760 all=279087 active=15031 piece=▁verfüg\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2690 size=8780 all=279411 active=15355 piece=oking\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2678 size=8800 all=279795 active=15739 piece=▁auffordern\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2677 min_freq=578\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2671 size=8820 all=280015 active=14208 piece=▁Todesstrafe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2662 size=8840 all=280232 active=14425 piece=▁wodurch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2653 size=8860 all=280786 active=14979 piece=▁democrat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2642 size=8880 all=281170 active=15363 piece=▁verteidigen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2631 size=8900 all=281754 active=15947 piece=▁Leute\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2631 min_freq=567\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2621 size=8920 all=282305 active=14639 piece=ctor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2614 size=8940 all=282394 active=14728 piece=▁firmly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2606 size=8960 all=282617 active=14951 piece=▁wünsche\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2596 size=8980 all=283085 active=15419 piece=▁Alger\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2583 size=9000 all=283567 active=15901 piece=▁Städ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2583 min_freq=558\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2574 size=9020 all=283706 active=14311 piece=ini\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2567 size=9040 all=284011 active=14616 piece=▁lebens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2559 size=9060 all=284430 active=15035 piece=▁implic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2548 size=9080 all=284786 active=15391 piece=▁Grünen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2542 size=9100 all=285227 active=15832 piece=ishing\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2542 min_freq=550\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2533 size=9120 all=285556 active=14554 piece=▁verringern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2523 size=9140 all=285715 active=14713 piece=▁hauptsächlich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2515 size=9160 all=285977 active=14975 piece=▁Ohne\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2507 size=9180 all=286371 active=15369 piece=▁abuse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2501 size=9200 all=286663 active=15661 piece=▁undoubtedly\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2500 min_freq=541\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2490 size=9220 all=287110 active=14781 piece=▁agency\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2485 size=9240 all=287518 active=15189 piece=▁fiscal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2479 size=9260 all=287718 active=15389 piece=ichtlinie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2472 size=9280 all=288166 active=15837 piece=▁expectations\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2464 size=9300 all=288403 active=16074 piece=kund\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2464 min_freq=532\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2457 size=9320 all=288871 active=14815 piece=lässlich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2445 size=9340 all=289119 active=15063 piece=▁oblige\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2438 size=9360 all=289362 active=15306 piece=wers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2429 size=9380 all=289678 active=15622 piece=▁conciliation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2422 size=9400 all=290283 active=16227 piece=▁exploitation\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2421 min_freq=524\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2412 size=9420 all=290655 active=14887 piece=▁trifft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2404 size=9440 all=290940 active=15172 piece=▁danach\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2398 size=9460 all=291243 active=15475 piece=▁Paket\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2391 size=9480 all=291639 active=15871 piece=▁Beteiligten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2384 size=9500 all=291859 active=16091 piece=gebaut\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2384 min_freq=515\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2376 size=9520 all=292011 active=14730 piece=▁erleben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2367 size=9540 all=292380 active=15099 piece=▁Milch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2358 size=9560 all=292630 active=15349 piece=▁Stadt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2350 size=9580 all=292834 active=15553 piece=▁apart\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2343 size=9600 all=293207 active=15926 piece=▁umsetzen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2343 min_freq=508\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2333 size=9620 all=294033 active=15486 piece=▁jemand\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2327 size=9640 all=294318 active=15771 piece=auft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2321 size=9660 all=294787 active=16240 piece=obil\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2314 size=9680 all=295288 active=16741 piece=▁Kürz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2305 size=9700 all=295842 active=17295 piece=▁Kräfte\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2305 min_freq=498\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2297 size=9720 all=295962 active=14903 piece=techn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2289 size=9740 all=296279 active=15220 piece=▁budgets\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2280 size=9760 all=296942 active=15883 piece=▁waiting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2272 size=9780 all=297112 active=16053 piece=imor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2269 size=9800 all=297347 active=16288 piece=▁identity\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2268 min_freq=491\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2258 size=9820 all=298154 active=15675 piece=▁psy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2250 size=9840 all=298423 active=15944 piece=▁zunehmend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2242 size=9860 all=298900 active=16421 piece=IDS\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2235 size=9880 all=299252 active=16773 piece=ell\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2227 size=9900 all=299532 active=17053 piece=uung\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2227 min_freq=483\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2219 size=9920 all=300125 active=15556 piece=▁Sal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2214 size=9940 all=300500 active=15931 piece=verläss\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2205 size=9960 all=301014 active=16445 piece=▁strategischen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2201 size=9980 all=301455 active=16886 piece=▁playing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2193 size=10000 all=301886 active=17317 piece=▁antworten\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2193 min_freq=476\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2187 size=10020 all=302252 active=15461 piece=▁gewün\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2178 size=10040 all=302506 active=15715 piece=Mittel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2172 size=10060 all=302752 active=15961 piece=▁beeinträcht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2165 size=10080 all=303097 active=16306 piece=▁jährlich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2158 size=10100 all=303248 active=16457 piece=▁Bush\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2158 min_freq=470\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2149 size=10120 all=303530 active=15441 piece=mäßigen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2142 size=10140 all=303977 active=15888 piece=no\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2138 size=10160 all=304271 active=16182 piece=▁Senkung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2130 size=10180 all=304589 active=16500 piece=▁television\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2124 size=10200 all=304884 active=16795 piece=▁75\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2123 min_freq=462\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2117 size=10220 all=305205 active=15546 piece=house\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2109 size=10240 all=305689 active=16030 piece=izza\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2105 size=10260 all=305970 active=16311 piece=▁Gefühl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2099 size=10280 all=306152 active=16493 piece=Parl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2092 size=10300 all=306822 active=17163 piece=▁Hinweis\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2092 min_freq=455\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2089 size=10320 all=306936 active=15450 piece=▁transitional\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2081 size=10340 all=307145 active=15659 piece=▁timetable\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2072 size=10360 all=307269 active=15783 piece=/2003\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2065 size=10380 all=307545 active=16059 piece=-2013\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2058 size=10400 all=307755 active=16269 piece=▁possibly\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2058 min_freq=451\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2049 size=10420 all=307984 active=15617 piece=▁behaupten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2043 size=10440 all=308468 active=16101 piece=▁einseit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2039 size=10460 all=308862 active=16495 piece=▁Leistungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2034 size=10480 all=309079 active=16712 piece=▁sugar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2029 size=10500 all=309276 active=16909 piece=▁Roth\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2029 min_freq=445\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2023 size=10520 all=309499 active=15679 piece=▁Positionen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2017 size=10540 all=309777 active=15957 piece=▁Aufhebung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2011 size=10560 all=309865 active=16045 piece=▁überaus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2002 size=10580 all=310116 active=16296 piece=▁facilities\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1994 size=10600 all=310477 active=16657 piece=▁centres\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1994 min_freq=440\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1989 size=10620 all=310743 active=15789 piece=itives\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1984 size=10640 all=310827 active=15873 piece=▁audiovis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1978 size=10660 all=311180 active=16226 piece=related\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1971 size=10680 all=311416 active=16462 piece=▁heavy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1964 size=10700 all=311637 active=16683 piece=▁Souveränität\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1963 min_freq=433\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1957 size=10720 all=311903 active=15847 piece=atures\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1950 size=10740 all=312129 active=16073 piece=▁poten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1943 size=10760 all=312241 active=16185 piece=raf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1938 size=10780 all=312542 active=16486 piece=▁sorgfältig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1931 size=10800 all=312900 active=16844 piece=▁addressing\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1930 min_freq=428\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1927 size=10820 all=313178 active=15923 piece=Der\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1920 size=10840 all=313452 active=16197 piece=▁Grem\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1911 size=10860 all=313725 active=16470 piece=▁coal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1907 size=10880 all=313908 active=16653 piece=▁governing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1900 size=10900 all=314013 active=16758 piece=▁Jahrhunder\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1900 min_freq=423\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1893 size=10920 all=314342 active=16022 piece=▁refers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1887 size=10940 all=314623 active=16303 piece=▁hart\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1882 size=10960 all=314715 active=16395 piece=▁BIP\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1878 size=10980 all=314927 active=16607 piece=▁esc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1873 size=11000 all=315076 active=16756 piece=kontroll\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1873 min_freq=418\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1867 size=11020 all=315317 active=15866 piece=artige\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1861 size=11040 all=315567 active=16116 piece=▁Zahlungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1855 size=11060 all=315946 active=16495 piece=wertet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1851 size=11080 all=316213 active=16762 piece=▁considerably\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1846 size=11100 all=316432 active=16981 piece=▁Vorredner\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1845 min_freq=412\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1838 size=11120 all=316571 active=15958 piece=lles\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1832 size=11140 all=316877 active=16264 piece=attung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1828 size=11160 all=317178 active=16565 piece=▁verschw\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1821 size=11180 all=317633 active=17020 piece=▁gemeinsamer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1815 size=11200 all=317889 active=17276 piece=▁Autonom\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1815 min_freq=407\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1809 size=11220 all=318122 active=16117 piece=gerufen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1804 size=11240 all=318361 active=16356 piece=▁historical\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1797 size=11260 all=318465 active=16460 piece=▁schlagen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1791 size=11280 all=318586 active=16581 piece=▁geschä\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1786 size=11300 all=318853 active=16848 piece=▁regarded\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1786 min_freq=402\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1779 size=11320 all=319116 active=16206 piece=▁abschließend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1776 size=11340 all=319360 active=16450 piece=▁legitimacy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1772 size=11360 all=319612 active=16702 piece=▁präsent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1769 size=11380 all=319869 active=16959 piece=ubringen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1764 size=11400 all=320186 active=17276 piece=▁Jahrhundert\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1764 min_freq=398\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1759 size=11420 all=320444 active=16256 piece=▁Vision\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1755 size=11440 all=320583 active=16395 piece=▁affecting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1749 size=11460 all=320783 active=16595 piece=▁Mazed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1745 size=11480 all=321083 active=16895 piece=▁laufenden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1739 size=11500 all=321344 active=17156 piece=endung\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1739 min_freq=393\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1734 size=11520 all=321716 active=16416 piece=▁Ung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1731 size=11540 all=321929 active=16629 piece=▁aggress\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1728 size=11560 all=322385 active=17085 piece=▁Versorgung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1722 size=11580 all=322656 active=17356 piece=▁subjects\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1716 size=11600 all=322983 active=17683 piece=▁sake\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1716 min_freq=387\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1713 size=11620 all=323232 active=16399 piece=▁ziel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1708 size=11640 all=323339 active=16506 piece=▁leader\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1704 size=11660 all=323557 active=16724 piece=▁Gesetzgeb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1701 size=11680 all=323664 active=16831 piece=▁Betroffen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1696 size=11700 all=323987 active=17154 piece=▁ster\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1696 min_freq=383\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1690 size=11720 all=324265 active=16465 piece=▁Klimawandels\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1684 size=11740 all=324667 active=16867 piece=▁treaties\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1679 size=11760 all=324759 active=16959 piece=bod\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1675 size=11780 all=325236 active=17436 piece=▁unterbreiten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1670 size=11800 all=325387 active=17587 piece=like\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1670 min_freq=379\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1664 size=11820 all=325868 active=16733 piece=▁Slovakia\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1657 size=11840 all=326150 active=17015 piece=akis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1654 size=11860 all=326682 active=17547 piece=▁einführen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1648 size=11880 all=326983 active=17848 piece=▁macro\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1641 size=11900 all=327186 active=18051 piece=▁Gewäss\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1641 min_freq=373\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1637 size=11920 all=327419 active=16585 piece=▁expressing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1631 size=11940 all=327673 active=16839 piece=▁erheblichen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1625 size=11960 all=327998 active=17164 piece=ressive\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1621 size=11980 all=328165 active=17331 piece=▁representation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1615 size=12000 all=328692 active=17858 piece=▁Projekten\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1615 min_freq=369\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1610 size=12020 all=328837 active=16580 piece=▁eliminate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1604 size=12040 all=329038 active=16781 piece=sprach\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1598 size=12060 all=329382 active=17125 piece=▁broader\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1593 size=12080 all=329732 active=17475 piece=▁0.\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1589 size=12100 all=330192 active=17935 piece=▁EVP\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1589 min_freq=364\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1585 size=12120 all=330772 active=17088 piece=acio\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1581 size=12140 all=330916 active=17232 piece=▁Ausnahm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1576 size=12160 all=331201 active=17517 piece=reite\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1572 size=12180 all=331349 active=17665 piece=▁category\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1569 size=12200 all=331758 active=18074 piece=▁stance\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1569 min_freq=360\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1566 size=12220 all=331957 active=16787 piece=▁spring\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1562 size=12240 all=332177 active=17007 piece=▁manche\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1558 size=12260 all=332582 active=17412 piece=▁resulted\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1552 size=12280 all=332767 active=17597 piece=▁Vietnam\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1547 size=12300 all=332972 active=17802 piece=5-03\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1547 min_freq=355\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1542 size=12320 all=333123 active=16780 piece=istent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1537 size=12340 all=333247 active=16904 piece=▁Washing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1533 size=12360 all=333511 active=17168 piece=▁frank\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1530 size=12380 all=333646 active=17303 piece=spolitische\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1527 size=12400 all=334079 active=17736 piece=▁voller\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1527 min_freq=351\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1523 size=12420 all=334257 active=16881 piece=▁Day\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1520 size=12440 all=334491 active=17115 piece=▁Director\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1516 size=12460 all=334573 active=17197 piece=▁langfristigen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1512 size=12480 all=334906 active=17530 piece=▁regeln\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1509 size=12500 all=334993 active=17617 piece=▁scrutin\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1508 min_freq=347\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1505 size=12520 all=335281 active=17032 piece=▁Lithuania\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1500 size=12540 all=335691 active=17442 piece=Politik\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1496 size=12560 all=336217 active=17968 piece=▁eingesch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1493 size=12580 all=336612 active=18363 piece=▁bevorstehenden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1487 size=12600 all=336925 active=18676 piece=EEC\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1487 min_freq=342\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1484 size=12620 all=337139 active=17055 piece=gebieten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1480 size=12640 all=337517 active=17433 piece=▁regardless\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1475 size=12660 all=337925 active=17841 piece=▁ECHO\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1472 size=12680 all=338106 active=18022 piece=▁einfache\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1469 size=12700 all=338255 active=18171 piece=▁stam\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1469 min_freq=338\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1466 size=12720 all=338432 active=17085 piece=▁akzeptabel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1459 size=12740 all=338788 active=17441 piece=aw\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1455 size=12760 all=338945 active=17598 piece=▁wählen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1451 size=12780 all=339212 active=17865 piece=ichtete\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1447 size=12800 all=339555 active=18208 piece=▁effiziente\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1446 min_freq=334\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1442 size=12820 all=339739 active=17162 piece=7,\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1438 size=12840 all=340157 active=17580 piece=▁Vorwand\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1434 size=12860 all=340580 active=18003 piece=EWG\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1431 size=12880 all=340805 active=18228 piece=▁alternatives\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1427 size=12900 all=340855 active=18278 piece=▁viable\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1427 min_freq=330\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1423 size=12920 all=341069 active=17257 piece=▁Mug\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1421 size=12940 all=341373 active=17561 piece=▁Fähigkeiten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1417 size=12960 all=341859 active=18047 piece=▁Ägyp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1414 size=12980 all=342221 active=18409 piece=abstimmung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1410 size=13000 all=342438 active=18626 piece=sprechend\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1410 min_freq=326\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1407 size=13020 all=342781 active=17449 piece=▁Betroffenen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1402 size=13040 all=342975 active=17643 piece=feit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1399 size=13060 all=343118 active=17786 piece=▁Pflichten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1395 size=13080 all=343166 active=17834 piece=▁transnational\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1390 size=13100 all=343342 active=18010 piece=▁Armee\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1390 min_freq=323\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1387 size=13120 all=343557 active=17369 piece=▁Folter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1384 size=13140 all=343622 active=17434 piece=▁approximately\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1380 size=13160 all=343854 active=17666 piece=▁parents\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1375 size=13180 all=344058 active=17870 piece=nell\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1370 size=13200 all=344388 active=18200 piece=chmark\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1370 min_freq=319\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1365 size=13220 all=344750 active=17568 piece=obyl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1361 size=13240 all=344893 active=17711 piece=gegeben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1357 size=13260 all=345213 active=18031 piece=country\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1354 size=13280 all=345372 active=18190 piece=▁festen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1348 size=13300 all=345769 active=18587 piece=▁Statut\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1348 min_freq=315\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1345 size=13320 all=346325 active=17840 piece=strichen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1343 size=13340 all=346469 active=17984 piece=▁intelligen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1339 size=13360 all=346618 active=18133 piece=etus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1335 size=13380 all=346695 active=18210 piece=▁Schicksal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1331 size=13400 all=347090 active=18605 piece=▁erklärte\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1331 min_freq=312\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1327 size=13420 all=347221 active=17486 piece=▁geplant\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1323 size=13440 all=347371 active=17636 piece=▁respective\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1318 size=13460 all=347693 active=17958 piece=lehnen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1315 size=13480 all=347962 active=18227 piece=▁Nachdem\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1311 size=13500 all=348065 active=18330 piece=▁III\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1311 min_freq=309\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1309 size=13520 all=348414 active=17750 piece=▁Verd\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1306 size=13540 all=348610 active=17946 piece=eiden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1304 size=13560 all=348795 active=18131 piece=▁highlights\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1301 size=13580 all=348905 active=18241 piece=agements\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1297 size=13600 all=348943 active=18279 piece=ikanen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1297 min_freq=306\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1294 size=13620 all=349323 active=17823 piece=▁Scheitern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1289 size=13640 all=349474 active=17974 piece=▁Termin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1286 size=13660 all=349870 active=18370 piece=soever\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1282 size=13680 all=350015 active=18515 piece=kom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1280 size=13700 all=350325 active=18825 piece=▁Verzögerungen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1279 min_freq=303\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1277 size=13720 all=350482 active=17674 piece=▁beeinflussen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1274 size=13740 all=350790 active=17982 piece=▁Frid\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1271 size=13760 all=351140 active=18332 piece=ürzen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1268 size=13780 all=351507 active=18699 piece=▁kos\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1264 size=13800 all=351883 active=19075 piece=▁klarstellen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1264 min_freq=299\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1261 size=13820 all=352021 active=17731 piece=▁justification\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1257 size=13840 all=352386 active=18096 piece=usetzen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1254 size=13860 all=352548 active=18258 piece=▁wofür\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1249 size=13880 all=352817 active=18527 piece=▁delegations\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1246 size=13900 all=352969 active=18679 piece=▁beinhalten\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1246 min_freq=296\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1242 size=13920 all=353235 active=17913 piece=▁Lebanon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1238 size=13940 all=353494 active=18172 piece=▁looks\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1234 size=13960 all=353655 active=18333 piece=▁könne\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1232 size=13980 all=353932 active=18610 piece=▁einzurichten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1229 size=14000 all=354037 active=18715 piece=▁universities\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1229 min_freq=293\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1225 size=14020 all=354418 active=18083 piece=▁gained\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1222 size=14040 all=354560 active=18225 piece=▁marginal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1219 size=14060 all=354804 active=18469 piece=▁pilot\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1217 size=14080 all=354929 active=18594 piece=▁Taliban\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1213 size=14100 all=355170 active=18835 piece=▁Erika\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1213 min_freq=290\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1211 size=14120 all=355273 active=17862 piece=▁Finanzielle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1209 size=14140 all=355398 active=17987 piece=▁safeguarding\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1204 size=14160 all=355896 active=18485 piece=▁Kommissars\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1201 size=14180 all=356193 active=18782 piece=▁Could\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1197 size=14200 all=356412 active=19001 piece=▁Euratom\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1197 min_freq=287\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1194 size=14220 all=356624 active=18025 piece=▁konsult\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1190 size=14240 all=356866 active=18267 piece=▁begründet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1188 size=14260 all=357023 active=18424 piece=▁Zielsetzung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1186 size=14280 all=357324 active=18725 piece=▁Criminal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1183 size=14300 all=357558 active=18959 piece=▁abroad\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1183 min_freq=283\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1181 size=14320 all=357792 active=18112 piece=▁eröffnen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1179 size=14340 all=357833 active=18153 piece=▁jurisdiction\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1175 size=14360 all=358024 active=18344 piece=▁containing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1172 size=14380 all=358196 active=18516 piece=▁Kluft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1170 size=14400 all=358314 active=18634 piece=▁Jarzembowski\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1170 min_freq=281\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1167 size=14420 all=358549 active=18151 piece=▁conve\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1164 size=14440 all=358820 active=18422 piece=prozess\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1161 size=14460 all=359218 active=18820 piece=schriften\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1159 size=14480 all=359438 active=19040 piece=▁Chairman\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1157 size=14500 all=359466 active=19068 piece=▁TACIS\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1157 min_freq=277\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1155 size=14520 all=359562 active=18062 piece=▁sight\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1152 size=14540 all=359768 active=18268 piece=▁released\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1150 size=14560 all=360167 active=18667 piece=▁broadc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1147 size=14580 all=360285 active=18785 piece=▁Sensib\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1143 size=14600 all=360606 active=19106 piece=Ru\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1143 min_freq=275\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1141 size=14620 all=360951 active=18365 piece=▁nachzudenken\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1139 size=14640 all=361073 active=18487 piece=greifende\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1135 size=14660 all=361219 active=18633 piece=▁Gespräch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1132 size=14680 all=361458 active=18872 piece=▁Soc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1128 size=14700 all=361643 active=19057 piece=▁tit\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1128 min_freq=272\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1126 size=14720 all=361952 active=18375 piece=▁hinein\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1123 size=14740 all=362173 active=18596 piece=▁zwangs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1121 size=14760 all=362217 active=18640 piece=▁rechtlich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1119 size=14780 all=362534 active=18957 piece=erusalem\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1116 size=14800 all=362645 active=19068 piece=▁John\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1116 min_freq=269\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1114 size=14820 all=362798 active=18282 piece=▁Vitor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1111 size=14840 all=362966 active=18450 piece=▁sämtlichen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1108 size=14860 all=363231 active=18715 piece=▁Migrations\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1106 size=14880 all=363430 active=18914 piece=wegungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1103 size=14900 all=363616 active=19100 piece=▁OSZE\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1103 min_freq=267\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1102 size=14920 all=363698 active=18261 piece=▁consistently\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1099 size=14940 all=363897 active=18460 piece=▁Nordirland\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1095 size=14960 all=364041 active=18604 piece=netze\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1091 size=14980 all=364336 active=18899 piece=▁contrast\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1089 size=15000 all=364565 active=19128 piece=▁everywhere\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1088 min_freq=265\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1086 size=15020 all=364852 active=18516 piece=▁irgendwel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1084 size=15040 all=365008 active=18672 piece=▁wahrnehmen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1081 size=15060 all=365659 active=19323 piece=▁annex\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1078 size=15080 all=365883 active=19547 piece=▁fairer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1075 size=15100 all=366193 active=19857 piece=▁normalen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1075 min_freq=262\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1072 size=15120 all=366282 active=18398 piece=▁120\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1069 size=15140 all=366468 active=18584 piece=olved\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1068 size=15160 all=366633 active=18749 piece=▁station\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1065 size=15180 all=366924 active=19040 piece=▁Südafrika\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1062 size=15200 all=367234 active=19350 piece=änz\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1062 min_freq=260\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1059 size=15220 all=367550 active=18643 piece=▁vigil\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1057 size=15240 all=367821 active=18914 piece=▁voranzubringen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1053 size=15260 all=367904 active=18997 piece=▁Gewinne\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1051 size=15280 all=368076 active=19169 piece=▁Vir\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1049 size=15300 all=368518 active=19611 piece=▁Tendenz\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1049 min_freq=258\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1046 size=15320 all=368750 active=18656 piece=iro\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1044 size=15340 all=369040 active=18946 piece=▁1989\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1042 size=15360 all=369512 active=19418 piece=▁müßten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1040 size=15380 all=369573 active=19479 piece=Entwicklungs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1038 size=15400 all=369929 active=19835 piece=▁notion\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1038 min_freq=255\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1036 size=15420 all=370078 active=18645 piece=▁fashion\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1034 size=15440 all=370316 active=18883 piece=▁herum\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1031 size=15460 all=370530 active=19097 piece=▁Kat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1029 size=15480 all=370659 active=19226 piece=▁Reaktionen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1027 size=15500 all=370710 active=19277 piece=gesetzgebung\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1026 min_freq=253\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1024 size=15520 all=371145 active=18939 piece=▁statistical\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1021 size=15540 all=371416 active=19210 piece=▁Hom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1019 size=15560 all=371545 active=19339 piece=▁participants\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1017 size=15580 all=371744 active=19538 piece=▁dual\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1015 size=15600 all=371940 active=19734 piece=fere\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1015 min_freq=250\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1014 size=15620 all=372117 active=18755 piece=▁transferred\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1011 size=15640 all=372371 active=19009 piece=▁enabled\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1007 size=15660 all=372561 active=19199 piece=astet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1005 size=15680 all=372718 active=19356 piece=ima\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1003 size=15700 all=372957 active=19595 piece=24\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1003 min_freq=248\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1002 size=15720 all=373385 active=18970 piece=▁biologischen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1000 size=15740 all=373514 active=19099 piece=▁Slowenien\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=997 size=15760 all=373654 active=19239 piece=▁Pen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=995 size=15780 all=373825 active=19410 piece=fi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=994 size=15800 all=374090 active=19675 piece=▁middle\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=994 min_freq=246\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=992 size=15820 all=374274 active=18886 piece=ermächtigungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=989 size=15840 all=374297 active=18909 piece=lichem\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=988 size=15860 all=374522 active=19134 piece=▁bereitstellen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=985 size=15880 all=374692 active=19304 piece=treib\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=983 size=15900 all=374832 active=19444 piece=▁Schiffen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=983 min_freq=243\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=980 size=15920 all=375036 active=18946 piece=astungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=978 size=15940 all=375380 active=19290 piece=ennbar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=976 size=15960 all=375782 active=19692 piece=▁Ihres\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=974 size=15980 all=375991 active=19901 piece=▁erstmals\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=972 size=16000 all=376231 active=20141 piece=▁Eingliederung\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=971 min_freq=241\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=969 size=16020 all=376462 active=19043 piece=▁haus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=968 size=16040 all=376549 active=19130 piece=▁gesetzlichen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=965 size=16060 all=376741 active=19322 piece=▁closing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=963 size=16080 all=376956 active=19537 piece=▁Finanzmärkte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=960 size=16100 all=377273 active=19854 piece=Russ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=960 min_freq=238\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=957 size=16120 all=377418 active=19000 piece=ults\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=956 size=16140 all=377530 active=19112 piece=▁announcement\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=953 size=16160 all=378032 active=19614 piece=▁Erkenntnisse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=951 size=16180 all=378097 active=19679 piece=▁Sowjet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=949 size=16200 all=378487 active=20069 piece=▁criticised\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=949 min_freq=236\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=946 size=16220 all=378780 active=19218 piece=▁Händen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=944 size=16240 all=378924 active=19362 piece=ölle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=942 size=16260 all=379163 active=19601 piece=▁hundert\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=940 size=16280 all=379431 active=19869 piece=aker\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=938 size=16300 all=379608 active=20046 piece=gewäss\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=938 min_freq=234\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=935 size=16320 all=379728 active=19064 piece=▁decade\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=933 size=16340 all=380056 active=19392 piece=▁verwende\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=931 size=16360 all=380270 active=19606 piece=▁reun\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=929 size=16380 all=380307 active=19643 piece=lli\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=927 size=16400 all=380600 active=19936 piece=▁Investoren\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=927 min_freq=232\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=925 size=16420 all=380899 active=19328 piece=▁Dritten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=924 size=16440 all=381102 active=19531 piece=ifikationen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=922 size=16460 all=381360 active=19789 piece=▁Congress\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=920 size=16480 all=381598 active=20027 piece=▁exacerb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=918 size=16500 all=381801 active=20230 piece=▁unternimmt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=918 min_freq=229\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=916 size=16520 all=381952 active=19242 piece=▁corporate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=914 size=16540 all=382113 active=19403 piece=▁angehört\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=911 size=16560 all=382159 active=19449 piece=▁unequ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=909 size=16580 all=382451 active=19741 piece=fahrts\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=908 size=16600 all=382883 active=20173 piece=▁Fontaine\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=908 min_freq=227\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=907 size=16620 all=383257 active=19516 piece=▁medizinische\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=905 size=16640 all=383570 active=19829 piece=▁Erdgas\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=902 size=16660 all=383791 active=20050 piece=▁Six\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=900 size=16680 all=383965 active=20224 piece=dauer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=899 size=16700 all=384229 active=20488 piece=▁disadvantage\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=898 min_freq=225\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=896 size=16720 all=384323 active=19305 piece=ements\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=895 size=16740 all=384515 active=19497 piece=weiterung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=893 size=16760 all=384695 active=19677 piece=▁Malmström\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=891 size=16780 all=384992 active=19974 piece=▁Profit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=889 size=16800 all=385133 active=20115 piece=▁diagn\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=889 min_freq=223\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=887 size=16820 all=385361 active=19479 piece=▁reverse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=885 size=16840 all=385422 active=19540 piece=▁Daß\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=884 size=16860 all=385548 active=19666 piece=▁Kompon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=883 size=16880 all=385669 active=19787 piece=▁Amsterdamer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=881 size=16900 all=385785 active=19903 piece=umm\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=881 min_freq=221\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=880 size=16920 all=386024 active=19433 piece=▁Strafen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=878 size=16940 all=386339 active=19748 piece=oeuv\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=876 size=16960 all=386604 active=20013 piece=▁Estland\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=874 size=16980 all=386672 active=20081 piece=ktisch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=871 size=17000 all=387014 active=20423 piece=▁angere\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=871 min_freq=219\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=870 size=17020 all=387231 active=19560 piece=▁manoeuv\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=868 size=17040 all=387389 active=19718 piece=▁bedeutend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=866 size=17060 all=387577 active=19906 piece=▁Darlehen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=864 size=17080 all=387700 active=20029 piece=▁gets\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=861 size=17100 all=387833 active=20162 piece=Ein\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=861 min_freq=217\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=860 size=17120 all=388002 active=19466 piece=▁relationships\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=858 size=17140 all=388104 active=19568 piece=▁bemerken\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=855 size=17160 all=388351 active=19815 piece=▁Garc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=854 size=17180 all=388463 active=19927 piece=▁vereinfacht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=852 size=17200 all=388637 active=20101 piece=berichte\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=852 min_freq=216\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=850 size=17220 all=388876 active=19596 piece=▁unannehmbar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=846 size=17240 all=389099 active=19819 piece=▁reale\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=844 size=17260 all=389297 active=20017 piece=▁strive\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=842 size=17280 all=389678 active=20398 piece=▁formula\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=840 size=17300 all=389834 active=20554 piece=▁unvermeid\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=840 min_freq=213\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=838 size=17320 all=390152 active=19802 piece=▁ausgedrückt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=836 size=17340 all=390447 active=20097 piece=▁displaced\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=834 size=17360 all=390832 active=20482 piece=ema\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=833 size=17380 all=391228 active=20878 piece=▁Vielmehr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=831 size=17400 all=391516 active=21166 piece=▁faces\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=831 min_freq=211\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=830 size=17420 all=391662 active=19722 piece=▁verknüpft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=827 size=17440 all=391769 active=19829 piece=yers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=826 size=17460 all=392008 active=20068 piece=▁Verhütung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=825 size=17480 all=392225 active=20285 piece=▁postponed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=823 size=17500 all=392423 active=20483 piece=▁Verg\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=823 min_freq=209\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=822 size=17520 all=392594 active=19778 piece=▁intelligence\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=820 size=17540 all=392667 active=19851 piece=▁Diensten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=818 size=17560 all=392733 active=19917 piece=aspe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=817 size=17580 all=393195 active=20379 piece=▁widerspiegelt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=815 size=17600 all=393491 active=20675 piece=▁convincing\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=815 min_freq=207\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=813 size=17620 all=393696 active=19879 piece=emit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=811 size=17640 all=393912 active=20095 piece=▁130\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=809 size=17660 all=394219 active=20402 piece=▁Ruf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=808 size=17680 all=394376 active=20559 piece=▁endanger\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=806 size=17700 all=394546 active=20729 piece=▁Rather\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=806 min_freq=206\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=805 size=17720 all=394696 active=19878 piece=▁Schande\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=803 size=17740 all=394779 active=19961 piece=▁weitem\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=802 size=17760 all=395051 active=20233 piece=▁aufgetreten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=800 size=17780 all=395313 active=20495 piece=▁driven\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=799 size=17800 all=395392 active=20574 piece=▁unmittelbaren\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=799 min_freq=204\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=797 size=17820 all=395578 active=19956 piece=▁Zugeständ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=795 size=17840 all=395774 active=20152 piece=▁energisch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=793 size=17860 all=396028 active=20406 piece=▁complexity\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=790 size=17880 all=396120 active=20498 piece=COS\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=789 size=17900 all=396302 active=20680 piece=▁freiwilligen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=789 min_freq=202\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=787 size=17920 all=396375 active=19889 piece=▁Eingriff\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=786 size=17940 all=396519 active=20033 piece=wirtschaftlichen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=784 size=17960 all=396841 active=20355 piece=existence\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=782 size=17980 all=396922 active=20436 piece=idden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=781 size=18000 all=397069 active=20583 piece=▁copyright\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=781 min_freq=201\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=779 size=18020 all=397276 active=20061 piece=ichtungs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=777 size=18040 all=397432 active=20217 piece=ubb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=776 size=18060 all=397635 active=20420 piece=weichen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=774 size=18080 all=397763 active=20548 piece=zedenz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=772 size=18100 all=397881 active=20666 piece=brechen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=772 min_freq=199\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=770 size=18120 all=397977 active=19961 piece=▁Karas\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=769 size=18140 all=398107 active=20091 piece=▁ungarische\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=768 size=18160 all=398569 active=20553 piece=▁unverzichtbar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=766 size=18180 all=398797 active=20781 piece=kampagne\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=765 size=18200 all=398986 active=20970 piece=▁selection\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=765 min_freq=197\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=763 size=18220 all=399260 active=20224 piece=▁Cor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=762 size=18240 all=399388 active=20352 piece=▁Juncker\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=761 size=18260 all=399517 active=20481 piece=▁untereinander\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=759 size=18280 all=399589 active=20553 piece=▁Indonesien\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=757 size=18300 all=399738 active=20702 piece=▁echo\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=757 min_freq=196\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=756 size=18320 all=399871 active=20117 piece=wichtig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=755 size=18340 all=399977 active=20223 piece=▁höchster\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=753 size=18360 all=400130 active=20376 piece=ng\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=752 size=18380 all=400515 active=20761 piece=▁gesenkt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=751 size=18400 all=400656 active=20902 piece=▁zentraler\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=751 min_freq=194\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=749 size=18420 all=400731 active=20108 piece=agenturen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=748 size=18440 all=400895 active=20272 piece=▁Pensions\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=747 size=18460 all=401174 active=20551 piece=▁Verhältnisse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=745 size=18480 all=401326 active=20703 piece=risy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=744 size=18500 all=401523 active=20900 piece=itre\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=744 min_freq=192\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=742 size=18520 all=401720 active=20252 piece=goti\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=741 size=18540 all=401833 active=20365 piece=▁Cashman\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=739 size=18560 all=402023 active=20555 piece=▁theory\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=738 size=18580 all=402136 active=20668 piece=▁customers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=737 size=18600 all=402289 active=20821 piece=▁demonstrating\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=736 min_freq=191\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=735 size=18620 all=402548 active=20374 piece=▁mußte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=734 size=18640 all=402618 active=20444 piece=▁sensitivity\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=732 size=18660 all=402917 active=20743 piece=ymmet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=731 size=18680 all=402968 active=20794 piece=cts\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=730 size=18700 all=403120 active=20946 piece=kapazitäten\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=730 min_freq=189\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=728 size=18720 all=403392 active=20385 piece=sprä\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=727 size=18740 all=403664 active=20657 piece=äme\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=726 size=18760 all=403823 active=20816 piece=▁Singap\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=724 size=18780 all=403910 active=20903 piece=▁Eben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=723 size=18800 all=404162 active=21155 piece=unken\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=723 min_freq=188\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=722 size=18820 all=404342 active=20361 piece=▁Verhofstadt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=720 size=18840 all=404618 active=20637 piece=▁coalition\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=718 size=18860 all=404963 active=20982 piece=gründe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=717 size=18880 all=405173 active=21192 piece=▁Embry\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=716 size=18900 all=405378 active=21397 piece=▁Grundprinzipien\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=716 min_freq=186\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=714 size=18920 all=405518 active=20409 piece=ächstes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=713 size=18940 all=405629 active=20520 piece=▁anzubieten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=712 size=18960 all=405731 active=20622 piece=▁vorantreiben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=711 size=18980 all=405906 active=20797 piece=▁Seeverkehrs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=709 size=19000 all=405979 active=20870 piece=KW\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=709 min_freq=185\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=708 size=19020 all=406076 active=20380 piece=bilanz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=707 size=19040 all=406315 active=20619 piece=versorgungs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=705 size=19060 all=406426 active=20730 piece=▁harass\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=704 size=19080 all=406711 active=21015 piece=ustoms\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=703 size=19100 all=406865 active=21169 piece=▁definitiv\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=703 min_freq=183\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=701 size=19120 all=407057 active=20535 piece=rent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=700 size=19140 all=407140 active=20618 piece=▁Wählern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=698 size=19160 all=407302 active=20780 piece=annoy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=697 size=19180 all=407445 active=20923 piece=▁Einhalt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=696 size=19200 all=407579 active=21057 piece=▁scenario\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=696 min_freq=182\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=694 size=19220 all=407829 active=20629 piece=▁widen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=693 size=19240 all=407921 active=20721 piece=▁privileged\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=691 size=19260 all=408244 active=21044 piece=éndez\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=690 size=19280 all=408414 active=21214 piece=▁morgigen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=688 size=19300 all=408574 active=21374 piece=▁ECR\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=688 min_freq=180\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=687 size=19320 all=408789 active=20641 piece=▁church\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=686 size=19340 all=408935 active=20787 piece=▁Inflations\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=684 size=19360 all=409092 active=20944 piece=appe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=683 size=19380 all=409259 active=21111 piece=reckt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=682 size=19400 all=409556 active=21408 piece=▁Inspe\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=682 min_freq=179\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=681 size=19420 all=409621 active=20541 piece=ifizierungs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=680 size=19440 all=409735 active=20655 piece=▁harmonisieren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=679 size=19460 all=410031 active=20951 piece=▁herausragen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=677 size=19480 all=410161 active=21081 piece=▁Migu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=675 size=19500 all=410347 active=21267 piece=long\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=675 min_freq=178\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=674 size=19520 all=410551 active=20711 piece=▁rede\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=673 size=19540 all=410618 active=20778 piece=▁unklar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=672 size=19560 all=410658 active=20818 piece=▁Korrektur\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=671 size=19580 all=410724 active=20884 piece=▁Olympischen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=669 size=19600 all=410892 active=21052 piece=▁20,\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=669 min_freq=176\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=668 size=19620 all=411137 active=20777 piece=▁Strafe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=667 size=19640 all=411479 active=21119 piece=▁stecken\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=666 size=19660 all=411760 active=21400 piece=▁Stalin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=665 size=19680 all=412049 active=21689 piece=▁schock\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=664 size=19700 all=412141 active=21781 piece=▁Conservative\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=663 min_freq=175\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=662 size=19720 all=412295 active=20762 piece=▁einzug\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=661 size=19740 all=412418 active=20885 piece=tagung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=660 size=19760 all=412533 active=21000 piece=▁Job\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=659 size=19780 all=412880 active=21347 piece=apeut\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=658 size=19800 all=412949 active=21416 piece=▁sech\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=658 min_freq=173\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=657 size=19820 all=413087 active=20776 piece=▁unus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=656 size=19840 all=413126 active=20815 piece=▁gleichzeit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=654 size=19860 all=413305 active=20994 piece=projekt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=653 size=19880 all=413480 active=21169 piece=▁ausb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=652 size=19900 all=413532 active=21221 piece=▁ingredients\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=652 min_freq=172\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=650 size=19920 all=413624 active=20769 piece=▁Konf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=649 size=19940 all=413757 active=20902 piece=▁enthusi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=648 size=19960 all=413956 active=21101 piece=▁Pharm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=647 size=19980 all=414254 active=21399 piece=ilation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=646 size=20000 all=414419 active=21564 piece=apolitik\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=646 min_freq=171\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=645 size=20020 all=414657 active=20938 piece=beschrän\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=644 size=20040 all=414925 active=21206 piece=▁subscr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=643 size=20060 all=415101 active=21382 piece=▁kurzer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=642 size=20080 all=415264 active=21545 piece=▁compr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=641 size=20100 all=415483 active=21764 piece=▁freier\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=641 min_freq=170\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=640 size=20120 all=415669 active=20958 piece=▁Tuber\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=639 size=20140 all=415905 active=21194 piece=▁Forscher\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=638 size=20160 all=416076 active=21365 piece=▁Mißbrauch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=636 size=20180 all=416310 active=21599 piece=▁hect\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=635 size=20200 all=416488 active=21777 piece=▁impunity\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=635 min_freq=168\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=634 size=20220 all=416534 active=20871 piece=▁settled\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=633 size=20240 all=416603 active=20940 piece=▁Rückführung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=631 size=20260 all=416791 active=21128 piece=▁ums\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=630 size=20280 all=416957 active=21294 piece=far\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=629 size=20300 all=417076 active=21413 piece=▁loop\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=629 min_freq=167\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=628 size=20320 all=417211 active=20987 piece=▁verwaltet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=627 size=20340 all=417295 active=21071 piece=▁verfasst\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=625 size=20360 all=417357 active=21133 piece=33\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=624 size=20380 all=417730 active=21506 piece=▁touched\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=623 size=20400 all=417779 active=21555 piece=▁prävent\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=623 min_freq=166\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=621 size=20420 all=417905 active=21011 piece=▁prer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=620 size=20440 all=418149 active=21255 piece=regulation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=619 size=20460 all=418375 active=21481 piece=▁vereinfach\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=617 size=20480 all=418577 active=21683 piece=▁Grupp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=616 size=20500 all=418694 active=21800 piece=▁klug\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=616 min_freq=165\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=615 size=20520 all=418920 active=21158 piece=ärente\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=614 size=20540 all=419072 active=21310 piece=▁Balance\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=613 size=20560 all=419253 active=21491 piece=▁verhäng\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=612 size=20580 all=419385 active=21623 piece=▁Ärzte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=611 size=20600 all=419537 active=21775 piece=▁Zahlung\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=611 min_freq=163\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=610 size=20620 all=419643 active=21078 piece=▁Mehrwertsteuers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=609 size=20640 all=419786 active=21221 piece=▁Waffenstill\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=607 size=20660 all=419925 active=21360 piece=owen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=606 size=20680 all=420052 active=21487 piece=split\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=605 size=20700 all=420254 active=21689 piece=zugleichen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=605 min_freq=162\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=604 size=20720 all=420412 active=21167 piece=▁Slovenian\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=603 size=20740 all=420487 active=21242 piece=▁Aktionspläne\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=601 size=20760 all=420747 active=21502 piece=▁tempt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=600 size=20780 all=420890 active=21645 piece=lyn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=599 size=20800 all=421165 active=21920 piece=▁Netto\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=599 min_freq=161\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=598 size=20820 all=421289 active=21146 piece=▁Sobald\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=596 size=20840 all=421393 active=21250 piece=▁2020,\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=595 size=20860 all=421531 active=21388 piece=▁schicken\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=594 size=20880 all=421632 active=21489 piece=▁Größen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=593 size=20900 all=421838 active=21695 piece=▁SOLVIT\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=593 min_freq=160\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=592 size=20920 all=422106 active=21360 piece=▁gedenken\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=590 size=20940 all=422285 active=21539 piece=nahms\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=589 size=20960 all=422474 active=21728 piece=▁outrage\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=588 size=20980 all=422612 active=21866 piece=▁Durchbruch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=587 size=21000 all=422780 active=22034 piece=▁signatures\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=587 min_freq=159\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=585 size=21020 all=422874 active=21233 piece=▁Arm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=584 size=21040 all=423138 active=21497 piece=usionen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=583 size=21060 all=423340 active=21699 piece=▁heiklen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=582 size=21080 all=423519 active=21878 piece=▁Water\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=581 size=21100 all=423671 active=22030 piece=gment\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=581 min_freq=158\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=580 size=21120 all=423834 active=21321 piece=▁Bern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=579 size=21140 all=424075 active=21562 piece=▁bewill\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=578 size=21160 all=424303 active=21790 piece=gestellte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=577 size=21180 all=424697 active=22184 piece=inistry\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=576 size=21200 all=424846 active=22333 piece=▁upheld\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=576 min_freq=156\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=575 size=21220 all=424900 active=21297 piece=▁ruft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=574 size=21240 all=425023 active=21420 piece=▁1996.\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=573 size=21260 all=425141 active=21538 piece=spielraum\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=572 size=21280 all=425400 active=21797 piece=pflanzen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=571 size=21300 all=425548 active=21945 piece=▁ausgelegt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=571 min_freq=155\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=570 size=21320 all=425786 active=21515 piece=stimmt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=569 size=21340 all=425935 active=21664 piece=▁termin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=568 size=21360 all=426036 active=21765 piece=▁vertret\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=567 size=21380 all=426153 active=21882 piece=▁exagger\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=566 size=21400 all=426370 active=22099 piece=▁Mitt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=566 min_freq=154\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=565 size=21420 all=426533 active=21472 piece=Burton\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=564 size=21440 all=426614 active=21553 piece=▁kontro\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=563 size=21460 all=426831 active=21770 piece=▁schott\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=562 size=21480 all=426926 active=21865 piece=▁promptly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=561 size=21500 all=427012 active=21951 piece=▁aussieht\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=561 min_freq=153\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=560 size=21520 all=427041 active=21380 piece=▁doppelt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=559 size=21540 all=427254 active=21593 piece=▁vehement\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=558 size=21560 all=427432 active=21771 piece=▁genügen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=557 size=21580 all=427598 active=21937 piece=▁scourge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=556 size=21600 all=427798 active=22137 piece=▁Touristen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=556 min_freq=152\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=555 size=21620 all=427903 active=21466 piece=▁Nothing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=554 size=21640 all=428038 active=21601 piece=▁Socrates\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=553 size=21660 all=428130 active=21693 piece=▁geboren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=553 size=21680 all=428142 active=21705 piece=▁simultaneously\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=551 size=21700 all=428271 active=21834 piece=▁Sene\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=551 min_freq=151\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=550 size=21720 all=428616 active=21755 piece=mind\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=549 size=21740 all=428856 active=21995 piece=▁unite\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=548 size=21760 all=428957 active=22096 piece=▁Konzepts\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=547 size=21780 all=429022 active=22161 piece=▁Games\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=546 size=21800 all=429171 active=22310 piece=yssen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=546 min_freq=150\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=545 size=21820 all=429308 active=21589 piece=▁Cam\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=545 size=21840 all=429435 active=21716 piece=▁Turkmenistan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=544 size=21860 all=429760 active=22041 piece=▁grundlegendes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=542 size=21880 all=430031 active=22312 piece=▁Heil\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=541 size=21900 all=430247 active=22528 piece=oca\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=541 min_freq=149\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=540 size=21920 all=430384 active=21639 piece=fällt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=540 size=21940 all=430591 active=21846 piece=▁mittelfrist\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=539 size=21960 all=430815 active=22070 piece=▁machinery\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=538 size=21980 all=431047 active=22302 piece=▁repeal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=537 size=22000 all=431190 active=22445 piece=▁Ideologie\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=537 min_freq=148\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=536 size=22020 all=431373 active=21742 piece=stranten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=535 size=22040 all=431623 active=21992 piece=▁Verbots\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=534 size=22060 all=431795 active=22164 piece=istenten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=533 size=22080 all=431929 active=22298 piece=bewegungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=531 size=22100 all=432112 active=22481 piece=/20\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=531 min_freq=147\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=531 size=22120 all=432326 active=21752 piece=▁Demonstranten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=529 size=22140 all=432564 active=21990 piece=▁scene\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=528 size=22160 all=432916 active=22342 piece=▁Illeg\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=527 size=22180 all=433177 active=22603 piece=▁pull\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=526 size=22200 all=433195 active=22621 piece=▁Sj\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=526 min_freq=146\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=525 size=22220 all=433373 active=21835 piece=▁Oze\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=524 size=22240 all=433634 active=22096 piece=mack\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=524 size=22260 all=433705 active=22167 piece=▁Finanzmitteln\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=522 size=22280 all=433857 active=22319 piece=▁22,\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=521 size=22300 all=433931 active=22393 piece=▁VII\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=521 min_freq=145\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=521 size=22320 all=434022 active=21784 piece=▁praktiziert\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=520 size=22340 all=434318 active=22080 piece=▁serbischen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=519 size=22360 all=434348 active=22110 piece=▁überleben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=518 size=22380 all=434465 active=22227 piece=▁signature\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=517 size=22400 all=434599 active=22361 piece=▁shameful\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=517 min_freq=144\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=516 size=22420 all=434818 active=21949 piece=▁Werke\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=515 size=22440 all=434893 active=22024 piece=▁dying\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=514 size=22460 all=435072 active=22203 piece=▁saved\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=513 size=22480 all=435194 active=22325 piece=▁Lehrer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=512 size=22500 all=435312 active=22443 piece=made\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=512 min_freq=143\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=512 size=22520 all=435353 active=21804 piece=▁Herangehen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=511 size=22540 all=435523 active=21974 piece=akthrough\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=510 size=22560 all=435641 active=22092 piece=▁stepping\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=509 size=22580 all=435883 active=22334 piece=▁Militä\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=508 size=22600 all=436017 active=22468 piece=Weg\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=508 min_freq=142\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=508 size=22620 all=436183 active=21963 piece=▁Zurückhaltung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=507 size=22640 all=436377 active=22157 piece=▁Parallel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=506 size=22660 all=436539 active=22319 piece=technik\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=505 size=22680 all=436659 active=22439 piece=▁anxious\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=504 size=22700 all=436811 active=22591 piece=▁procla\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=504 min_freq=141\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=503 size=22720 all=437054 active=22081 piece=▁ICT\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=503 size=22740 all=437114 active=22141 piece=▁Kinderarbeit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=502 size=22760 all=437214 active=22241 piece=▁niedrigeren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=501 size=22780 all=437463 active=22490 piece=▁lorries\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=500 size=22800 all=437653 active=22680 piece=▁Sprecher\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=500 min_freq=140\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=499 size=22820 all=437676 active=21902 piece=▁Italiens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=498 size=22840 all=437929 active=22155 piece=▁erleiden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=497 size=22860 all=438145 active=22371 piece=▁gesucht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=496 size=22880 all=438292 active=22518 piece=▁Nachweis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=495 size=22900 all=438369 active=22595 piece=▁unknown\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=495 min_freq=139\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=494 size=22920 all=438568 active=22117 piece=▁einzub\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=494 size=22940 all=438600 active=22149 piece=▁Opportunities\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=493 size=22960 all=438719 active=22268 piece=▁contractual\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=492 size=22980 all=438804 active=22353 piece=▁Eurobonds\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=491 size=23000 all=438875 active=22424 piece=▁multif\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=491 min_freq=138\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=490 size=23020 all=438938 active=21999 piece=olidar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=489 size=23040 all=439041 active=22102 piece=▁63\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=488 size=23060 all=439271 active=22332 piece=▁Klau\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=488 size=23080 all=439330 active=22391 piece=▁objektiven\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=487 size=23100 all=439455 active=22516 piece=▁cereals\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=487 min_freq=137\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=486 size=23120 all=439494 active=22012 piece=▁Muslims\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=485 size=23140 all=439651 active=22169 piece=▁Kop\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=485 size=23160 all=439851 active=22369 piece=ichtigen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=484 size=23180 all=440122 active=22640 piece=▁Regen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=483 size=23200 all=440403 active=22921 piece=▁Fava\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=483 min_freq=136\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=483 size=23220 all=440489 active=22107 piece=▁Geldpolitik\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=482 size=23240 all=440679 active=22297 piece=▁Charakters\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=481 size=23260 all=440825 active=22443 piece=wirksam\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=480 size=23280 all=440899 active=22517 piece=Land\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=480 size=23300 all=441014 active=22632 piece=▁ungleich\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=480 min_freq=135\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=479 size=23320 all=441227 active=22250 piece=▁readiness\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=478 size=23340 all=441471 active=22494 piece=▁begeben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=477 size=23360 all=441577 active=22600 piece=▁Fahrgast\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=476 size=23380 all=441619 active=22642 piece=Fl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=476 size=23400 all=441815 active=22838 piece=▁artists\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=476 min_freq=134\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=475 size=23420 all=442007 active=22283 piece=fristen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=474 size=23440 all=442282 active=22558 piece=ollt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=474 size=23460 all=442342 active=22618 piece=sprechungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=473 size=23480 all=442487 active=22763 piece=▁occupying\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=472 size=23500 all=442661 active=22937 piece=▁adopts\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=472 min_freq=133\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=471 size=23520 all=442823 active=22296 piece=gestion\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=470 size=23540 all=442890 active=22363 piece=öch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=470 size=23560 all=443069 active=22542 piece=▁begünstigen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=469 size=23580 all=443140 active=22613 piece=▁Ansprüche\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=468 size=23600 all=443296 active=22769 piece=▁LEADER\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=468 min_freq=133\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=467 size=23620 all=443385 active=22252 piece=▁loan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=466 size=23640 all=443480 active=22347 piece=teht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=466 size=23660 all=443595 active=22462 piece=▁Bearbeitung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=465 size=23680 all=443859 active=22726 piece=▁unlauteren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=464 size=23700 all=443989 active=22856 piece=▁Istanbul\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=464 min_freq=132\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=463 size=23720 all=444142 active=22352 piece=volles\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=463 size=23740 all=444214 active=22424 piece=▁facilitation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=462 size=23760 all=444499 active=22709 piece=▁Vollstre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=461 size=23780 all=444665 active=22875 piece=▁Aufträge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=460 size=23800 all=444800 active=23010 piece=▁flour\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=460 min_freq=131\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=459 size=23820 all=444896 active=22332 piece=▁27,\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=459 size=23840 all=444998 active=22434 piece=▁laufende\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=458 size=23860 all=445102 active=22538 piece=aktivisten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=457 size=23880 all=445264 active=22700 piece=▁Flüge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=457 size=23900 all=445358 active=22794 piece=▁concentrating\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=457 min_freq=130\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=456 size=23920 all=445571 active=22481 piece=ungsbefugnisse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=455 size=23940 all=445725 active=22635 piece=▁umzugehen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=454 size=23960 all=445930 active=22840 piece=▁reveals\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=453 size=23980 all=446082 active=22992 piece=▁opted\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=452 size=24000 all=446144 active=23054 piece=▁Fehlern\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=452 min_freq=129\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=451 size=24020 all=446375 active=22537 piece=log\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=451 size=24040 all=446597 active=22759 piece=▁underestimate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=450 size=24060 all=446886 active=23048 piece=▁humans\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=450 size=24080 all=446916 active=23078 piece=▁verschlimmert\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=449 size=24100 all=447057 active=23219 piece=▁Planungs\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=449 min_freq=128\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=448 size=24120 all=447260 active=22495 piece=▁Azoren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=447 size=24140 all=447377 active=22612 piece=zing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=447 size=24160 all=447562 active=22797 piece=▁scheinbar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=446 size=24180 all=447854 active=23089 piece=▁Schock\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=446 size=24200 all=447941 active=23176 piece=▁anzustreben\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=446 min_freq=127\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=445 size=24220 all=448045 active=22499 piece=▁entnehmen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=444 size=24240 all=448224 active=22678 piece=▁schöne\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=443 size=24260 all=448313 active=22767 piece=ethn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=443 size=24280 all=448718 active=23172 piece=▁Sammlung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=442 size=24300 all=448817 active=23271 piece=noten\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=442 min_freq=127\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=442 size=24320 all=449076 active=22678 piece=▁förderlich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=441 size=24340 all=449193 active=22795 piece=▁Press\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=441 size=24360 all=449238 active=22840 piece=▁Möglicherweise\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=440 size=24380 all=449345 active=22947 piece=▁erledigt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=439 size=24400 all=449482 active=23084 piece=▁Umlauf\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=439 min_freq=126\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=438 size=24420 all=449541 active=22526 piece=Ind\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=438 size=24440 all=449684 active=22669 piece=▁Assistenten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=437 size=24460 all=449940 active=22925 piece=▁Geburten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=436 size=24480 all=450147 active=23132 piece=▁burn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=436 size=24500 all=450172 active=23157 piece=▁Schwarzmeer\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=436 min_freq=125\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=435 size=24520 all=450353 active=22682 piece=▁Linkohr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=434 size=24540 all=450461 active=22790 piece=▁wem\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=434 size=24560 all=450586 active=22915 piece=▁verzögern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=433 size=24580 all=450753 active=23082 piece=▁zögern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=432 size=24600 all=450882 active=23211 piece=▁Bre\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=432 min_freq=124\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=431 size=24620 all=450929 active=22575 piece=)].\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=431 size=24640 all=451040 active=22686 piece=▁asiatischen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=430 size=24660 all=451260 active=22906 piece=▁geistige\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=429 size=24680 all=451396 active=23042 piece=▁jahr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=428 size=24700 all=451592 active=23238 piece=habe\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=428 min_freq=123\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=428 size=24720 all=451739 active=22718 piece=▁unhalt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=427 size=24740 all=451795 active=22774 piece=holes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=427 size=24760 all=451993 active=22972 piece=▁eingehender\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=426 size=24780 all=452262 active=23241 piece=▁gebührend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=425 size=24800 all=452352 active=23331 piece=legungs\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=425 min_freq=123\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=425 size=24820 all=452542 active=22707 piece=▁Volksabstimmung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=424 size=24840 all=452798 active=22963 piece=▁Andersson\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=423 size=24860 all=452927 active=23092 piece=commerce\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=422 size=24880 all=453072 active=23237 piece=▁unsu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=422 size=24900 all=453205 active=23370 piece=▁verzögert\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=422 min_freq=122\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=421 size=24920 all=453323 active=22779 piece=▁choosing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=420 size=24940 all=453415 active=22871 piece=▁Eurom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=420 size=24960 all=453460 active=22916 piece=▁Versuchung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=419 size=24980 all=453576 active=23032 piece=erstoff\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=418 size=25000 all=453695 active=23151 piece=Organ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=418 min_freq=121\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=418 size=25020 all=453799 active=22777 piece=▁wendet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=417 size=25040 all=453939 active=22917 piece=▁Micha\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=417 size=25060 all=453995 active=22973 piece=▁notwendiger\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=416 size=25080 all=454162 active=23140 piece=identally\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=415 size=25100 all=454305 active=23283 piece=▁Tindem\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=415 min_freq=120\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=414 size=25120 all=454332 active=22740 piece=▁Take\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=414 size=25140 all=454399 active=22807 piece=▁feasibility\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=413 size=25160 all=454504 active=22912 piece=zentrum\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=412 size=25180 all=454731 active=23139 piece=▁Band\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=412 size=25200 all=454884 active=23292 piece=▁relocations\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=412 min_freq=120\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=411 size=25220 all=455020 active=22881 piece=▁Notfall\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=410 size=25240 all=455182 active=23043 piece=▁ped\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=410 size=25260 all=455361 active=23222 piece=▁responds\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=409 size=25280 all=455515 active=23376 piece=kredit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=409 size=25300 all=455639 active=23500 piece=▁demonstriert\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=409 min_freq=119\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=408 size=25320 all=455704 active=22847 piece=▁religiöser\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=407 size=25340 all=455839 active=22982 piece=▁Seitdem\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=407 size=25360 all=455871 active=23014 piece=▁aforementioned\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=406 size=25380 all=456158 active=23301 piece=▁versorgen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=405 size=25400 all=456277 active=23420 piece=▁Thomas\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=405 min_freq=118\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=405 size=25420 all=456284 active=22821 piece=▁unterschätzen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=404 size=25440 all=456589 active=23126 piece=▁Garriga\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=403 size=25460 all=456673 active=23210 piece=ppi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=403 size=25480 all=456836 active=23373 piece=ästigung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=402 size=25500 all=456944 active=23481 piece=UTS\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=402 min_freq=117\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=402 size=25520 all=457137 active=23038 piece=▁Fischereir\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=401 size=25540 all=457226 active=23127 piece=▁shed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=400 size=25560 all=457292 active=23193 piece=ozi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=400 size=25580 all=457545 active=23446 piece=▁beliefs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=399 size=25600 all=457577 active=23478 piece=ARD\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=399 min_freq=117\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=399 size=25620 all=457699 active=22993 piece=▁erteile\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=398 size=25640 all=457881 active=23175 piece=rants\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=398 size=25660 all=458033 active=23327 piece=▁combining\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=397 size=25680 all=458286 active=23580 piece=▁deckt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=397 size=25700 all=458438 active=23732 piece=▁Richtungen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=397 min_freq=116\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=396 size=25720 all=458532 active=23016 piece=▁machine\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=395 size=25740 all=458542 active=23026 piece=varez\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=395 size=25760 all=458641 active=23125 piece=▁zufällig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=394 size=25780 all=458830 active=23314 piece=boden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=394 size=25800 all=459062 active=23546 piece=▁broadcas\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=394 min_freq=115\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=393 size=25820 all=459148 active=23037 piece=▁pool\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=393 size=25840 all=459231 active=23120 piece=▁Agrarausgaben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=392 size=25860 all=459484 active=23373 piece=spolitischer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=391 size=25880 all=459634 active=23523 piece=▁Proteste\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=390 size=25900 all=459764 active=23653 piece=▁Too\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=390 min_freq=114\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=390 size=25920 all=459935 active=23159 piece=▁Subvention\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=389 size=25940 all=460163 active=23387 piece=▁Drucks\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=388 size=25960 all=460178 active=23402 piece=llten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=388 size=25980 all=460350 active=23574 piece=▁wondering\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=387 size=26000 all=460442 active=23666 piece=▁Palette\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=387 min_freq=114\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=386 size=26020 all=460505 active=23086 piece=▁odd\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=386 size=26040 all=460839 active=23420 piece=▁Liechten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=385 size=26060 all=461181 active=23762 piece=▁häus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=385 size=26080 all=461233 active=23814 piece=▁Freihandel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=384 size=26100 all=461458 active=24039 piece=legenen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=384 min_freq=113\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=384 size=26120 all=461561 active=23167 piece=▁Befürchtung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=383 size=26140 all=461714 active=23320 piece=ipelines\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=383 size=26160 all=461780 active=23386 piece=Übereinkommens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=382 size=26180 all=462034 active=23640 piece=▁betreibt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=381 size=26200 all=462105 active=23711 piece=▁Depre\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=381 min_freq=112\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=381 size=26220 all=462164 active=23163 piece=▁unterschrieben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=380 size=26240 all=462379 active=23378 piece=▁Berater\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=379 size=26260 all=462433 active=23432 piece=Arab\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=379 size=26280 all=462644 active=23643 piece=ordination\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=378 size=26300 all=462750 active=23749 piece=▁befugt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=378 min_freq=112\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=378 size=26320 all=462803 active=23191 piece=▁Bewerberländer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=377 size=26340 all=462978 active=23366 piece=▁traders\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=376 size=26360 all=463075 active=23463 piece=kay\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=376 size=26380 all=463294 active=23682 piece=▁tsunami\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=375 size=26400 all=463397 active=23785 piece=▁Cat\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=375 min_freq=111\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=375 size=26420 all=463493 active=23254 piece=▁Benchmark\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=374 size=26440 all=463771 active=23532 piece=oise\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=374 size=26460 all=463884 active=23645 piece=▁Demzufolge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=373 size=26480 all=463982 active=23743 piece=Aktion\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=373 size=26500 all=464104 active=23865 piece=▁Herrschaft\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=373 min_freq=110\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=372 size=26520 all=464118 active=23219 piece=flation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=372 size=26540 all=464173 active=23274 piece=▁irreversible\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=371 size=26560 all=464338 active=23439 piece=▁Michael\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=371 size=26580 all=464377 active=23478 piece=▁aufgezwungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=370 size=26600 all=464615 active=23716 piece=▁hartnäck\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=370 min_freq=110\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=369 size=26620 all=464736 active=23346 piece=▁Asy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=369 size=26640 all=464880 active=23490 piece=▁Dialogue\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=369 size=26660 all=464903 active=23513 piece=▁Veranstaltungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=368 size=26680 all=465023 active=23633 piece=▁Polizeibe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=367 size=26700 all=465184 active=23794 piece=▁doctr\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=367 min_freq=109\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=367 size=26720 all=465296 active=23367 piece=▁incomplete\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=366 size=26740 all=465405 active=23476 piece=rainer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=366 size=26760 all=465523 active=23594 piece=▁Binnenschiff\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=365 size=26780 all=465754 active=23825 piece=▁mutige\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=365 size=26800 all=465904 active=23975 piece=▁Diamandouros\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=365 min_freq=108\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=364 size=26820 all=466045 active=23437 piece=▁Rwanda\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=363 size=26840 all=466128 active=23520 piece=▁Hope\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=363 size=26860 all=466303 active=23695 piece=▁angelangt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=362 size=26880 all=466406 active=23798 piece=▁Campos\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=362 size=26900 all=466445 active=23837 piece=▁ähnliches\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=362 min_freq=108\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=361 size=26920 all=466532 active=23410 piece=terten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=360 size=26940 all=466792 active=23670 piece=ça\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=360 size=26960 all=466966 active=23844 piece=▁Materie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=360 size=26980 all=466966 active=23844 piece=▁unnecessarily\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=359 size=27000 all=467143 active=24021 piece=▁blatant\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=359 min_freq=107\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=359 size=27020 all=467156 active=23371 piece=▁lebenslanges\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=358 size=27040 all=467455 active=23670 piece=▁cater\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=358 size=27060 all=467542 active=23757 piece=▁ausspricht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=357 size=27080 all=467649 active=23864 piece=▁seventh\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=357 size=27100 all=467655 active=23870 piece=▁Verantwortungs\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=357 min_freq=106\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=356 size=27120 all=467944 active=23671 piece=▁emerges\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=355 size=27140 all=467978 active=23705 piece=GR\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=355 size=27160 all=468128 active=23855 piece=▁Eingreif\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=354 size=27180 all=468290 active=24017 piece=health\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=354 size=27200 all=468309 active=24036 piece=▁Schweizer\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=354 min_freq=106\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=353 size=27220 all=468360 active=23464 piece=▁Nazi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=353 size=27240 all=468394 active=23498 piece=schreitend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=352 size=27260 all=468414 active=23518 piece=tech\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=352 size=27280 all=468463 active=23567 piece=sproblemen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=351 size=27300 all=468588 active=23692 piece=▁ED\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=351 min_freq=105\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=351 size=27320 all=468701 active=23535 piece=▁Seeleute\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=350 size=27340 all=468713 active=23547 piece=ST\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=350 size=27360 all=468977 active=23811 piece=▁winners\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=349 size=27380 all=469109 active=23943 piece=ayot\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=349 size=27400 all=469318 active=24152 piece=▁Landwirt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=349 min_freq=105\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=348 size=27420 all=469417 active=23563 piece=zahler\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=348 size=27440 all=469555 active=23701 piece=▁shipowners\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=347 size=27460 all=469767 active=23913 piece=▁ginge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=347 size=27480 all=469829 active=23975 piece=urteilungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=346 size=27500 all=469898 active=24044 piece=gefahr\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=346 min_freq=104\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=346 size=27520 all=469982 active=23536 piece=▁expulsion\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=345 size=27540 all=470144 active=23698 piece=▁Dog\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=344 size=27560 all=470239 active=23793 piece=▁web\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=344 size=27580 all=470430 active=23984 piece=▁Kaschmir\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=343 size=27600 all=470490 active=24044 piece=Kopf\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=343 min_freq=103\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=343 size=27620 all=470725 active=23751 piece=▁Werften\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=342 size=27640 all=470776 active=23802 piece=duct\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=342 size=27660 all=471043 active=24069 piece=utauschen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=341 size=27680 all=471051 active=24077 piece=felds\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=341 size=27700 all=471217 active=24243 piece=▁wundern\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=341 min_freq=103\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=340 size=27720 all=471341 active=23685 piece=▁brä\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=340 size=27740 all=471534 active=23878 piece=Konvention\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=339 size=27760 all=471816 active=24160 piece=regime\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=339 size=27780 all=472004 active=24348 piece=▁informelle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=338 size=27800 all=472193 active=24537 piece=▁infiz\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=338 min_freq=102\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=338 size=27820 all=472265 active=23675 piece=▁Begleitung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=337 size=27840 all=472434 active=23844 piece=▁Arias\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=337 size=27860 all=472475 active=23885 piece=▁Berechnungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=336 size=27880 all=472652 active=24062 piece=▁plane\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=336 size=27900 all=472798 active=24208 piece=▁dringlich\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=336 min_freq=101\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=335 size=27920 all=472854 active=23691 piece=hofft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=335 size=27940 all=472978 active=23815 piece=▁stürzen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=334 size=27960 all=473025 active=23862 piece=vell\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=334 size=27980 all=473213 active=24050 piece=avigations\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=333 size=28000 all=473285 active=24122 piece=▁bon\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=333 min_freq=101\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=333 size=28020 all=473341 active=23708 piece=▁bankruptcy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=332 size=28040 all=473449 active=23816 piece=streich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=332 size=28060 all=473584 active=23951 piece=▁Komponenten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=331 size=28080 all=473695 active=24062 piece=▁Dilemma\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=331 size=28100 all=473732 active=24099 piece=▁ausreichender\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=331 min_freq=100\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=330 size=28120 all=473917 active=23872 piece=Minister\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=330 size=28140 all=473943 active=23898 piece=infrastrukturen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=329 size=28160 all=474082 active=24037 piece=▁geraum\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=329 size=28180 all=474141 active=24096 piece=▁Brustkrebs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=328 size=28200 all=474320 active=24275 piece=ophobic\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=328 min_freq=100\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=328 size=28220 all=474427 active=23813 piece=▁consisting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=327 size=28240 all=474572 active=23958 piece=▁dump\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=327 size=28260 all=474842 active=24228 piece=▁machten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=327 size=28280 all=474920 active=24306 piece=▁Treibhausgase\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=326 size=28300 all=475166 active=24552 piece=▁despair\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=326 min_freq=99\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=326 size=28320 all=475192 active=23782 piece=▁weitergegeben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=325 size=28340 all=475404 active=23994 piece=▁Keyser\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=325 size=28360 all=475502 active=24092 piece=▁qualities\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=324 size=28380 all=475655 active=24245 piece=horst\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=324 size=28400 all=475757 active=24347 piece=▁gefoltert\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=324 min_freq=99\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=323 size=28420 all=475858 active=23889 piece=▁laud\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=323 size=28440 all=475955 active=23986 piece=▁Versand\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=322 size=28460 all=475981 active=24012 piece=nels\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=322 size=28480 all=476128 active=24159 piece=gedanken\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=322 size=28500 all=476147 active=24178 piece=▁constituent\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=322 min_freq=98\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=321 size=28520 all=476234 active=23895 piece=▁ausgen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=321 size=28540 all=476314 active=23975 piece=▁einberufen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=320 size=28560 all=476498 active=24159 piece=▁krank\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=320 size=28580 all=476615 active=24276 piece=▁overnight\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=319 size=28600 all=476826 active=24487 piece=▁länder\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=319 min_freq=98\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=318 size=28620 all=476855 active=23862 piece=kov\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=318 size=28640 all=477012 active=24019 piece=▁Chechen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=318 size=28660 all=477003 active=24010 piece=▁Genehmigungs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=317 size=28680 all=477214 active=24221 piece=▁schlug\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=317 size=28700 all=477263 active=24270 piece=▁mobilising\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=317 min_freq=97\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=316 size=28720 all=477476 active=24077 piece=▁null\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=316 size=28740 all=477513 active=24114 piece=▁womöglich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=315 size=28760 all=477657 active=24258 piece=beiträge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=315 size=28780 all=477739 active=24340 piece=▁infolgedessen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=314 size=28800 all=477919 active=24520 piece=lichere\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=314 min_freq=97\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=314 size=28820 all=478027 active=23968 piece=▁Kompromissen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=313 size=28840 all=478156 active=24097 piece=▁Menrad\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=313 size=28860 all=478197 active=24138 piece=▁intensity\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=312 size=28880 all=478216 active=24157 piece=▁87\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=312 size=28900 all=478385 active=24326 piece=▁übrige\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=312 min_freq=96\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=312 size=28920 all=478408 active=23943 piece=▁scepticism\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=311 size=28940 all=478593 active=24128 piece=▁Stubb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=311 size=28960 all=478645 active=24180 piece=speicherung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=310 size=28980 all=478743 active=24278 piece=▁Färm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=310 size=29000 all=478775 active=24310 piece=▁presently\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=310 min_freq=96\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=309 size=29020 all=478856 active=24020 piece=▁fits\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=309 size=29040 all=478967 active=24131 piece=▁comprising\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=308 size=29060 all=479027 active=24191 piece=chnen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=308 size=29080 all=479153 active=24317 piece=▁conducive\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=307 size=29100 all=479356 active=24520 piece=▁BBC\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=307 min_freq=95\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=307 size=29120 all=479492 active=24103 piece=▁Fifthly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=307 size=29140 all=479498 active=24109 piece=▁entrepreneurial\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=306 size=29160 all=479672 active=24283 piece=▁Generell\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=306 size=29180 all=479656 active=24267 piece=▁Zersplitterung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=305 size=29200 all=479839 active=24450 piece=untern\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=305 min_freq=95\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=305 size=29220 all=480003 active=24147 piece=▁logistics\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=304 size=29240 all=480177 active=24321 piece=ivic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=304 size=29260 all=480278 active=24422 piece=▁Ostens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=304 size=29280 all=480353 active=24497 piece=▁zuzuhören\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=303 size=29300 all=480348 active=24492 piece=aida\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=303 min_freq=94\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=303 size=29320 all=480587 active=24250 piece=▁Ossetia\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=303 size=29340 all=480623 active=24286 piece=▁Architektur\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=302 size=29360 all=480682 active=24345 piece=▁zusch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=302 size=29380 all=480739 active=24402 piece=▁Philippinen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=301 size=29400 all=480840 active=24503 piece=leister\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=301 min_freq=94\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=301 size=29420 all=480987 active=24183 piece=▁forcefully\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=300 size=29440 all=481042 active=24238 piece=run\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=300 size=29460 all=481212 active=24408 piece=▁passes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=300 size=29480 all=481274 active=24470 piece=▁Hungarians\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=299 size=29500 all=481544 active=24740 piece=light\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=299 min_freq=93\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=299 size=29520 all=481809 active=24329 piece=▁Demnach\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=299 size=29540 all=481815 active=24335 piece=▁vorangebracht\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=298 size=29560 all=482001 active=24521 piece=▁Schwab\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=298 size=29580 all=481999 active=24519 piece=▁explosion\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=298 size=29600 all=481993 active=24513 piece=▁Berichtsentwurf\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=297 min_freq=93\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=297 size=29620 all=482209 active=24316 piece=▁feared\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=297 size=29640 all=482258 active=24365 piece=▁auszurichten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=296 size=29660 all=482354 active=24461 piece=▁agri\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=296 size=29680 all=482530 active=24637 piece=▁Recital\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=296 size=29700 all=482537 active=24644 piece=▁detaillierter\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=296 min_freq=92\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=295 size=29720 all=482675 active=24262 piece=▁Elmar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=295 size=29740 all=482720 active=24307 piece=▁Benutzung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=295 size=29760 all=482718 active=24305 piece=▁Überprüfungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=294 size=29780 all=482897 active=24484 piece=▁erlaube\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=294 size=29800 all=482918 active=24505 piece=▁Meerespolitik\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=294 min_freq=92\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=293 size=29820 all=483105 active=24332 piece=/2004)\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=293 size=29840 all=483228 active=24455 piece=▁Benennung\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=292 size=29860 all=483270 active=24497 piece=tedt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=292 size=29880 all=483501 active=24728 piece=▁provoc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=292 size=29900 all=483581 active=24808 piece=▁Berufsleben\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=292 min_freq=91\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=291 size=29920 all=483653 active=24252 piece=abgaben\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=291 size=29940 all=483770 active=24369 piece=▁Datenbanken\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=290 size=29960 all=483942 active=24541 piece=▁Gläub\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=290 size=29980 all=484029 active=24628 piece=ionalität\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=289 size=30000 all=484040 active=24639 piece=lig\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=289 min_freq=91\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=289 size=30020 all=484199 active=24329 piece=▁opfern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=289 size=30040 all=484245 active=24375 piece=▁pregnancy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=288 size=30060 all=484303 active=24433 piece=▁Vort\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=288 size=30080 all=484458 active=24588 piece=wasserst\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=288 size=30100 all=484506 active=24636 piece=▁utilisation\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=288 min_freq=90\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=287 size=30120 all=484562 active=24282 piece=▁Nitrat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=287 size=30140 all=484638 active=24358 piece=▁incorporates\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=286 size=30160 all=484787 active=24507 piece=mitten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=286 size=30180 all=484888 active=24608 piece=▁Umweltze\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=286 size=30200 all=484906 active=24626 piece=▁Rahmenabkommen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=286 min_freq=90\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=285 size=30220 all=485072 active=24412 piece=▁starch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=285 size=30240 all=485094 active=24434 piece=▁präzisiert\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=284 size=30260 all=485185 active=24525 piece=oweit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=284 size=30280 all=485292 active=24632 piece=▁coincide\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=284 size=30300 all=485310 active=24650 piece=▁belarussischen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=284 min_freq=89\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=283 size=30320 all=485461 active=24417 piece=▁Bergreg\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=283 size=30340 all=485493 active=24449 piece=▁consultative\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=282 size=30360 all=485750 active=24706 piece=bedingte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=282 size=30380 all=485886 active=24842 piece=▁Grundpfeiler\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=281 size=30400 all=486087 active=25043 piece=innern\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=281 min_freq=89\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=281 size=30420 all=486287 active=24495 piece=▁Spezifik\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=281 size=30440 all=486304 active=24512 piece=▁Reconstruction\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=280 size=30460 all=486447 active=24655 piece=▁Effekte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=280 size=30480 all=486455 active=24663 piece=▁Kernkraftwerk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=279 size=30500 all=486722 active=24930 piece=▁Irre\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=279 min_freq=88\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=279 size=30520 all=486818 active=24418 piece=▁Gesamtz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=279 size=30540 all=486862 active=24462 piece=▁entsprechendes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=278 size=30560 all=487018 active=24618 piece=▁Krimine\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=278 size=30580 all=487080 active=24680 piece=▁benachteiligte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=277 size=30600 all=487281 active=24881 piece=▁konsum\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=277 min_freq=88\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=277 size=30620 all=487381 active=24452 piece=▁beunruhigen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=276 size=30640 all=487592 active=24663 piece=▁leis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=276 size=30660 all=487686 active=24757 piece=▁verwurz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=276 size=30680 all=487721 active=24792 piece=▁pragmatisch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=275 size=30700 all=487789 active=24860 piece=breite\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=275 min_freq=87\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=275 size=30720 all=487842 active=24423 piece=▁lebende\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=275 size=30740 all=487868 active=24449 piece=▁precautions\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=274 size=30760 all=488063 active=24644 piece=▁ernen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=274 size=30780 all=488126 active=24707 piece=▁Positives\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=274 size=30800 all=488119 active=24700 piece=▁beträchtlicher\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=274 min_freq=87\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=273 size=30820 all=488213 active=24500 piece=▁liest\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=273 size=30840 all=488285 active=24572 piece=▁stipulate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=272 size=30860 all=488326 active=24613 piece=▁Ear\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=272 size=30880 all=488439 active=24726 piece=keptiker\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=272 size=30900 all=488468 active=24755 piece=▁Anwendungs\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=272 min_freq=87\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=271 size=30920 all=488700 active=24627 piece=Afrika\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=271 size=30940 all=488719 active=24646 piece=▁mentality\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=270 size=30960 all=488749 active=24676 piece=iano\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=270 size=30980 all=489016 active=24943 piece=▁Anwalt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=270 size=31000 all=489139 active=25066 piece=▁britischer\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=270 min_freq=86\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=269 size=31020 all=489213 active=24531 piece=▁Käl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=269 size=31040 all=489399 active=24717 piece=▁Volumen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=269 size=31060 all=489445 active=24763 piece=▁Fachleuten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=268 size=31080 all=489551 active=24869 piece=strom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=268 size=31100 all=489750 active=25068 piece=▁ungew\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=268 min_freq=86\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=268 size=31120 all=489880 active=24608 piece=▁Bindungen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=268 size=31140 all=489908 active=24636 piece=Währungsgebiet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=267 size=31160 all=490054 active=24782 piece=prises\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=267 size=31180 all=490103 active=24831 piece=mißbrauch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=267 size=31200 all=490129 active=24857 piece=▁Bergregionen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=267 min_freq=85\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=266 size=31220 all=490300 active=24678 piece=▁Gasò\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=266 size=31240 all=490328 active=24706 piece=▁Ökonom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=266 size=31260 all=490429 active=24807 piece=▁Antisemit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=265 size=31280 all=490490 active=24868 piece=▁Pel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=265 size=31300 all=490639 active=25017 piece=▁Buenos\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=265 min_freq=85\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=265 size=31320 all=490729 active=24622 piece=▁präzisen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=264 size=31340 all=490816 active=24709 piece=▁Ries\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=264 size=31360 all=491039 active=24932 piece=▁worded\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=264 size=31380 all=491101 active=24994 piece=▁Aufbauwerks\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=263 size=31400 all=491306 active=25199 piece=▁ow\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=263 min_freq=84\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=263 size=31420 all=491526 active=24784 piece=▁Sammel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=263 size=31440 all=491591 active=24849 piece=▁meanwhile\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=262 size=31460 all=491694 active=24952 piece=▁hur\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=262 size=31480 all=491783 active=25041 piece=▁Samland\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=262 size=31500 all=491797 active=25055 piece=▁verkünden\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=262 min_freq=84\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=261 size=31520 all=491872 active=24664 piece=nieß\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=261 size=31540 all=492073 active=24865 piece=▁Wüsten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=261 size=31560 all=492112 active=24904 piece=▁geeignetes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=260 size=31580 all=492244 active=25036 piece=ové\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=260 size=31600 all=492622 active=25414 piece=▁Aarhus\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=260 min_freq=83\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=260 size=31620 all=492648 active=24658 piece=▁akzeptablen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=259 size=31640 all=492875 active=24885 piece=▁TSE\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=259 size=31660 all=492987 active=24997 piece=▁Ökolog\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=259 size=31680 all=493000 active=25010 piece=▁mountains\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: translation_tokenizer.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: translation_tokenizer.vocab\n",
      "Tokenizer training complete!\n",
      "Loading tokenizer...\n",
      "\n",
      "Tokenizer Info:\n",
      "Vocabulary size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "\n",
      "Creating dataloaders...\n",
      "\n",
      "Training set sample:\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Input (DE): [DE] Veränderungen sollten nicht zu schnell eingeführt werden oder zu radikal sein, weil sonst die öffentliche Meinung eine Ratifizierung künftiger EU-Verträge erheblich erschweren könnte.\n",
      "Target (EN): [EN] Changes should not be brought about too quickly and cannot be too sweeping, otherwise public opinion will make ratification of any future European Union treaty very difficult indeed.\n",
      "\n",
      "Validation set sample:\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Input (DE): [DE] Wenn Sie den Text aufmerksam lesen, so können Sie erkennen, daß dieser Vorschlag für eine Kapitalsteuer ein ganz normales Instrument darstellt, mit dem versucht werden soll, die internationalen Anleger zu einem verantwortlichen Handeln auf den Finanzmärkten zu verpflichten.\n",
      "Target (EN): [EN] If you look carefully, this proposed tax on capital is just one of several instruments aimed at forcing international investors to behave responsibly on the financial markets.\n",
      "\n",
      "Test set sample:\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4Input (DE): [DE] Auch vor dem Hintergrund dieser Maßnahmenliste, die im übrigen nicht einmal vollständig ist, kann ich hier und heute vor der Ratspräsidentschaft und den Abgeordneten erneut und mit großer Überzeugung versichern: Wenn 1999 das Jahr der Konsolidierung des Wirkens der Union in diesem maßgeblichen Bereich war, so hoffe ich, daß 1999 auch der Aufbruch in eine neuen Phase war, deren Ziel die Beschleunigung der Schaffung eines Raums der Freiheit, der Sicherheit und des Rechts ist.\n",
      "Target (EN): [EN] This list of actions, which is not exhaustive, should, here today, in the presence of the Council Presidency and of the Members of this House, help to make it clear that, while 1999 was a year of consolidation for EU action in this key area, it also - I very much hope - represented the start of a new phase, marked by the desire to speed up the establishment of an area of freedom, security and justice.\n",
      "\n",
      "  [EN] ID: 5\n",
      "\n",
      "Epoch 1/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "/opt/anaconda3/envs/de-en-translator/lib/python3.9/site-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 1/250 [00:09<41:13,  9.93s/it, loss=10.5732, tokens/sMax input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:14<28:40,  6.94s/it, loss=10.1458, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:16<19:33,  4.75s/it, loss=9.9033, tokens/s=Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:23<21:40,  5.29s/it, loss=9.7271, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:25<16:49,  4.12s/it, loss=9.5938, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:29<17:10,  4.22s/it, loss=9.4944, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:32<15:53,  3.92s/it, loss=9.4077, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:37<16:16,  4.04s/it, loss=9.3361, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:42<17:56,  4.47s/it, loss=9.2667, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:44<15:16,  3.82s/it, loss=9.1972, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:48<14:29,  3.64s/it, loss=9.1351, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:52<15:42,  3.96s/it, loss=9.0864, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:56<15:28,  3.92s/it, loss=9.0352, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:58<13:06,  3.33s/it, loss=8.9784, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [01:01<12:15,  3.13s/it, loss=8.9199, tokens/sMax input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [01:05<13:52,  3.56s/it, loss=8.8660, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [01:09<14:14,  3.67s/it, loss=8.8259, tokens/sMax input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:13<14:33,  3.77s/it, loss=8.7754, tokens/sMax input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:19<16:38,  4.32s/it, loss=8.7297, tokens/sMax input_id: 31773\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:26<20:04,  5.24s/it, loss=8.6865, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:29<16:45,  4.39s/it, loss=8.6399, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:32<15:56,  4.19s/it, loss=8.6025, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:35<13:50,  3.66s/it, loss=8.5567, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:38<13:32,  3.60s/it, loss=8.5217, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:45<16:57,  4.52s/it, loss=8.4823, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:51<19:06,  5.12s/it, loss=8.4464, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:54<16:24,  4.42s/it, loss=8.4089, tokens/sMax input_id: 31771\n",
      "Max target_input: 31806\n",
      "Max label: 31806\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [02:00<17:57,  4.85s/it, loss=8.3769, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [02:03<15:55,  4.32s/it, loss=8.3426, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [02:05<13:35,  3.71s/it, loss=8.3049, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [02:09<13:06,  3.59s/it, loss=8.2735, tokens/sMax input_id: 31764\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [02:15<16:23,  4.51s/it, loss=8.2362, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [02:18<14:43,  4.07s/it, loss=8.2043, tokens/sMax input_id: 31767\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:22<14:25,  4.01s/it, loss=8.1726, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:27<14:34,  4.07s/it, loss=8.1462, tokens/sMax input_id: 31766\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:29<12:50,  3.60s/it, loss=8.1131, tokens/sMax input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:32<12:10,  3.43s/it, loss=8.0785, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:34<10:45,  3.04s/it, loss=8.0450, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:39<12:51,  3.65s/it, loss=8.0108, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:42<12:03,  3.44s/it, loss=7.9822, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:45<11:25,  3.28s/it, loss=7.9528, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:49<12:06,  3.49s/it, loss=7.9205, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:54<13:34,  3.93s/it, loss=7.8944, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:57<12:05,  3.52s/it, loss=7.8646, tokens/sMax input_id: 31770\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [03:00<12:19,  3.61s/it, loss=7.8377, tokens/sMax input_id: 31769\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [03:03<11:11,  3.29s/it, loss=7.8126, tokens/sMax input_id: 31767\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [03:06<10:45,  3.18s/it, loss=7.7847, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [03:13<14:15,  4.24s/it, loss=7.7539, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [03:16<13:12,  3.94s/it, loss=7.7273, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [03:19<12:39,  3.80s/it, loss=7.7045, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [03:27<16:05,  4.85s/it, loss=7.6813, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:29<13:46,  4.18s/it, loss=7.6551, tokens/sMax input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:32<12:40,  3.86s/it, loss=7.6300, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:39<14:55,  4.57s/it, loss=7.6083, tokens/sMax input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:42<14:01,  4.32s/it, loss=7.5879, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:46<13:06,  4.05s/it, loss=7.5651, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:48<11:28,  3.57s/it, loss=7.5397, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:53<12:37,  3.95s/it, loss=7.5186, tokens/sMax input_id: 31764\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:56<11:54,  3.74s/it, loss=7.4966, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [04:01<13:07,  4.14s/it, loss=7.4751, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [04:05<12:44,  4.04s/it, loss=7.4530, tokens/sMax input_id: 31770\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [04:08<11:27,  3.66s/it, loss=7.4316, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [04:11<10:23,  3.34s/it, loss=7.4092, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [04:17<13:39,  4.41s/it, loss=7.3881, tokens/sMax input_id: 31767\n",
      "Max target_input: 31766\n",
      "Max label: 31766\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [04:22<13:27,  4.36s/it, loss=7.3679, tokens/sMax input_id: 31781\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [04:29<15:38,  5.10s/it, loss=7.3478, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [04:31<13:19,  4.37s/it, loss=7.3273, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [04:36<13:35,  4.48s/it, loss=7.3085, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [04:41<13:59,  4.64s/it, loss=7.2893, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [04:45<13:14,  4.42s/it, loss=7.2712, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:50<13:57,  4.68s/it, loss=7.2518, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:53<12:02,  4.06s/it, loss=7.2336, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:56<11:14,  3.81s/it, loss=7.2143, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:59<10:09,  3.46s/it, loss=7.1986, tokens/sMax input_id: 31767\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [05:01<09:00,  3.09s/it, loss=7.1815, tokens/sMax input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [05:05<10:14,  3.53s/it, loss=7.1658, tokens/sMax input_id: 31867\n",
      "Max target_input: 31867\n",
      "Max label: 31867\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [05:09<10:14,  3.55s/it, loss=7.1513, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [05:14<11:42,  4.09s/it, loss=7.1367, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [05:17<10:37,  3.73s/it, loss=7.1223, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [05:23<12:43,  4.49s/it, loss=7.1078, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [05:26<10:47,  3.83s/it, loss=7.0945, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [05:30<11:14,  4.02s/it, loss=7.0806, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [05:34<10:43,  3.85s/it, loss=7.0659, tokens/sMax input_id: 31794\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [05:41<13:17,  4.81s/it, loss=7.0523, tokens/sMax input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [05:43<11:30,  4.19s/it, loss=7.0377, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [05:46<10:01,  3.67s/it, loss=7.0207, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [05:49<09:22,  3.45s/it, loss=7.0070, tokens/sMax input_id: 31782\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [05:51<08:39,  3.21s/it, loss=6.9936, tokens/sMax input_id: 31789\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [05:59<11:46,  4.39s/it, loss=6.9826, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [06:01<09:54,  3.72s/it, loss=6.9687, tokens/sMax input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [06:04<09:25,  3.56s/it, loss=6.9559, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [06:07<08:46,  3.33s/it, loss=6.9443, tokens/sMax input_id: 31782\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [06:10<08:29,  3.24s/it, loss=6.9339, tokens/sMax input_id: 31761\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [06:11<07:09,  2.76s/it, loss=6.9200, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [06:14<07:03,  2.73s/it, loss=6.9105, tokens/sMax input_id: 31772\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [06:17<07:16,  2.84s/it, loss=6.8962, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [06:20<06:56,  2.72s/it, loss=6.8839, tokens/sMax input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [06:25<08:41,  3.43s/it, loss=6.8745, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [06:27<07:51,  3.12s/it, loss=6.8593, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [06:34<10:48,  4.32s/it, loss=6.8508, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [06:36<09:02,  3.64s/it, loss=6.8401, tokens/Max input_id: 31771\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [06:39<08:10,  3.31s/it, loss=6.8279, tokens/Max input_id: 31771\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [06:42<07:57,  3.25s/it, loss=6.8163, tokens/Max input_id: 31794\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [06:46<08:26,  3.47s/it, loss=6.8074, tokens/Max input_id: 31738\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [06:48<07:31,  3.11s/it, loss=6.7970, tokens/Max input_id: 31766\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [06:53<08:40,  3.61s/it, loss=6.7865, tokens/Max input_id: 31771\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [06:56<08:08,  3.41s/it, loss=6.7762, tokens/Max input_id: 31767\n",
      "Max target_input: 31825\n",
      "Max label: 31825\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [06:58<07:27,  3.15s/it, loss=6.7664, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [07:01<06:52,  2.92s/it, loss=6.7581, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [07:05<07:38,  3.28s/it, loss=6.7481, tokens/Max input_id: 31771\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [07:09<07:55,  3.42s/it, loss=6.7403, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [07:11<07:19,  3.19s/it, loss=6.7303, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [07:20<10:45,  4.71s/it, loss=6.7214, tokens/Max input_id: 31803\n",
      "Max target_input: 31803\n",
      "Max label: 31803\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [07:22<09:11,  4.05s/it, loss=6.7126, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [07:25<07:58,  3.55s/it, loss=6.7029, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [07:28<07:43,  3.46s/it, loss=6.6941, tokens/Max input_id: 31779\n",
      "Max target_input: 31779\n",
      "Max label: 31779\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [07:34<09:19,  4.21s/it, loss=6.6870, tokens/Max input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [07:41<11:05,  5.04s/it, loss=6.6785, tokens/Max input_id: 31764\n",
      "Max target_input: 31828\n",
      "Max label: 31828\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [07:44<09:46,  4.48s/it, loss=6.6712, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [07:46<08:09,  3.77s/it, loss=6.6624, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [07:50<07:59,  3.72s/it, loss=6.6549, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [07:53<07:52,  3.70s/it, loss=6.6485, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [07:57<08:10,  3.86s/it, loss=6.6406, tokens/Max input_id: 31782\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [08:00<07:01,  3.34s/it, loss=6.6309, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [08:03<07:08,  3.43s/it, loss=6.6226, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [08:06<06:50,  3.31s/it, loss=6.6147, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [08:08<05:55,  2.89s/it, loss=6.6061, tokens/Max input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [08:11<05:53,  2.90s/it, loss=6.5978, tokens/Max input_id: 31771\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [08:13<05:24,  2.68s/it, loss=6.5894, tokens/Max input_id: 31771\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [08:17<05:53,  2.95s/it, loss=6.5817, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [08:21<06:26,  3.25s/it, loss=6.5767, tokens/Max input_id: 31768\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [08:23<05:59,  3.04s/it, loss=6.5693, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [08:25<05:20,  2.74s/it, loss=6.5620, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [08:32<07:15,  3.76s/it, loss=6.5538, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [08:37<07:56,  4.15s/it, loss=6.5459, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [08:41<07:59,  4.21s/it, loss=6.5395, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [08:43<06:48,  3.61s/it, loss=6.5317, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [08:46<06:20,  3.40s/it, loss=6.5241, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [08:49<06:07,  3.31s/it, loss=6.5173, tokens/Max input_id: 31767\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [08:52<05:44,  3.13s/it, loss=6.5116, tokens/Max input_id: 31772\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [08:56<06:19,  3.48s/it, loss=6.5044, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [08:58<05:32,  3.08s/it, loss=6.4983, tokens/Max input_id: 31794\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [09:01<05:30,  3.09s/it, loss=6.4911, tokens/Max input_id: 31815\n",
      "Max target_input: 31815\n",
      "Max label: 31815\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [09:04<05:12,  2.95s/it, loss=6.4832, tokens/Max input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [09:09<06:18,  3.61s/it, loss=6.4781, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [09:12<05:41,  3.29s/it, loss=6.4723, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [09:14<04:57,  2.89s/it, loss=6.4650, tokens/Max input_id: 31768\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [09:17<05:04,  2.99s/it, loss=6.4606, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [09:21<05:45,  3.42s/it, loss=6.4552, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [09:26<06:26,  3.86s/it, loss=6.4496, tokens/Max input_id: 31794\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [09:29<05:49,  3.53s/it, loss=6.4447, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [09:33<06:05,  3.73s/it, loss=6.4390, tokens/Max input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [09:36<05:31,  3.41s/it, loss=6.4335, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [09:40<06:00,  3.76s/it, loss=6.4267, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [09:42<05:05,  3.21s/it, loss=6.4215, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [09:46<05:11,  3.31s/it, loss=6.4166, tokens/Max input_id: 31779\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [09:50<05:22,  3.46s/it, loss=6.4118, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [09:54<05:37,  3.67s/it, loss=6.4088, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [09:58<05:42,  3.77s/it, loss=6.4035, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [10:01<05:14,  3.50s/it, loss=6.3983, tokens/Max input_id: 31794\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [10:06<06:03,  4.09s/it, loss=6.3929, tokens/Max input_id: 31765\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [10:09<05:31,  3.76s/it, loss=6.3888, tokens/Max input_id: 31767\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [10:11<04:38,  3.20s/it, loss=6.3828, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [10:14<04:17,  3.00s/it, loss=6.3770, tokens/Max input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [10:18<04:49,  3.40s/it, loss=6.3719, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [10:25<06:16,  4.49s/it, loss=6.3678, tokens/Max input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [10:29<05:52,  4.25s/it, loss=6.3617, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [10:32<05:29,  4.02s/it, loss=6.3577, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [10:34<04:30,  3.34s/it, loss=6.3517, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [10:37<04:15,  3.19s/it, loss=6.3466, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [10:44<05:44,  4.36s/it, loss=6.3403, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [10:46<04:41,  3.61s/it, loss=6.3351, tokens/Max input_id: 31789\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [10:49<04:28,  3.49s/it, loss=6.3323, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [10:52<04:17,  3.39s/it, loss=6.3274, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [10:54<03:42,  2.97s/it, loss=6.3229, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [10:59<04:16,  3.46s/it, loss=6.3180, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [11:01<03:58,  3.27s/it, loss=6.3143, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [11:04<03:41,  3.08s/it, loss=6.3090, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [11:08<03:51,  3.26s/it, loss=6.3054, tokens/Max input_id: 31772\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [11:11<03:57,  3.39s/it, loss=6.3010, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [11:14<03:27,  3.00s/it, loss=6.2957, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [11:21<04:52,  4.30s/it, loss=6.2902, tokens/Max input_id: 31771\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [11:24<04:32,  4.07s/it, loss=6.2856, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [11:27<03:56,  3.59s/it, loss=6.2806, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [11:29<03:31,  3.26s/it, loss=6.2769, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [11:33<03:39,  3.43s/it, loss=6.2720, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [11:35<03:05,  2.94s/it, loss=6.2677, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [11:38<02:57,  2.87s/it, loss=6.2630, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [11:41<02:56,  2.89s/it, loss=6.2584, tokens/Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [11:47<03:57,  3.97s/it, loss=6.2544, tokens/Max input_id: 31800\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [11:50<03:37,  3.68s/it, loss=6.2514, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [11:54<03:33,  3.69s/it, loss=6.2465, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [11:57<03:16,  3.45s/it, loss=6.2435, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [12:00<03:12,  3.45s/it, loss=6.2394, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [12:02<02:49,  3.08s/it, loss=6.2354, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [12:05<02:40,  2.97s/it, loss=6.2310, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [12:08<02:28,  2.80s/it, loss=6.2264, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [12:11<02:33,  2.96s/it, loss=6.2210, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [12:14<02:32,  3.00s/it, loss=6.2169, tokens/Max input_id: 31794\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [12:18<02:43,  3.26s/it, loss=6.2131, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [12:25<03:35,  4.39s/it, loss=6.2103, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [12:30<03:39,  4.57s/it, loss=6.2073, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [12:33<03:12,  4.10s/it, loss=6.2032, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [12:36<02:49,  3.69s/it, loss=6.1996, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [12:39<02:38,  3.53s/it, loss=6.1974, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [12:42<02:28,  3.37s/it, loss=6.1941, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [12:45<02:22,  3.31s/it, loss=6.1904, tokens/Max input_id: 31771\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [12:47<02:07,  3.04s/it, loss=6.1872, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [12:51<02:10,  3.18s/it, loss=6.1834, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [12:56<02:29,  3.74s/it, loss=6.1797, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [12:59<02:23,  3.68s/it, loss=6.1746, tokens/Max input_id: 31790\n",
      "Max target_input: 31790\n",
      "Max label: 31790\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [13:03<02:18,  3.65s/it, loss=6.1707, tokens/Max input_id: 31794\n",
      "Max target_input: 31757\n",
      "Max label: 31757\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [13:05<01:59,  3.24s/it, loss=6.1669, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [13:08<01:49,  3.05s/it, loss=6.1635, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [13:10<01:35,  2.73s/it, loss=6.1589, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [13:12<01:31,  2.68s/it, loss=6.1559, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [13:18<01:55,  3.49s/it, loss=6.1519, tokens/Max input_id: 31771\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [13:22<01:54,  3.59s/it, loss=6.1485, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [13:25<01:46,  3.43s/it, loss=6.1446, tokens/Max input_id: 31762\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [13:27<01:36,  3.21s/it, loss=6.1416, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [13:31<01:32,  3.20s/it, loss=6.1376, tokens/Max input_id: 31794\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [13:33<01:25,  3.06s/it, loss=6.1333, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [13:36<01:21,  3.01s/it, loss=6.1299, tokens/Max input_id: 31772\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [13:42<01:40,  3.86s/it, loss=6.1274, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [13:45<01:26,  3.46s/it, loss=6.1235, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [13:47<01:14,  3.10s/it, loss=6.1181, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [13:49<01:02,  2.70s/it, loss=6.1138, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [13:51<00:55,  2.51s/it, loss=6.1096, tokens/Max input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [13:54<00:57,  2.72s/it, loss=6.1068, tokens/Max input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [13:56<00:48,  2.45s/it, loss=6.1029, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [14:01<01:04,  3.38s/it, loss=6.0991, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [14:07<01:12,  4.06s/it, loss=6.0950, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [14:09<00:58,  3.47s/it, loss=6.0909, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [14:16<01:10,  4.43s/it, loss=6.0876, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [14:18<00:57,  3.86s/it, loss=6.0852, tokens/Max input_id: 31797\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [14:24<01:02,  4.50s/it, loss=6.0830, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [14:27<00:51,  3.94s/it, loss=6.0793, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [14:30<00:44,  3.68s/it, loss=6.0763, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [14:34<00:43,  3.94s/it, loss=6.0730, tokens/Max input_id: 31801\n",
      "Max target_input: 31801\n",
      "Max label: 31801\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [14:38<00:37,  3.78s/it, loss=6.0704, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [14:40<00:30,  3.38s/it, loss=6.0672, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [14:43<00:26,  3.30s/it, loss=6.0645, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [14:46<00:21,  3.03s/it, loss=6.0606, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [14:48<00:17,  2.93s/it, loss=6.0583, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [14:51<00:13,  2.75s/it, loss=6.0545, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [14:54<00:11,  2.77s/it, loss=6.0506, tokens/Max input_id: 31782\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Training:  99%|█████████▉| 247/250 [14:59<00:10,  3.62s/it, loss=6.0489, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Training:  99%|█████████▉| 248/250 [15:02<00:06,  3.29s/it, loss=6.0468, tokens/Max input_id: 31800\n",
      "Max target_input: 31800\n",
      "Max label: 31800\n",
      "Training: 100%|█████████▉| 249/250 [15:04<00:03,  3.04s/it, loss=6.0451, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Training: 100%|██████████| 250/250 [15:21<00:00,  3.69s/it, loss=6.0430, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "/opt/anaconda3/envs/de-en-translator/lib/python3.9/site-packages/torch/nn/modules/transformer.py:505: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "Evaluating:   3%|█                               | 1/32 [00:07<03:42,  7.18s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:08<01:50,  3.70s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:10<01:28,  3.04s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:11<01:01,  2.19s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:12<00:48,  1.81s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:13<00:40,  1.58s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:14<00:34,  1.36s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:15<00:29,  1.24s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:17<00:29,  1.26s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:17<00:24,  1.12s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:18<00:23,  1.11s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:19<00:19,  1.02it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:20<00:19,  1.03s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:21<00:16,  1.06it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:22<00:15,  1.09it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:23<00:13,  1.15it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:24<00:14,  1.05it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:25<00:13,  1.06it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:26<00:12,  1.05it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:27<00:11,  1.03it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:27<00:09,  1.15it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:28<00:09,  1.11it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:30<00:10,  1.21s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:31<00:09,  1.22s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:32<00:07,  1.13s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:34<00:07,  1.23s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:35<00:05,  1.14s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:48<00:00,  1.52s/it]\n",
      "Removed old checkpoint: model_epoch_1.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_1.pt\n",
      "Saved training results to training_results_20250511_211346.csv\n",
      "Train Loss: 6.0430\n",
      "Val Loss: 5.2918\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: , the Commission.\n",
      "\n",
      "Epoch 2/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:10<42:23, 10.22s/it, loss=5.0602, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:14<26:56,  6.52s/it, loss=5.2470, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:16<18:35,  4.52s/it, loss=5.2879, tokens/s=Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:22<20:56,  5.11s/it, loss=5.2331, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:24<16:19,  4.00s/it, loss=5.2274, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:28<15:58,  3.93s/it, loss=5.2041, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:31<14:58,  3.70s/it, loss=5.1893, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:34<14:36,  3.62s/it, loss=5.1924, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:40<16:57,  4.22s/it, loss=5.1951, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:42<14:26,  3.61s/it, loss=5.1968, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:45<13:54,  3.49s/it, loss=5.1995, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:49<14:15,  3.60s/it, loss=5.2199, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:53<14:14,  3.60s/it, loss=5.2200, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:55<12:07,  3.08s/it, loss=5.2189, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [00:57<10:50,  2.77s/it, loss=5.2114, tokens/sMax input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [00:59<09:47,  2.51s/it, loss=5.1996, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [01:02<10:28,  2.70s/it, loss=5.2055, tokens/sMax input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:04<10:19,  2.67s/it, loss=5.1973, tokens/sMax input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:09<12:09,  3.16s/it, loss=5.1932, tokens/sMax input_id: 31773\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:17<17:51,  4.66s/it, loss=5.1903, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:19<15:21,  4.02s/it, loss=5.1786, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:24<15:40,  4.12s/it, loss=5.1873, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:26<13:35,  3.59s/it, loss=5.1786, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:31<15:32,  4.13s/it, loss=5.1835, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:37<17:18,  4.62s/it, loss=5.1851, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:44<20:01,  5.36s/it, loss=5.1854, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:47<17:13,  4.63s/it, loss=5.1868, tokens/sMax input_id: 31771\n",
      "Max target_input: 31806\n",
      "Max label: 31806\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [01:54<19:35,  5.30s/it, loss=5.1918, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [01:57<17:22,  4.72s/it, loss=5.1922, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [02:00<14:40,  4.00s/it, loss=5.1874, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [02:06<16:49,  4.61s/it, loss=5.1908, tokens/sMax input_id: 31764\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [02:13<19:54,  5.48s/it, loss=5.1909, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [02:16<17:06,  4.73s/it, loss=5.1923, tokens/sMax input_id: 31767\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:19<15:01,  4.17s/it, loss=5.1956, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:23<14:56,  4.17s/it, loss=5.2023, tokens/sMax input_id: 31766\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:26<13:06,  3.67s/it, loss=5.2016, tokens/sMax input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:29<12:33,  3.54s/it, loss=5.1988, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:32<11:56,  3.38s/it, loss=5.1947, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:38<14:12,  4.04s/it, loss=5.1921, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:41<13:02,  3.72s/it, loss=5.1898, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:44<12:12,  3.51s/it, loss=5.1881, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:47<11:44,  3.39s/it, loss=5.1866, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:51<12:42,  3.68s/it, loss=5.1892, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:54<11:22,  3.31s/it, loss=5.1861, tokens/sMax input_id: 31770\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [02:59<13:31,  3.96s/it, loss=5.1853, tokens/sMax input_id: 31769\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [03:02<11:58,  3.52s/it, loss=5.1884, tokens/sMax input_id: 31767\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [03:05<11:38,  3.44s/it, loss=5.1867, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [03:12<15:23,  4.57s/it, loss=5.1833, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [03:15<14:09,  4.23s/it, loss=5.1830, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [03:22<16:24,  4.92s/it, loss=5.1865, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [03:29<17:59,  5.42s/it, loss=5.1888, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:31<15:03,  4.56s/it, loss=5.1874, tokens/sMax input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:34<13:27,  4.10s/it, loss=5.1852, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:40<15:24,  4.72s/it, loss=5.1885, tokens/sMax input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:43<13:47,  4.24s/it, loss=5.1901, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:46<12:36,  3.90s/it, loss=5.1877, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:49<10:56,  3.40s/it, loss=5.1842, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:56<14:37,  4.57s/it, loss=5.1851, tokens/sMax input_id: 31764\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:58<12:11,  3.83s/it, loss=5.1837, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [04:02<11:58,  3.78s/it, loss=5.1822, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [04:05<11:27,  3.64s/it, loss=5.1802, tokens/sMax input_id: 31770\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [04:08<10:21,  3.31s/it, loss=5.1772, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [04:10<09:22,  3.01s/it, loss=5.1738, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [04:16<12:10,  3.93s/it, loss=5.1727, tokens/sMax input_id: 31767\n",
      "Max target_input: 31766\n",
      "Max label: 31766\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [04:19<10:59,  3.56s/it, loss=5.1706, tokens/sMax input_id: 31781\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [04:25<13:36,  4.44s/it, loss=5.1693, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [04:27<11:27,  3.76s/it, loss=5.1662, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [04:30<10:23,  3.43s/it, loss=5.1644, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [04:33<09:42,  3.22s/it, loss=5.1636, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [04:35<08:49,  2.94s/it, loss=5.1637, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:38<08:49,  2.96s/it, loss=5.1616, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:40<08:16,  2.79s/it, loss=5.1607, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:43<07:55,  2.69s/it, loss=5.1578, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:49<10:29,  3.58s/it, loss=5.1586, tokens/sMax input_id: 31767\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [04:51<09:17,  3.19s/it, loss=5.1570, tokens/sMax input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [04:56<10:39,  3.68s/it, loss=5.1559, tokens/sMax input_id: 31867\n",
      "Max target_input: 31867\n",
      "Max label: 31867\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [04:59<10:37,  3.69s/it, loss=5.1563, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [05:05<12:30,  4.36s/it, loss=5.1567, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [05:08<11:17,  3.96s/it, loss=5.1563, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [05:13<11:42,  4.13s/it, loss=5.1562, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [05:16<10:53,  3.87s/it, loss=5.1569, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [05:23<13:25,  4.79s/it, loss=5.1560, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [05:26<12:04,  4.34s/it, loss=5.1548, tokens/sMax input_id: 31794\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [05:33<14:09,  5.12s/it, loss=5.1539, tokens/sMax input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [05:36<12:09,  4.42s/it, loss=5.1524, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [05:40<11:29,  4.20s/it, loss=5.1482, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [05:42<09:36,  3.54s/it, loss=5.1472, tokens/sMax input_id: 31782\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [05:45<09:03,  3.35s/it, loss=5.1454, tokens/sMax input_id: 31789\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [05:52<12:13,  4.56s/it, loss=5.1470, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [05:54<10:21,  3.89s/it, loss=5.1459, tokens/sMax input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [05:58<09:50,  3.72s/it, loss=5.1444, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [06:00<09:03,  3.44s/it, loss=5.1438, tokens/sMax input_id: 31782\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [06:05<10:10,  3.89s/it, loss=5.1445, tokens/sMax input_id: 31761\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [06:07<08:28,  3.26s/it, loss=5.1410, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [06:11<08:56,  3.46s/it, loss=5.1432, tokens/sMax input_id: 31772\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [06:13<07:51,  3.06s/it, loss=5.1392, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [06:16<07:16,  2.85s/it, loss=5.1375, tokens/sMax input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [06:22<10:07,  3.99s/it, loss=5.1393, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [06:25<09:02,  3.59s/it, loss=5.1342, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [06:32<11:44,  4.70s/it, loss=5.1365, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [06:34<09:37,  3.88s/it, loss=5.1361, tokens/Max input_id: 31771\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [06:37<08:25,  3.41s/it, loss=5.1336, tokens/Max input_id: 31771\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [06:39<07:51,  3.21s/it, loss=5.1311, tokens/Max input_id: 31794\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [06:42<07:34,  3.11s/it, loss=5.1316, tokens/Max input_id: 31738\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [06:44<06:51,  2.84s/it, loss=5.1304, tokens/Max input_id: 31766\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [06:50<08:52,  3.70s/it, loss=5.1292, tokens/Max input_id: 31771\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [06:53<08:32,  3.58s/it, loss=5.1278, tokens/Max input_id: 31767\n",
      "Max target_input: 31825\n",
      "Max label: 31825\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [06:56<07:44,  3.27s/it, loss=5.1271, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [06:58<07:02,  3.00s/it, loss=5.1270, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [07:03<08:21,  3.58s/it, loss=5.1250, tokens/Max input_id: 31771\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [07:07<08:20,  3.60s/it, loss=5.1256, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [07:11<08:19,  3.62s/it, loss=5.1238, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [07:18<10:43,  4.70s/it, loss=5.1236, tokens/Max input_id: 31803\n",
      "Max target_input: 31803\n",
      "Max label: 31803\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [07:20<09:12,  4.06s/it, loss=5.1228, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [07:23<08:01,  3.57s/it, loss=5.1215, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [07:26<07:49,  3.51s/it, loss=5.1202, tokens/Max input_id: 31779\n",
      "Max target_input: 31779\n",
      "Max label: 31779\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [07:33<09:51,  4.44s/it, loss=5.1205, tokens/Max input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [07:39<11:08,  5.07s/it, loss=5.1202, tokens/Max input_id: 31764\n",
      "Max target_input: 31828\n",
      "Max label: 31828\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [07:44<11:09,  5.11s/it, loss=5.1208, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [07:47<09:06,  4.21s/it, loss=5.1194, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [07:49<08:02,  3.74s/it, loss=5.1193, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [07:52<07:27,  3.50s/it, loss=5.1203, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [07:55<07:06,  3.36s/it, loss=5.1195, tokens/Max input_id: 31782\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [07:57<06:14,  2.97s/it, loss=5.1169, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [08:00<06:12,  2.98s/it, loss=5.1155, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [08:03<06:09,  2.98s/it, loss=5.1144, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [08:06<06:00,  2.93s/it, loss=5.1122, tokens/Max input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [08:09<06:13,  3.06s/it, loss=5.1105, tokens/Max input_id: 31771\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [08:11<05:34,  2.76s/it, loss=5.1084, tokens/Max input_id: 31771\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [08:14<05:21,  2.68s/it, loss=5.1074, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [08:17<05:23,  2.72s/it, loss=5.1089, tokens/Max input_id: 31768\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [08:19<05:07,  2.60s/it, loss=5.1076, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [08:21<04:40,  2.39s/it, loss=5.1061, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [08:26<06:24,  3.32s/it, loss=5.1045, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [08:33<07:58,  4.17s/it, loss=5.1028, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [08:37<08:03,  4.24s/it, loss=5.1023, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [08:39<06:50,  3.63s/it, loss=5.1008, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [08:42<06:20,  3.39s/it, loss=5.0995, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [08:44<05:41,  3.07s/it, loss=5.0985, tokens/Max input_id: 31767\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [08:47<05:19,  2.90s/it, loss=5.0986, tokens/Max input_id: 31772\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [08:51<06:08,  3.38s/it, loss=5.0967, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [08:54<05:23,  2.99s/it, loss=5.0965, tokens/Max input_id: 31794\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [08:59<06:49,  3.83s/it, loss=5.0951, tokens/Max input_id: 31815\n",
      "Max target_input: 31815\n",
      "Max label: 31815\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [09:03<06:38,  3.76s/it, loss=5.0925, tokens/Max input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [09:08<07:32,  4.31s/it, loss=5.0924, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [09:11<06:32,  3.78s/it, loss=5.0916, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [09:13<05:31,  3.22s/it, loss=5.0895, tokens/Max input_id: 31768\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [09:15<05:03,  2.97s/it, loss=5.0904, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [09:19<05:28,  3.25s/it, loss=5.0898, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [09:25<06:43,  4.03s/it, loss=5.0893, tokens/Max input_id: 31794\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [09:30<07:00,  4.25s/it, loss=5.0897, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [09:35<07:38,  4.67s/it, loss=5.0891, tokens/Max input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [09:39<06:50,  4.23s/it, loss=5.0884, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [09:44<07:23,  4.62s/it, loss=5.0866, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [09:46<06:02,  3.81s/it, loss=5.0859, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [09:50<06:04,  3.87s/it, loss=5.0859, tokens/Max input_id: 31779\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [09:54<05:56,  3.83s/it, loss=5.0856, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [10:00<06:45,  4.41s/it, loss=5.0872, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [10:04<06:40,  4.40s/it, loss=5.0867, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [10:07<06:10,  4.12s/it, loss=5.0860, tokens/Max input_id: 31794\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [10:14<07:21,  4.96s/it, loss=5.0852, tokens/Max input_id: 31765\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [10:18<06:51,  4.68s/it, loss=5.0856, tokens/Max input_id: 31767\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [10:21<05:39,  3.90s/it, loss=5.0840, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [10:25<05:51,  4.09s/it, loss=5.0825, tokens/Max input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [10:30<06:08,  4.34s/it, loss=5.0815, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [10:35<06:19,  4.52s/it, loss=5.0813, tokens/Max input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [10:39<06:01,  4.36s/it, loss=5.0797, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [10:44<06:11,  4.54s/it, loss=5.0801, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [10:46<04:59,  3.70s/it, loss=5.0785, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [10:49<05:00,  3.76s/it, loss=5.0776, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [10:58<07:00,  5.32s/it, loss=5.0755, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [11:00<05:36,  4.32s/it, loss=5.0744, tokens/Max input_id: 31789\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [11:05<05:28,  4.27s/it, loss=5.0755, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [11:07<04:36,  3.64s/it, loss=5.0748, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [11:09<03:54,  3.13s/it, loss=5.0745, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [11:12<04:00,  3.25s/it, loss=5.0737, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [11:15<03:38,  2.99s/it, loss=5.0740, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [11:17<03:18,  2.76s/it, loss=5.0726, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [11:20<03:33,  3.00s/it, loss=5.0730, tokens/Max input_id: 31772\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [11:24<03:51,  3.30s/it, loss=5.0727, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [11:27<03:24,  2.96s/it, loss=5.0711, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [11:34<04:44,  4.18s/it, loss=5.0690, tokens/Max input_id: 31771\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [11:36<04:06,  3.68s/it, loss=5.0682, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [11:38<03:36,  3.27s/it, loss=5.0667, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [11:41<03:15,  3.01s/it, loss=5.0664, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [11:47<04:10,  3.92s/it, loss=5.0652, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [11:49<03:27,  3.30s/it, loss=5.0642, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [11:52<03:31,  3.40s/it, loss=5.0630, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [11:57<03:49,  3.76s/it, loss=5.0619, tokens/Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [12:04<04:41,  4.70s/it, loss=5.0610, tokens/Max input_id: 31800\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [12:07<04:10,  4.24s/it, loss=5.0613, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [12:10<03:39,  3.79s/it, loss=5.0599, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [12:13<03:18,  3.49s/it, loss=5.0603, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [12:18<03:53,  4.17s/it, loss=5.0598, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [12:21<03:17,  3.59s/it, loss=5.0592, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [12:24<03:10,  3.52s/it, loss=5.0579, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [12:26<02:50,  3.22s/it, loss=5.0565, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [12:30<02:57,  3.41s/it, loss=5.0546, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [12:34<02:52,  3.38s/it, loss=5.0537, tokens/Max input_id: 31794\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [12:39<03:19,  3.99s/it, loss=5.0528, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [12:45<03:42,  4.55s/it, loss=5.0531, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [12:53<04:33,  5.70s/it, loss=5.0535, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [12:56<03:50,  4.90s/it, loss=5.0526, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [12:59<03:15,  4.24s/it, loss=5.0519, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [13:03<03:02,  4.05s/it, loss=5.0528, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [13:06<02:45,  3.76s/it, loss=5.0527, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [13:09<02:38,  3.68s/it, loss=5.0524, tokens/Max input_id: 31771\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [13:12<02:18,  3.31s/it, loss=5.0520, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [13:14<02:05,  3.06s/it, loss=5.0510, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [13:20<02:40,  4.01s/it, loss=5.0502, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [13:25<02:42,  4.16s/it, loss=5.0482, tokens/Max input_id: 31790\n",
      "Max target_input: 31790\n",
      "Max label: 31790\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [13:30<02:46,  4.37s/it, loss=5.0473, tokens/Max input_id: 31794\n",
      "Max target_input: 31757\n",
      "Max label: 31757\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [13:32<02:18,  3.73s/it, loss=5.0464, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [13:34<02:01,  3.36s/it, loss=5.0459, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [13:36<01:43,  2.96s/it, loss=5.0439, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [13:39<01:34,  2.79s/it, loss=5.0438, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [13:44<02:00,  3.64s/it, loss=5.0427, tokens/Max input_id: 31771\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [13:48<01:53,  3.54s/it, loss=5.0417, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [13:51<01:44,  3.37s/it, loss=5.0407, tokens/Max input_id: 31762\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [13:53<01:34,  3.14s/it, loss=5.0406, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [13:57<01:35,  3.29s/it, loss=5.0394, tokens/Max input_id: 31794\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [14:00<01:26,  3.10s/it, loss=5.0375, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [14:03<01:21,  3.04s/it, loss=5.0368, tokens/Max input_id: 31772\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [14:06<01:24,  3.26s/it, loss=5.0371, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [14:10<01:26,  3.48s/it, loss=5.0357, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [14:13<01:14,  3.12s/it, loss=5.0329, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [14:14<01:02,  2.71s/it, loss=5.0313, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [14:16<00:54,  2.47s/it, loss=5.0297, tokens/Max input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [14:20<01:01,  2.94s/it, loss=5.0291, tokens/Max input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [14:22<00:54,  2.70s/it, loss=5.0276, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [14:27<01:03,  3.36s/it, loss=5.0264, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [14:33<01:11,  4.00s/it, loss=5.0247, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [14:36<01:03,  3.71s/it, loss=5.0231, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [14:44<01:18,  4.94s/it, loss=5.0223, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [14:46<01:03,  4.25s/it, loss=5.0226, tokens/Max input_id: 31797\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [14:54<01:12,  5.17s/it, loss=5.0230, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [14:56<00:57,  4.45s/it, loss=5.0218, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [15:01<00:54,  4.50s/it, loss=5.0211, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [15:05<00:48,  4.41s/it, loss=5.0203, tokens/Max input_id: 31801\n",
      "Max target_input: 31801\n",
      "Max label: 31801\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [15:09<00:42,  4.24s/it, loss=5.0198, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [15:12<00:33,  3.77s/it, loss=5.0192, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [15:16<00:32,  4.05s/it, loss=5.0190, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [15:19<00:25,  3.58s/it, loss=5.0174, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [15:22<00:20,  3.35s/it, loss=5.0170, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [15:24<00:15,  3.07s/it, loss=5.0156, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [15:27<00:12,  3.01s/it, loss=5.0139, tokens/Max input_id: 31782\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Training:  99%|█████████▉| 247/250 [15:30<00:09,  3.07s/it, loss=5.0146, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Training:  99%|█████████▉| 248/250 [15:34<00:06,  3.22s/it, loss=5.0147, tokens/Max input_id: 31800\n",
      "Max target_input: 31800\n",
      "Max label: 31800\n",
      "Training: 100%|█████████▉| 249/250 [15:37<00:03,  3.07s/it, loss=5.0152, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Training: 100%|██████████| 250/250 [15:53<00:00,  3.82s/it, loss=5.0154, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:07<03:51,  7.47s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:08<01:56,  3.89s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:11<01:31,  3.16s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:12<01:03,  2.26s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:13<00:50,  1.85s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:14<00:41,  1.58s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:15<00:34,  1.37s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:16<00:30,  1.25s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:17<00:29,  1.30s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:18<00:26,  1.19s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:19<00:24,  1.18s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:20<00:20,  1.04s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:21<00:20,  1.09s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:22<00:18,  1.00s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:23<00:16,  1.03it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:24<00:14,  1.09it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:25<00:14,  1.03it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:26<00:16,  1.19s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:27<00:14,  1.13s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:28<00:13,  1.10s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:29<00:10,  1.03it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:30<00:09,  1.02it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:31<00:09,  1.04s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:32<00:08,  1.10s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:33<00:07,  1.06s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:35<00:06,  1.16s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:36<00:05,  1.09s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:49<00:00,  1.55s/it]\n",
      "Removed old checkpoint: model_epoch_2.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_2.pt\n",
      "Saved training results to training_results_20250511_213031.csv\n",
      "Train Loss: 5.0154\n",
      "Val Loss: 4.9357\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: , the Commission' s report.\n",
      "\n",
      "Epoch 3/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:10<41:55, 10.10s/it, loss=4.5853, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:14<27:00,  6.54s/it, loss=4.7859, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:17<20:53,  5.07s/it, loss=4.8265, tokens/s=Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:23<22:42,  5.54s/it, loss=4.7724, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:25<17:19,  4.24s/it, loss=4.7753, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:28<15:45,  3.88s/it, loss=4.7598, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:30<13:24,  3.31s/it, loss=4.7448, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:33<12:22,  3.07s/it, loss=4.7418, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:39<15:44,  3.92s/it, loss=4.7395, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:41<13:58,  3.49s/it, loss=4.7410, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:48<17:08,  4.31s/it, loss=4.7435, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:53<17:57,  4.53s/it, loss=4.7635, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:55<15:53,  4.02s/it, loss=4.7685, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:57<13:29,  3.43s/it, loss=4.7677, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [00:59<11:45,  3.00s/it, loss=4.7603, tokens/sMax input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [01:01<10:17,  2.64s/it, loss=4.7508, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [01:04<10:44,  2.77s/it, loss=4.7588, tokens/sMax input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:06<09:55,  2.57s/it, loss=4.7535, tokens/sMax input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:13<14:00,  3.64s/it, loss=4.7508, tokens/sMax input_id: 31773\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:20<17:55,  4.67s/it, loss=4.7504, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:22<15:07,  3.96s/it, loss=4.7409, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:25<14:04,  3.70s/it, loss=4.7523, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:27<12:20,  3.26s/it, loss=4.7439, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:30<12:06,  3.21s/it, loss=4.7468, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:35<13:15,  3.54s/it, loss=4.7502, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:43<18:43,  5.01s/it, loss=4.7526, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:46<16:15,  4.38s/it, loss=4.7541, tokens/sMax input_id: 31771\n",
      "Max target_input: 31806\n",
      "Max label: 31806\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [01:53<18:36,  5.03s/it, loss=4.7621, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [01:56<16:34,  4.50s/it, loss=4.7620, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [01:58<14:06,  3.85s/it, loss=4.7582, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [02:01<13:18,  3.65s/it, loss=4.7626, tokens/sMax input_id: 31764\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [02:09<17:15,  4.75s/it, loss=4.7626, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [02:13<16:33,  4.58s/it, loss=4.7649, tokens/sMax input_id: 31767\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:17<15:48,  4.39s/it, loss=4.7687, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:22<16:06,  4.49s/it, loss=4.7740, tokens/sMax input_id: 31766\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:24<13:51,  3.88s/it, loss=4.7736, tokens/sMax input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:27<12:49,  3.61s/it, loss=4.7722, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:29<11:07,  3.15s/it, loss=4.7680, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:34<12:51,  3.66s/it, loss=4.7658, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:38<12:56,  3.70s/it, loss=4.7627, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:42<13:54,  3.99s/it, loss=4.7601, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:46<12:57,  3.74s/it, loss=4.7591, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:50<13:20,  3.87s/it, loss=4.7621, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:52<11:55,  3.47s/it, loss=4.7587, tokens/sMax input_id: 31770\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [02:55<11:27,  3.35s/it, loss=4.7584, tokens/sMax input_id: 31769\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [02:58<10:24,  3.06s/it, loss=4.7607, tokens/sMax input_id: 31767\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [03:01<10:58,  3.24s/it, loss=4.7598, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [03:08<14:16,  4.24s/it, loss=4.7559, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [03:12<13:49,  4.12s/it, loss=4.7560, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [03:16<13:24,  4.02s/it, loss=4.7597, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [03:22<15:22,  4.64s/it, loss=4.7631, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:24<13:27,  4.08s/it, loss=4.7621, tokens/sMax input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:28<12:52,  3.92s/it, loss=4.7599, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:36<16:45,  5.13s/it, loss=4.7642, tokens/sMax input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:39<14:50,  4.57s/it, loss=4.7664, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:42<13:28,  4.17s/it, loss=4.7633, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:45<11:37,  3.61s/it, loss=4.7606, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:51<13:39,  4.27s/it, loss=4.7617, tokens/sMax input_id: 31764\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:53<11:34,  3.63s/it, loss=4.7609, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [03:56<11:38,  3.68s/it, loss=4.7600, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [04:03<13:49,  4.39s/it, loss=4.7577, tokens/sMax input_id: 31770\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [04:05<12:21,  3.95s/it, loss=4.7539, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [04:08<10:58,  3.52s/it, loss=4.7499, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [04:14<13:25,  4.33s/it, loss=4.7499, tokens/sMax input_id: 31767\n",
      "Max target_input: 31766\n",
      "Max label: 31766\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [04:17<11:53,  3.86s/it, loss=4.7473, tokens/sMax input_id: 31781\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [04:20<11:21,  3.70s/it, loss=4.7463, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [04:22<09:54,  3.25s/it, loss=4.7436, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [04:26<10:06,  3.33s/it, loss=4.7413, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [04:29<10:04,  3.34s/it, loss=4.7408, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [04:32<09:06,  3.04s/it, loss=4.7412, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:36<10:07,  3.39s/it, loss=4.7398, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:38<09:15,  3.12s/it, loss=4.7390, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:41<08:19,  2.82s/it, loss=4.7365, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:43<07:58,  2.72s/it, loss=4.7377, tokens/sMax input_id: 31767\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [04:46<08:12,  2.81s/it, loss=4.7362, tokens/sMax input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [04:50<09:16,  3.20s/it, loss=4.7356, tokens/sMax input_id: 31867\n",
      "Max target_input: 31867\n",
      "Max label: 31867\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [04:53<09:11,  3.19s/it, loss=4.7360, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [04:58<10:16,  3.58s/it, loss=4.7365, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [05:00<09:18,  3.27s/it, loss=4.7367, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [05:03<09:03,  3.20s/it, loss=4.7371, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [05:06<08:07,  2.88s/it, loss=4.7378, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [05:10<09:09,  3.27s/it, loss=4.7369, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [05:15<10:33,  3.79s/it, loss=4.7361, tokens/sMax input_id: 31794\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [05:22<13:10,  4.76s/it, loss=4.7352, tokens/sMax input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [05:24<11:24,  4.15s/it, loss=4.7343, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [05:27<09:56,  3.64s/it, loss=4.7301, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [05:29<08:29,  3.12s/it, loss=4.7290, tokens/sMax input_id: 31782\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [05:31<07:54,  2.93s/it, loss=4.7270, tokens/sMax input_id: 31789\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [05:40<12:31,  4.67s/it, loss=4.7293, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [05:42<10:22,  3.89s/it, loss=4.7281, tokens/sMax input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [05:46<10:36,  4.00s/it, loss=4.7269, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [05:49<09:45,  3.71s/it, loss=4.7255, tokens/sMax input_id: 31782\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [05:53<09:15,  3.54s/it, loss=4.7265, tokens/sMax input_id: 31761\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [05:54<07:42,  2.96s/it, loss=4.7225, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [05:57<07:32,  2.92s/it, loss=4.7248, tokens/sMax input_id: 31772\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [06:00<07:30,  2.93s/it, loss=4.7211, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [06:03<07:16,  2.85s/it, loss=4.7200, tokens/sMax input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [06:08<08:53,  3.51s/it, loss=4.7223, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [06:10<07:58,  3.17s/it, loss=4.7177, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [06:17<10:51,  4.34s/it, loss=4.7204, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [06:19<09:03,  3.65s/it, loss=4.7203, tokens/Max input_id: 31771\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [06:21<08:04,  3.27s/it, loss=4.7179, tokens/Max input_id: 31771\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [06:28<10:05,  4.12s/it, loss=4.7158, tokens/Max input_id: 31794\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [06:32<10:01,  4.12s/it, loss=4.7164, tokens/Max input_id: 31738\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [06:34<08:36,  3.56s/it, loss=4.7157, tokens/Max input_id: 31766\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [06:39<09:41,  4.04s/it, loss=4.7149, tokens/Max input_id: 31771\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [06:42<09:02,  3.80s/it, loss=4.7131, tokens/Max input_id: 31767\n",
      "Max target_input: 31825\n",
      "Max label: 31825\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [06:45<08:05,  3.42s/it, loss=4.7128, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [06:48<08:04,  3.43s/it, loss=4.7132, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [06:54<09:48,  4.21s/it, loss=4.7110, tokens/Max input_id: 31771\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [06:59<10:05,  4.35s/it, loss=4.7116, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [07:02<08:55,  3.88s/it, loss=4.7101, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [07:09<11:17,  4.95s/it, loss=4.7103, tokens/Max input_id: 31803\n",
      "Max target_input: 31803\n",
      "Max label: 31803\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [07:12<09:32,  4.21s/it, loss=4.7097, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [07:14<08:15,  3.67s/it, loss=4.7087, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [07:20<09:39,  4.33s/it, loss=4.7073, tokens/Max input_id: 31779\n",
      "Max target_input: 31779\n",
      "Max label: 31779\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [07:26<10:54,  4.92s/it, loss=4.7076, tokens/Max input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [07:33<12:08,  5.52s/it, loss=4.7078, tokens/Max input_id: 31764\n",
      "Max target_input: 31828\n",
      "Max label: 31828\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [07:36<10:33,  4.83s/it, loss=4.7090, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [07:39<08:42,  4.02s/it, loss=4.7080, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [07:41<07:41,  3.58s/it, loss=4.7084, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [07:44<07:10,  3.36s/it, loss=4.7098, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [07:48<07:25,  3.51s/it, loss=4.7091, tokens/Max input_id: 31782\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [07:50<06:26,  3.07s/it, loss=4.7065, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [07:54<07:17,  3.50s/it, loss=4.7056, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [07:59<08:06,  3.92s/it, loss=4.7049, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [08:01<06:55,  3.38s/it, loss=4.7031, tokens/Max input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [08:06<07:38,  3.76s/it, loss=4.7019, tokens/Max input_id: 31771\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [08:09<06:56,  3.44s/it, loss=4.7003, tokens/Max input_id: 31771\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [08:13<07:23,  3.70s/it, loss=4.6997, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [08:17<07:29,  3.78s/it, loss=4.7012, tokens/Max input_id: 31768\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [08:19<06:35,  3.36s/it, loss=4.6997, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [08:21<05:41,  2.92s/it, loss=4.6987, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [08:27<07:29,  3.88s/it, loss=4.6975, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [08:33<08:27,  4.42s/it, loss=4.6963, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [08:37<08:03,  4.24s/it, loss=4.6962, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [08:40<07:35,  4.03s/it, loss=4.6951, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [08:44<07:15,  3.89s/it, loss=4.6939, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [08:46<06:12,  3.36s/it, loss=4.6933, tokens/Max input_id: 31767\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [08:48<05:32,  3.02s/it, loss=4.6935, tokens/Max input_id: 31772\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [08:51<05:32,  3.05s/it, loss=4.6917, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [08:54<05:01,  2.79s/it, loss=4.6917, tokens/Max input_id: 31794\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [08:57<05:08,  2.88s/it, loss=4.6907, tokens/Max input_id: 31815\n",
      "Max target_input: 31815\n",
      "Max label: 31815\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [09:00<05:27,  3.09s/it, loss=4.6889, tokens/Max input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [09:06<06:43,  3.85s/it, loss=4.6888, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [09:08<05:57,  3.44s/it, loss=4.6882, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [09:10<05:08,  3.00s/it, loss=4.6863, tokens/Max input_id: 31768\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [09:13<04:45,  2.80s/it, loss=4.6875, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [09:16<04:49,  2.86s/it, loss=4.6871, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [09:19<05:04,  3.04s/it, loss=4.6868, tokens/Max input_id: 31794\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [09:22<04:55,  2.98s/it, loss=4.6875, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [09:28<06:31,  3.99s/it, loss=4.6872, tokens/Max input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [09:31<05:52,  3.63s/it, loss=4.6867, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [09:35<06:05,  3.81s/it, loss=4.6852, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [09:37<05:10,  3.26s/it, loss=4.6845, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [09:40<04:58,  3.17s/it, loss=4.6849, tokens/Max input_id: 31779\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [09:43<04:46,  3.08s/it, loss=4.6845, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [09:46<04:35,  3.00s/it, loss=4.6862, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [09:50<05:10,  3.41s/it, loss=4.6864, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [09:54<04:59,  3.32s/it, loss=4.6861, tokens/Max input_id: 31794\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [09:59<05:57,  4.01s/it, loss=4.6857, tokens/Max input_id: 31765\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [10:02<05:24,  3.68s/it, loss=4.6865, tokens/Max input_id: 31767\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [10:04<04:32,  3.13s/it, loss=4.6852, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [10:06<04:08,  2.89s/it, loss=4.6839, tokens/Max input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [10:10<04:27,  3.15s/it, loss=4.6833, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [10:16<05:29,  3.92s/it, loss=4.6833, tokens/Max input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [10:19<05:06,  3.69s/it, loss=4.6821, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [10:22<04:51,  3.55s/it, loss=4.6827, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [10:24<04:04,  3.01s/it, loss=4.6817, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [10:27<03:54,  2.94s/it, loss=4.6810, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [10:33<05:23,  4.10s/it, loss=4.6791, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [10:36<04:33,  3.51s/it, loss=4.6785, tokens/Max input_id: 31789\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [10:39<04:23,  3.42s/it, loss=4.6794, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [10:42<04:15,  3.36s/it, loss=4.6790, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [10:44<03:40,  2.94s/it, loss=4.6792, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [10:48<04:04,  3.30s/it, loss=4.6787, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [10:51<03:41,  3.03s/it, loss=4.6793, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [10:53<03:20,  2.79s/it, loss=4.6784, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [10:55<03:15,  2.75s/it, loss=4.6790, tokens/Max input_id: 31772\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [10:58<03:07,  2.67s/it, loss=4.6789, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [11:01<03:08,  2.73s/it, loss=4.6776, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [11:07<04:22,  3.87s/it, loss=4.6757, tokens/Max input_id: 31771\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [11:10<03:52,  3.46s/it, loss=4.6750, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [11:12<03:27,  3.14s/it, loss=4.6739, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [11:15<03:08,  2.91s/it, loss=4.6740, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [11:18<03:09,  2.96s/it, loss=4.6732, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [11:19<02:43,  2.60s/it, loss=4.6721, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [11:23<02:57,  2.86s/it, loss=4.6712, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [11:26<03:05,  3.04s/it, loss=4.6704, tokens/Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [11:33<04:15,  4.25s/it, loss=4.6695, tokens/Max input_id: 31800\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [11:36<03:49,  3.89s/it, loss=4.6697, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [11:39<03:27,  3.57s/it, loss=4.6681, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [11:42<03:11,  3.36s/it, loss=4.6687, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [11:46<03:10,  3.40s/it, loss=4.6684, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [11:49<03:03,  3.33s/it, loss=4.6680, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [11:52<02:51,  3.17s/it, loss=4.6672, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [11:54<02:35,  2.94s/it, loss=4.6660, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [11:58<02:50,  3.27s/it, loss=4.6644, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [12:01<02:46,  3.26s/it, loss=4.6639, tokens/Max input_id: 31794\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [12:06<02:58,  3.56s/it, loss=4.6630, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [12:12<03:29,  4.28s/it, loss=4.6634, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [12:19<04:17,  5.36s/it, loss=4.6639, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [12:22<03:37,  4.62s/it, loss=4.6633, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [12:25<03:06,  4.06s/it, loss=4.6628, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [12:28<02:52,  3.82s/it, loss=4.6642, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [12:31<02:37,  3.57s/it, loss=4.6642, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [12:35<02:29,  3.47s/it, loss=4.6644, tokens/Max input_id: 31771\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [12:37<02:12,  3.14s/it, loss=4.6645, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [12:40<02:13,  3.25s/it, loss=4.6638, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [12:46<02:32,  3.81s/it, loss=4.6633, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [12:49<02:25,  3.74s/it, loss=4.6618, tokens/Max input_id: 31790\n",
      "Max target_input: 31790\n",
      "Max label: 31790\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [12:53<02:24,  3.82s/it, loss=4.6611, tokens/Max input_id: 31794\n",
      "Max target_input: 31757\n",
      "Max label: 31757\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [12:55<02:03,  3.34s/it, loss=4.6605, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [12:58<01:50,  3.07s/it, loss=4.6607, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [13:00<01:36,  2.76s/it, loss=4.6590, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [13:03<01:40,  2.97s/it, loss=4.6593, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [13:08<01:58,  3.60s/it, loss=4.6585, tokens/Max input_id: 31771\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [13:11<01:49,  3.43s/it, loss=4.6577, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [13:14<01:41,  3.29s/it, loss=4.6569, tokens/Max input_id: 31762\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [13:17<01:32,  3.08s/it, loss=4.6571, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [13:20<01:30,  3.10s/it, loss=4.6562, tokens/Max input_id: 31794\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [13:23<01:23,  2.99s/it, loss=4.6546, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [13:27<01:27,  3.23s/it, loss=4.6543, tokens/Max input_id: 31772\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [13:32<01:40,  3.86s/it, loss=4.6549, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [13:34<01:25,  3.42s/it, loss=4.6539, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [13:37<01:13,  3.08s/it, loss=4.6513, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [13:38<01:01,  2.69s/it, loss=4.6498, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [13:40<00:54,  2.47s/it, loss=4.6486, tokens/Max input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [13:43<00:55,  2.65s/it, loss=4.6482, tokens/Max input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [13:45<00:48,  2.40s/it, loss=4.6468, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [13:51<01:06,  3.52s/it, loss=4.6458, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [13:57<01:14,  4.13s/it, loss=4.6444, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [13:59<00:59,  3.53s/it, loss=4.6431, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [14:06<01:11,  4.45s/it, loss=4.6425, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [14:08<00:58,  3.89s/it, loss=4.6430, tokens/Max input_id: 31797\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [14:14<01:04,  4.58s/it, loss=4.6438, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [14:17<00:51,  4.00s/it, loss=4.6429, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [14:22<00:52,  4.38s/it, loss=4.6424, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [14:26<00:46,  4.25s/it, loss=4.6422, tokens/Max input_id: 31801\n",
      "Max target_input: 31801\n",
      "Max label: 31801\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [14:29<00:38,  3.85s/it, loss=4.6418, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [14:32<00:30,  3.40s/it, loss=4.6415, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [14:35<00:26,  3.28s/it, loss=4.6416, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [14:37<00:21,  3.03s/it, loss=4.6404, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [14:40<00:17,  2.95s/it, loss=4.6399, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [14:43<00:15,  3.05s/it, loss=4.6387, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [14:47<00:12,  3.22s/it, loss=4.6372, tokens/Max input_id: 31782\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Training:  99%|█████████▉| 247/250 [14:51<00:10,  3.65s/it, loss=4.6380, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Training:  99%|█████████▉| 248/250 [14:54<00:06,  3.33s/it, loss=4.6384, tokens/Max input_id: 31800\n",
      "Max target_input: 31800\n",
      "Max label: 31800\n",
      "Training: 100%|█████████▉| 249/250 [14:56<00:03,  3.05s/it, loss=4.6392, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Training: 100%|██████████| 250/250 [15:13<00:00,  3.65s/it, loss=4.6397, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:08<04:09,  8.06s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:09<02:03,  4.12s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:10<01:22,  2.86s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:11<00:57,  2.06s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:12<00:46,  1.73s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:13<00:39,  1.52s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:14<00:33,  1.33s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:15<00:28,  1.20s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:17<00:28,  1.25s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:17<00:24,  1.10s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:19<00:23,  1.11s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:20<00:24,  1.22s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:21<00:23,  1.21s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:22<00:19,  1.07s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:23<00:17,  1.01s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:24<00:15,  1.05it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:25<00:15,  1.04s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:26<00:14,  1.00s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:27<00:13,  1.06s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:28<00:12,  1.05s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:29<00:10,  1.05it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:30<00:09,  1.02it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:32<00:11,  1.32s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:33<00:10,  1.29s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:34<00:08,  1.17s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:35<00:07,  1.27s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:36<00:05,  1.17s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:50<00:00,  1.57s/it]\n",
      "Removed old checkpoint: model_epoch_3.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_3.pt\n",
      "Saved training results to training_results_20250511_214637.csv\n",
      "Train Loss: 4.6397\n",
      "Val Loss: 4.7686\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: , the European Union.\n",
      "\n",
      "Epoch 4/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size:Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      " 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:10<43:39, 10.52s/it, loss=4.2938, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:14<27:55,  6.75s/it, loss=4.4946, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:16<19:01,  4.62s/it, loss=4.5455, tokens/s=Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:22<20:38,  5.03s/it, loss=4.4936, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:24<16:37,  4.07s/it, loss=4.4927, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:29<16:58,  4.18s/it, loss=4.4742, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:32<15:25,  3.81s/it, loss=4.4550, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:35<14:45,  3.66s/it, loss=4.4488, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:40<16:50,  4.19s/it, loss=4.4455, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:43<14:23,  3.60s/it, loss=4.4381, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:46<14:05,  3.54s/it, loss=4.4382, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:50<14:19,  3.61s/it, loss=4.4553, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:52<12:58,  3.28s/it, loss=4.4627, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:55<12:24,  3.15s/it, loss=4.4641, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [00:57<10:59,  2.81s/it, loss=4.4579, tokens/sMax input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [00:59<09:50,  2.52s/it, loss=4.4486, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [01:02<10:08,  2.61s/it, loss=4.4568, tokens/sMax input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:04<09:30,  2.46s/it, loss=4.4520, tokens/sMax input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:08<11:40,  3.03s/it, loss=4.4491, tokens/sMax input_id: 31773\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:15<15:24,  4.02s/it, loss=4.4490, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:18<14:36,  3.83s/it, loss=4.4395, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:23<15:31,  4.08s/it, loss=4.4499, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:25<13:29,  3.57s/it, loss=4.4433, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:28<12:57,  3.44s/it, loss=4.4445, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:33<14:43,  3.93s/it, loss=4.4482, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:40<17:56,  4.81s/it, loss=4.4523, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:43<15:29,  4.17s/it, loss=4.4548, tokens/sMax input_id: 31771\n",
      "Max target_input: 31806\n",
      "Max label: 31806\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [01:51<19:50,  5.36s/it, loss=4.4651, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [01:56<18:58,  5.15s/it, loss=4.4655, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [01:58<15:40,  4.28s/it, loss=4.4631, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [02:03<16:21,  4.48s/it, loss=4.4677, tokens/sMax input_id: 31764\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [02:10<19:33,  5.38s/it, loss=4.4661, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [02:14<17:12,  4.76s/it, loss=4.4681, tokens/sMax input_id: 31767\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:16<15:03,  4.18s/it, loss=4.4718, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:23<17:50,  4.98s/it, loss=4.4762, tokens/sMax input_id: 31766\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:26<15:12,  4.27s/it, loss=4.4764, tokens/sMax input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:29<13:43,  3.86s/it, loss=4.4755, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:31<11:49,  3.34s/it, loss=4.4719, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:35<11:58,  3.41s/it, loss=4.4693, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:37<11:11,  3.20s/it, loss=4.4652, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:40<10:38,  3.05s/it, loss=4.4615, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:44<11:17,  3.26s/it, loss=4.4617, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:48<12:06,  3.51s/it, loss=4.4646, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:50<10:55,  3.18s/it, loss=4.4613, tokens/sMax input_id: 31770\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [02:53<10:47,  3.16s/it, loss=4.4618, tokens/sMax input_id: 31769\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [02:56<09:55,  2.92s/it, loss=4.4634, tokens/sMax input_id: 31767\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [02:59<09:46,  2.89s/it, loss=4.4631, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [03:04<12:30,  3.71s/it, loss=4.4595, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [03:08<12:54,  3.85s/it, loss=4.4597, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [03:12<12:22,  3.71s/it, loss=4.4629, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [03:17<13:53,  4.19s/it, loss=4.4663, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:19<12:05,  3.66s/it, loss=4.4656, tokens/sMax input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:22<11:18,  3.45s/it, loss=4.4637, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:28<13:41,  4.19s/it, loss=4.4675, tokens/sMax input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:31<12:27,  3.84s/it, loss=4.4698, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:36<13:21,  4.13s/it, loss=4.4660, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:38<11:28,  3.57s/it, loss=4.4638, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:44<13:15,  4.14s/it, loss=4.4654, tokens/sMax input_id: 31764\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:46<11:16,  3.54s/it, loss=4.4647, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [03:49<10:50,  3.42s/it, loss=4.4637, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [03:52<10:28,  3.33s/it, loss=4.4614, tokens/sMax input_id: 31770\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [03:55<09:54,  3.16s/it, loss=4.4578, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [03:58<10:05,  3.24s/it, loss=4.4540, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [04:05<12:49,  4.14s/it, loss=4.4544, tokens/sMax input_id: 31767\n",
      "Max target_input: 31766\n",
      "Max label: 31766\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [04:07<11:25,  3.70s/it, loss=4.4510, tokens/sMax input_id: 31781\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [04:11<11:00,  3.59s/it, loss=4.4495, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [04:13<09:35,  3.14s/it, loss=4.4475, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [04:15<08:59,  2.96s/it, loss=4.4448, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [04:18<08:41,  2.88s/it, loss=4.4440, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [04:21<08:56,  2.98s/it, loss=4.4450, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:24<08:53,  2.98s/it, loss=4.4439, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:27<08:16,  2.79s/it, loss=4.4433, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:29<07:38,  2.59s/it, loss=4.4405, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:31<07:20,  2.51s/it, loss=4.4415, tokens/sMax input_id: 31767\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [04:33<06:52,  2.36s/it, loss=4.4401, tokens/sMax input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [04:36<07:27,  2.57s/it, loss=4.4395, tokens/sMax input_id: 31867\n",
      "Max target_input: 31867\n",
      "Max label: 31867\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [04:39<08:07,  2.82s/it, loss=4.4400, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [04:44<09:16,  3.24s/it, loss=4.4406, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [04:46<08:35,  3.02s/it, loss=4.4415, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [04:49<08:28,  2.99s/it, loss=4.4420, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [04:51<07:41,  2.73s/it, loss=4.4420, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [04:54<07:50,  2.80s/it, loss=4.4411, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [04:57<08:02,  2.89s/it, loss=4.4403, tokens/sMax input_id: 31794\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [05:05<11:47,  4.26s/it, loss=4.4389, tokens/sMax input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [05:08<10:29,  3.81s/it, loss=4.4381, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [05:10<09:23,  3.44s/it, loss=4.4338, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [05:12<08:06,  2.98s/it, loss=4.4324, tokens/sMax input_id: 31782\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [05:14<07:35,  2.81s/it, loss=4.4305, tokens/sMax input_id: 31789\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [05:21<10:43,  4.00s/it, loss=4.4329, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [05:23<09:08,  3.43s/it, loss=4.4324, tokens/sMax input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [05:29<10:48,  4.08s/it, loss=4.4318, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [05:32<10:18,  3.91s/it, loss=4.4301, tokens/sMax input_id: 31782\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [05:36<09:47,  3.74s/it, loss=4.4311, tokens/sMax input_id: 31761\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [05:37<08:05,  3.12s/it, loss=4.4269, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [05:40<07:48,  3.02s/it, loss=4.4293, tokens/sMax input_id: 31772\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [05:43<07:13,  2.82s/it, loss=4.4256, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [05:46<07:41,  3.02s/it, loss=4.4248, tokens/sMax input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [05:51<09:05,  3.59s/it, loss=4.4275, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [05:53<08:11,  3.25s/it, loss=4.4239, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [06:01<11:04,  4.43s/it, loss=4.4270, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [06:03<09:19,  3.76s/it, loss=4.4262, tokens/Max input_id: 31771\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [06:06<09:03,  3.67s/it, loss=4.4238, tokens/Max input_id: 31771\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [06:10<08:39,  3.53s/it, loss=4.4216, tokens/Max input_id: 31794\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [06:13<08:15,  3.40s/it, loss=4.4228, tokens/Max input_id: 31738\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [06:15<07:19,  3.03s/it, loss=4.4222, tokens/Max input_id: 31766\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [06:18<07:44,  3.22s/it, loss=4.4211, tokens/Max input_id: 31771\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [06:23<08:38,  3.62s/it, loss=4.4195, tokens/Max input_id: 31767\n",
      "Max target_input: 31825\n",
      "Max label: 31825\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [06:26<07:51,  3.32s/it, loss=4.4200, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [06:28<07:07,  3.03s/it, loss=4.4203, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [06:33<08:31,  3.65s/it, loss=4.4179, tokens/Max input_id: 31771\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [06:37<08:21,  3.61s/it, loss=4.4186, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [06:40<08:19,  3.62s/it, loss=4.4178, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [06:47<10:38,  4.66s/it, loss=4.4184, tokens/Max input_id: 31803\n",
      "Max target_input: 31803\n",
      "Max label: 31803\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [06:50<09:10,  4.04s/it, loss=4.4176, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [06:52<08:04,  3.59s/it, loss=4.4168, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [06:56<08:00,  3.58s/it, loss=4.4154, tokens/Max input_id: 31779\n",
      "Max target_input: 31779\n",
      "Max label: 31779\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [07:05<11:20,  5.12s/it, loss=4.4160, tokens/Max input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [07:13<13:09,  5.98s/it, loss=4.4168, tokens/Max input_id: 31764\n",
      "Max target_input: 31828\n",
      "Max label: 31828\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [07:16<11:15,  5.16s/it, loss=4.4185, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [07:18<09:11,  4.24s/it, loss=4.4179, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [07:21<08:06,  3.77s/it, loss=4.4187, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [07:24<08:02,  3.77s/it, loss=4.4201, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [07:29<08:16,  3.91s/it, loss=4.4198, tokens/Max input_id: 31782\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [07:31<07:04,  3.37s/it, loss=4.4175, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [07:35<07:31,  3.61s/it, loss=4.4170, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [07:38<07:16,  3.52s/it, loss=4.4164, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [07:40<06:13,  3.03s/it, loss=4.4149, tokens/Max input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [07:44<06:34,  3.23s/it, loss=4.4139, tokens/Max input_id: 31771\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [07:46<05:49,  2.89s/it, loss=4.4127, tokens/Max input_id: 31771\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [07:49<05:40,  2.84s/it, loss=4.4122, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [07:51<05:35,  2.82s/it, loss=4.4137, tokens/Max input_id: 31768\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [07:54<05:13,  2.66s/it, loss=4.4123, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [07:56<04:46,  2.45s/it, loss=4.4114, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [08:01<06:23,  3.31s/it, loss=4.4104, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [08:08<08:27,  4.41s/it, loss=4.4095, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [08:12<07:58,  4.20s/it, loss=4.4096, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [08:14<06:46,  3.60s/it, loss=4.4086, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [08:17<06:09,  3.30s/it, loss=4.4075, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [08:19<05:26,  2.95s/it, loss=4.4071, tokens/Max input_id: 31767\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [08:21<04:56,  2.70s/it, loss=4.4074, tokens/Max input_id: 31772\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [08:24<05:08,  2.83s/it, loss=4.4056, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [08:27<05:17,  2.94s/it, loss=4.4059, tokens/Max input_id: 31794\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [08:32<06:17,  3.53s/it, loss=4.4051, tokens/Max input_id: 31815\n",
      "Max target_input: 31815\n",
      "Max label: 31815\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [08:35<05:50,  3.30s/it, loss=4.4035, tokens/Max input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [08:40<06:38,  3.80s/it, loss=4.4035, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [08:42<05:53,  3.40s/it, loss=4.4028, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [08:44<05:04,  2.95s/it, loss=4.4011, tokens/Max input_id: 31768\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [08:47<05:12,  3.07s/it, loss=4.4023, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [08:52<05:50,  3.47s/it, loss=4.4021, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [08:57<06:25,  3.86s/it, loss=4.4021, tokens/Max input_id: 31794\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [09:00<05:52,  3.56s/it, loss=4.4028, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [09:04<06:29,  3.98s/it, loss=4.4024, tokens/Max input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [09:07<05:43,  3.55s/it, loss=4.4019, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [09:11<05:59,  3.75s/it, loss=4.4003, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [09:14<05:32,  3.50s/it, loss=4.3996, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [09:18<05:46,  3.68s/it, loss=4.4002, tokens/Max input_id: 31779\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [09:23<05:58,  3.86s/it, loss=4.3997, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [09:25<05:28,  3.57s/it, loss=4.4015, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [09:28<05:06,  3.37s/it, loss=4.4018, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [09:31<04:47,  3.19s/it, loss=4.4018, tokens/Max input_id: 31794\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [09:36<05:42,  3.85s/it, loss=4.4016, tokens/Max input_id: 31765\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [09:41<05:46,  3.94s/it, loss=4.4025, tokens/Max input_id: 31767\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [09:43<04:50,  3.34s/it, loss=4.4013, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [09:45<04:26,  3.10s/it, loss=4.4001, tokens/Max input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [09:50<05:05,  3.60s/it, loss=4.3997, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [09:54<05:03,  3.61s/it, loss=4.3998, tokens/Max input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [09:56<04:36,  3.33s/it, loss=4.3988, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [10:00<04:46,  3.49s/it, loss=4.3997, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [10:02<04:06,  3.04s/it, loss=4.3987, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [10:06<04:32,  3.40s/it, loss=4.3982, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [10:13<05:49,  4.42s/it, loss=4.3963, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [10:15<04:43,  3.64s/it, loss=4.3956, tokens/Max input_id: 31789\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [10:18<04:26,  3.47s/it, loss=4.3964, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [10:20<03:52,  3.06s/it, loss=4.3959, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [10:23<03:49,  3.06s/it, loss=4.3964, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [10:27<04:14,  3.44s/it, loss=4.3961, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [10:30<03:52,  3.18s/it, loss=4.3967, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [10:32<03:30,  2.92s/it, loss=4.3962, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [10:35<03:20,  2.83s/it, loss=4.3968, tokens/Max input_id: 31772\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [10:37<03:10,  2.72s/it, loss=4.3970, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [10:40<02:54,  2.53s/it, loss=4.3961, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [10:47<04:40,  4.12s/it, loss=4.3946, tokens/Max input_id: 31771\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [10:50<04:02,  3.62s/it, loss=4.3940, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [10:52<03:33,  3.23s/it, loss=4.3933, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [10:55<03:15,  3.01s/it, loss=4.3933, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [10:58<03:20,  3.13s/it, loss=4.3925, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [11:00<02:52,  2.73s/it, loss=4.3914, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [11:03<03:02,  2.94s/it, loss=4.3908, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [11:08<03:30,  3.45s/it, loss=4.3904, tokens/Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [11:15<04:40,  4.68s/it, loss=4.3896, tokens/Max input_id: 31800\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [11:19<04:16,  4.35s/it, loss=4.3897, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [11:22<03:42,  3.83s/it, loss=4.3880, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [11:24<03:21,  3.53s/it, loss=4.3886, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [11:28<03:19,  3.56s/it, loss=4.3885, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [11:31<03:08,  3.42s/it, loss=4.3882, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [11:35<03:13,  3.59s/it, loss=4.3876, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [11:38<02:53,  3.27s/it, loss=4.3865, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [11:41<02:55,  3.38s/it, loss=4.3849, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [11:44<02:46,  3.26s/it, loss=4.3846, tokens/Max input_id: 31794\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [11:50<03:14,  3.89s/it, loss=4.3835, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [11:58<04:21,  5.34s/it, loss=4.3841, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [12:07<04:58,  6.22s/it, loss=4.3848, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [12:10<04:17,  5.49s/it, loss=4.3844, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [12:14<03:42,  4.84s/it, loss=4.3840, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [12:19<03:38,  4.86s/it, loss=4.3855, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [12:23<03:30,  4.78s/it, loss=4.3856, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [12:30<03:48,  5.32s/it, loss=4.3858, tokens/Max input_id: 31771\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [12:32<03:06,  4.44s/it, loss=4.3860, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [12:35<02:37,  3.85s/it, loss=4.3856, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [12:38<02:30,  3.77s/it, loss=4.3854, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [12:41<02:19,  3.59s/it, loss=4.3840, tokens/Max input_id: 31790\n",
      "Max target_input: 31790\n",
      "Max label: 31790\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [12:45<02:15,  3.56s/it, loss=4.3835, tokens/Max input_id: 31794\n",
      "Max target_input: 31757\n",
      "Max label: 31757\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [12:47<01:57,  3.17s/it, loss=4.3833, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [12:51<01:57,  3.25s/it, loss=4.3835, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [12:53<01:40,  2.87s/it, loss=4.3819, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [12:55<01:32,  2.71s/it, loss=4.3821, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [12:59<01:42,  3.11s/it, loss=4.3815, tokens/Max input_id: 31771\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [13:02<01:39,  3.12s/it, loss=4.3807, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [13:05<01:35,  3.07s/it, loss=4.3800, tokens/Max input_id: 31762\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [13:09<01:35,  3.17s/it, loss=4.3801, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [13:12<01:31,  3.16s/it, loss=4.3794, tokens/Max input_id: 31794\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [13:14<01:23,  2.99s/it, loss=4.3780, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [13:17<01:18,  2.92s/it, loss=4.3780, tokens/Max input_id: 31772\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [13:20<01:18,  3.02s/it, loss=4.3788, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [13:23<01:11,  2.85s/it, loss=4.3779, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [13:25<01:03,  2.64s/it, loss=4.3753, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [13:28<01:00,  2.64s/it, loss=4.3738, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [13:29<00:53,  2.43s/it, loss=4.3726, tokens/Max input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [13:33<00:56,  2.69s/it, loss=4.3722, tokens/Max input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [13:35<00:48,  2.44s/it, loss=4.3709, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [13:39<00:56,  2.97s/it, loss=4.3698, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [13:43<01:00,  3.34s/it, loss=4.3686, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [13:46<00:55,  3.27s/it, loss=4.3674, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [13:53<01:10,  4.39s/it, loss=4.3669, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [13:56<00:57,  3.82s/it, loss=4.3674, tokens/Max input_id: 31797\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [14:00<00:57,  4.12s/it, loss=4.3683, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [14:03<00:47,  3.66s/it, loss=4.3676, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [14:06<00:42,  3.53s/it, loss=4.3675, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [14:11<00:42,  3.85s/it, loss=4.3674, tokens/Max input_id: 31801\n",
      "Max target_input: 31801\n",
      "Max label: 31801\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [14:14<00:35,  3.51s/it, loss=4.3672, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [14:16<00:28,  3.17s/it, loss=4.3670, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [14:19<00:24,  3.12s/it, loss=4.3672, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [14:21<00:20,  2.92s/it, loss=4.3662, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [14:24<00:17,  2.86s/it, loss=4.3657, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [14:26<00:13,  2.70s/it, loss=4.3645, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [14:30<00:11,  2.95s/it, loss=4.3632, tokens/Max input_id: 31782\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Training:  99%|█████████▉| 247/250 [14:33<00:09,  3.08s/it, loss=4.3643, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Training:  99%|█████████▉| 248/250 [14:36<00:05,  2.94s/it, loss=4.3646, tokens/Max input_id: 31800\n",
      "Max target_input: 31800\n",
      "Max label: 31800\n",
      "Training: 100%|█████████▉| 249/250 [14:38<00:02,  2.78s/it, loss=4.3654, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Training: 100%|██████████| 250/250 [14:55<00:00,  3.58s/it, loss=4.3661, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size:Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      " 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:08<04:09,  8.06s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:09<02:03,  4.11s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:10<01:23,  2.87s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:11<00:57,  2.05s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:12<00:46,  1.74s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:13<00:38,  1.49s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:14<00:32,  1.29s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:15<00:28,  1.18s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:17<00:33,  1.46s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:18<00:27,  1.26s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:19<00:25,  1.20s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:20<00:20,  1.05s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:21<00:20,  1.07s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:22<00:17,  1.04it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:23<00:16,  1.04it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:23<00:14,  1.12it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:24<00:14,  1.05it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:25<00:12,  1.09it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:26<00:11,  1.08it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:27<00:11,  1.06it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:28<00:09,  1.16it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:29<00:08,  1.12it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:30<00:08,  1.02it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:32<00:09,  1.25s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:33<00:08,  1.16s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:34<00:07,  1.22s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:35<00:05,  1.12s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:48<00:00,  1.52s/it]\n",
      "Removed old checkpoint: model_epoch_4.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_4.pt\n",
      "Saved training results to training_results_20250511_220223.csv\n",
      "Train Loss: 4.3661\n",
      "Val Loss: 4.6950\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: , the same?\n",
      "\n",
      "Epoch 5/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size:Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      " 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:10<42:59, 10.36s/it, loss=4.0901, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:14<27:22,  6.62s/it, loss=4.2615, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:16<18:49,  4.57s/it, loss=4.2952, tokens/s=Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:22<20:21,  4.97s/it, loss=4.2526, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:23<15:46,  3.86s/it, loss=4.2524, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:27<14:57,  3.68s/it, loss=4.2377, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:30<14:02,  3.47s/it, loss=4.2213, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:32<12:45,  3.16s/it, loss=4.2134, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:38<15:26,  3.84s/it, loss=4.2091, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:40<13:20,  3.34s/it, loss=4.2003, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:43<12:44,  3.20s/it, loss=4.1949, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:47<13:31,  3.41s/it, loss=4.2113, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:50<13:34,  3.44s/it, loss=4.2202, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:52<11:41,  2.97s/it, loss=4.2210, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [00:54<10:29,  2.68s/it, loss=4.2149, tokens/sMax input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [00:56<09:25,  2.42s/it, loss=4.2066, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [00:59<09:48,  2.53s/it, loss=4.2146, tokens/sMax input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:01<09:11,  2.38s/it, loss=4.2116, tokens/sMax input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:05<11:55,  3.10s/it, loss=4.2110, tokens/sMax input_id: 31773\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:12<15:55,  4.16s/it, loss=4.2111, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:14<13:38,  3.57s/it, loss=4.2013, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:17<12:50,  3.38s/it, loss=4.2119, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:19<11:27,  3.03s/it, loss=4.2056, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:22<11:22,  3.02s/it, loss=4.2052, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:27<12:48,  3.42s/it, loss=4.2089, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:35<18:25,  4.94s/it, loss=4.2154, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:38<15:53,  4.28s/it, loss=4.2169, tokens/sMax input_id: 31771\n",
      "Max target_input: 31806\n",
      "Max label: 31806\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [01:44<17:36,  4.76s/it, loss=4.2283, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [01:48<17:01,  4.62s/it, loss=4.2290, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [01:50<14:19,  3.91s/it, loss=4.2283, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [01:54<13:26,  3.68s/it, loss=4.2332, tokens/sMax input_id: 31764\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [02:02<18:35,  5.12s/it, loss=4.2309, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [02:05<16:09,  4.47s/it, loss=4.2331, tokens/sMax input_id: 31767\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:08<14:21,  3.99s/it, loss=4.2369, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:11<13:39,  3.81s/it, loss=4.2394, tokens/sMax input_id: 31766\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:14<12:09,  3.41s/it, loss=4.2389, tokens/sMax input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:17<11:31,  3.25s/it, loss=4.2388, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:19<10:13,  2.89s/it, loss=4.2350, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:25<13:30,  3.84s/it, loss=4.2320, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:28<12:22,  3.53s/it, loss=4.2277, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:30<11:35,  3.33s/it, loss=4.2238, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:33<11:03,  3.19s/it, loss=4.2235, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:37<11:18,  3.28s/it, loss=4.2261, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:39<10:23,  3.03s/it, loss=4.2222, tokens/sMax input_id: 31770\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [02:43<11:35,  3.39s/it, loss=4.2230, tokens/sMax input_id: 31769\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [02:46<10:34,  3.11s/it, loss=4.2236, tokens/sMax input_id: 31767\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [02:50<11:14,  3.32s/it, loss=4.2232, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [02:56<13:43,  4.08s/it, loss=4.2189, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [02:59<12:34,  3.75s/it, loss=4.2185, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [03:02<11:57,  3.59s/it, loss=4.2211, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [03:09<15:35,  4.70s/it, loss=4.2253, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:11<13:15,  4.02s/it, loss=4.2253, tokens/sMax input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:14<12:06,  3.69s/it, loss=4.2233, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:20<13:55,  4.26s/it, loss=4.2282, tokens/sMax input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:23<12:33,  3.86s/it, loss=4.2298, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:26<11:37,  3.59s/it, loss=4.2252, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:28<10:11,  3.17s/it, loss=4.2231, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:35<13:33,  4.24s/it, loss=4.2253, tokens/sMax input_id: 31764\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:37<11:28,  3.61s/it, loss=4.2247, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [03:40<11:03,  3.49s/it, loss=4.2242, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [03:43<10:42,  3.40s/it, loss=4.2229, tokens/sMax input_id: 31770\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [03:46<09:54,  3.16s/it, loss=4.2187, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [03:48<09:03,  2.91s/it, loss=4.2143, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [03:55<12:51,  4.15s/it, loss=4.2153, tokens/sMax input_id: 31767\n",
      "Max target_input: 31766\n",
      "Max label: 31766\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [03:58<11:25,  3.71s/it, loss=4.2116, tokens/sMax input_id: 31781\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [04:01<10:56,  3.57s/it, loss=4.2100, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [04:03<09:33,  3.13s/it, loss=4.2077, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [04:06<08:56,  2.95s/it, loss=4.2050, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [04:09<08:45,  2.90s/it, loss=4.2044, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [04:11<08:13,  2.74s/it, loss=4.2055, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:15<09:09,  3.07s/it, loss=4.2039, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:17<08:30,  2.87s/it, loss=4.2034, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:19<07:43,  2.62s/it, loss=4.2012, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:22<07:30,  2.56s/it, loss=4.2021, tokens/sMax input_id: 31767\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [04:24<07:00,  2.40s/it, loss=4.2009, tokens/sMax input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [04:28<08:23,  2.89s/it, loss=4.2007, tokens/sMax input_id: 31867\n",
      "Max target_input: 31867\n",
      "Max label: 31867\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [04:30<08:12,  2.84s/it, loss=4.2013, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [04:36<10:30,  3.67s/it, loss=4.2016, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [04:39<09:35,  3.37s/it, loss=4.2032, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [04:42<09:14,  3.26s/it, loss=4.2041, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [04:44<08:17,  2.94s/it, loss=4.2032, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [04:47<08:20,  2.98s/it, loss=4.2021, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [04:50<08:23,  3.02s/it, loss=4.2016, tokens/sMax input_id: 31794\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [04:57<11:32,  4.17s/it, loss=4.2000, tokens/sMax input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [05:01<11:05,  4.03s/it, loss=4.1993, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [05:03<09:46,  3.58s/it, loss=4.1950, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [05:05<08:18,  3.06s/it, loss=4.1937, tokens/sMax input_id: 31782\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [05:08<07:49,  2.90s/it, loss=4.1918, tokens/sMax input_id: 31789\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [05:15<11:15,  4.19s/it, loss=4.1944, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [05:17<09:31,  3.57s/it, loss=4.1937, tokens/sMax input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [05:22<10:39,  4.02s/it, loss=4.1931, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [05:25<10:02,  3.81s/it, loss=4.1912, tokens/sMax input_id: 31782\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [05:29<09:29,  3.63s/it, loss=4.1924, tokens/sMax input_id: 31761\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [05:30<08:00,  3.08s/it, loss=4.1887, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [05:34<08:26,  3.26s/it, loss=4.1911, tokens/sMax input_id: 31772\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [05:36<07:24,  2.89s/it, loss=4.1875, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [05:38<06:55,  2.72s/it, loss=4.1872, tokens/sMax input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [05:45<09:47,  3.87s/it, loss=4.1896, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [05:48<08:48,  3.50s/it, loss=4.1860, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [05:55<11:56,  4.78s/it, loss=4.1889, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [05:57<09:48,  3.95s/it, loss=4.1879, tokens/Max input_id: 31771\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [06:00<08:32,  3.46s/it, loss=4.1851, tokens/Max input_id: 31771\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [06:04<09:00,  3.68s/it, loss=4.1831, tokens/Max input_id: 31794\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [06:10<10:51,  4.46s/it, loss=4.1845, tokens/Max input_id: 31738\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [06:14<10:08,  4.20s/it, loss=4.1837, tokens/Max input_id: 31766\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [06:20<11:47,  4.91s/it, loss=4.1828, tokens/Max input_id: 31771\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [06:25<11:53,  4.99s/it, loss=4.1813, tokens/Max input_id: 31767\n",
      "Max target_input: 31825\n",
      "Max label: 31825\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [06:29<11:00,  4.65s/it, loss=4.1813, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [06:33<10:13,  4.35s/it, loss=4.1816, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [06:41<12:58,  5.56s/it, loss=4.1789, tokens/Max input_id: 31771\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [06:47<13:08,  5.67s/it, loss=4.1795, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [06:50<11:17,  4.91s/it, loss=4.1784, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [06:58<12:43,  5.57s/it, loss=4.1788, tokens/Max input_id: 31803\n",
      "Max target_input: 31803\n",
      "Max label: 31803\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [07:00<10:30,  4.63s/it, loss=4.1782, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [07:02<08:51,  3.94s/it, loss=4.1771, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [07:07<09:37,  4.31s/it, loss=4.1756, tokens/Max input_id: 31779\n",
      "Max target_input: 31779\n",
      "Max label: 31779\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [07:14<11:20,  5.12s/it, loss=4.1762, tokens/Max input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [07:21<12:06,  5.50s/it, loss=4.1769, tokens/Max input_id: 31764\n",
      "Max target_input: 31828\n",
      "Max label: 31828\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [07:24<10:27,  4.79s/it, loss=4.1788, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [07:26<08:34,  3.96s/it, loss=4.1781, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [07:29<07:34,  3.52s/it, loss=4.1792, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [07:31<06:59,  3.28s/it, loss=4.1809, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [07:35<07:23,  3.49s/it, loss=4.1806, tokens/Max input_id: 31782\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [07:37<06:28,  3.08s/it, loss=4.1786, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [07:42<07:06,  3.41s/it, loss=4.1782, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [07:46<07:34,  3.67s/it, loss=4.1776, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [07:48<06:25,  3.14s/it, loss=4.1760, tokens/Max input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [07:51<06:14,  3.07s/it, loss=4.1751, tokens/Max input_id: 31771\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [07:54<06:08,  3.04s/it, loss=4.1740, tokens/Max input_id: 31771\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [07:56<05:48,  2.90s/it, loss=4.1734, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [07:59<05:46,  2.91s/it, loss=4.1748, tokens/Max input_id: 31768\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [08:01<05:21,  2.73s/it, loss=4.1736, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [08:03<04:51,  2.49s/it, loss=4.1730, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [08:09<06:34,  3.40s/it, loss=4.1719, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [08:15<07:59,  4.17s/it, loss=4.1711, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [08:18<07:29,  3.94s/it, loss=4.1710, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [08:20<06:28,  3.44s/it, loss=4.1696, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [08:23<05:58,  3.20s/it, loss=4.1685, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [08:25<05:19,  2.88s/it, loss=4.1680, tokens/Max input_id: 31767\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [08:27<04:51,  2.65s/it, loss=4.1688, tokens/Max input_id: 31772\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [08:30<05:00,  2.76s/it, loss=4.1671, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [08:33<05:07,  2.85s/it, loss=4.1672, tokens/Max input_id: 31794\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [08:37<05:32,  3.11s/it, loss=4.1668, tokens/Max input_id: 31815\n",
      "Max target_input: 31815\n",
      "Max label: 31815\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [08:40<05:14,  2.97s/it, loss=4.1654, tokens/Max input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [08:45<06:27,  3.69s/it, loss=4.1657, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [08:48<05:46,  3.33s/it, loss=4.1650, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [08:50<05:03,  2.94s/it, loss=4.1632, tokens/Max input_id: 31768\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [08:53<05:09,  3.04s/it, loss=4.1642, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [08:57<05:41,  3.38s/it, loss=4.1640, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [09:02<06:26,  3.87s/it, loss=4.1640, tokens/Max input_id: 31794\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [09:05<05:53,  3.57s/it, loss=4.1649, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [09:10<06:17,  3.86s/it, loss=4.1647, tokens/Max input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [09:12<05:37,  3.48s/it, loss=4.1639, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [09:18<06:49,  4.27s/it, loss=4.1629, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [09:20<05:39,  3.58s/it, loss=4.1627, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [09:23<05:19,  3.40s/it, loss=4.1635, tokens/Max input_id: 31779\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [09:26<05:01,  3.24s/it, loss=4.1631, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [09:29<04:46,  3.12s/it, loss=4.1651, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [09:32<04:39,  3.08s/it, loss=4.1656, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [09:36<04:53,  3.26s/it, loss=4.1658, tokens/Max input_id: 31794\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [09:42<06:04,  4.10s/it, loss=4.1657, tokens/Max input_id: 31765\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [09:45<05:37,  3.83s/it, loss=4.1664, tokens/Max input_id: 31767\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [09:47<04:43,  3.25s/it, loss=4.1652, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [09:49<04:18,  3.00s/it, loss=4.1641, tokens/Max input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [09:53<04:25,  3.12s/it, loss=4.1637, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [09:59<05:36,  4.00s/it, loss=4.1637, tokens/Max input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [10:01<05:04,  3.67s/it, loss=4.1630, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [10:05<04:49,  3.53s/it, loss=4.1639, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [10:06<04:02,  2.99s/it, loss=4.1627, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [10:09<03:56,  2.96s/it, loss=4.1623, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [10:16<05:25,  4.12s/it, loss=4.1604, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [10:19<04:51,  3.74s/it, loss=4.1599, tokens/Max input_id: 31789\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [10:23<04:58,  3.88s/it, loss=4.1607, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [10:25<04:15,  3.37s/it, loss=4.1603, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [10:27<03:39,  2.93s/it, loss=4.1611, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [10:31<04:02,  3.28s/it, loss=4.1609, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [10:34<03:40,  3.02s/it, loss=4.1617, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [10:37<03:37,  3.02s/it, loss=4.1614, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [10:39<03:23,  2.87s/it, loss=4.1622, tokens/Max input_id: 31772\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [10:42<03:12,  2.75s/it, loss=4.1624, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [10:44<02:57,  2.57s/it, loss=4.1615, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [10:51<04:26,  3.91s/it, loss=4.1602, tokens/Max input_id: 31771\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [10:53<03:53,  3.48s/it, loss=4.1599, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [10:57<03:47,  3.45s/it, loss=4.1592, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [10:59<03:23,  3.13s/it, loss=4.1595, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [11:03<03:31,  3.31s/it, loss=4.1588, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [11:05<02:59,  2.84s/it, loss=4.1578, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [11:07<02:54,  2.82s/it, loss=4.1574, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [11:11<02:56,  2.89s/it, loss=4.1570, tokens/Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [11:19<04:40,  4.67s/it, loss=4.1565, tokens/Max input_id: 31800\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [11:24<04:41,  4.77s/it, loss=4.1565, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [11:27<04:06,  4.25s/it, loss=4.1550, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [11:30<03:39,  3.85s/it, loss=4.1556, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [11:35<03:51,  4.13s/it, loss=4.1554, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [11:38<03:30,  3.82s/it, loss=4.1550, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [11:42<03:30,  3.90s/it, loss=4.1545, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [11:47<03:39,  4.14s/it, loss=4.1536, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [11:52<03:54,  4.50s/it, loss=4.1520, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [11:57<03:53,  4.58s/it, loss=4.1520, tokens/Max input_id: 31794\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [12:03<04:11,  5.04s/it, loss=4.1510, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [12:12<05:06,  6.26s/it, loss=4.1519, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [12:20<05:14,  6.56s/it, loss=4.1526, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [12:22<04:14,  5.41s/it, loss=4.1522, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [12:25<03:30,  4.58s/it, loss=4.1519, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [12:28<03:08,  4.20s/it, loss=4.1533, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [12:31<02:48,  3.84s/it, loss=4.1536, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [12:36<03:01,  4.21s/it, loss=4.1539, tokens/Max input_id: 31771\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [12:39<02:40,  3.83s/it, loss=4.1540, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [12:42<02:22,  3.46s/it, loss=4.1535, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [12:46<02:26,  3.67s/it, loss=4.1533, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [12:50<02:23,  3.68s/it, loss=4.1518, tokens/Max input_id: 31790\n",
      "Max target_input: 31790\n",
      "Max label: 31790\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [12:57<03:00,  4.75s/it, loss=4.1510, tokens/Max input_id: 31794\n",
      "Max target_input: 31757\n",
      "Max label: 31757\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [12:59<02:27,  3.99s/it, loss=4.1508, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [13:02<02:10,  3.62s/it, loss=4.1509, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [13:04<01:49,  3.14s/it, loss=4.1492, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [13:06<01:38,  2.91s/it, loss=4.1496, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [13:11<01:51,  3.37s/it, loss=4.1490, tokens/Max input_id: 31771\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [13:16<02:08,  4.03s/it, loss=4.1481, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [13:21<02:07,  4.11s/it, loss=4.1473, tokens/Max input_id: 31762\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [13:23<01:48,  3.63s/it, loss=4.1473, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [13:27<01:44,  3.61s/it, loss=4.1464, tokens/Max input_id: 31794\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [13:29<01:33,  3.34s/it, loss=4.1449, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [13:32<01:27,  3.24s/it, loss=4.1448, tokens/Max input_id: 31772\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [13:39<01:46,  4.08s/it, loss=4.1455, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [13:41<01:30,  3.61s/it, loss=4.1445, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [13:43<01:16,  3.19s/it, loss=4.1418, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [13:45<01:03,  2.77s/it, loss=4.1402, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [13:47<00:55,  2.52s/it, loss=4.1390, tokens/Max input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [13:50<00:59,  2.83s/it, loss=4.1385, tokens/Max input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [13:53<00:56,  2.83s/it, loss=4.1372, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [13:59<01:08,  3.61s/it, loss=4.1362, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [14:04<01:16,  4.23s/it, loss=4.1352, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [14:06<01:00,  3.55s/it, loss=4.1337, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [14:13<01:12,  4.52s/it, loss=4.1333, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [14:16<00:58,  3.91s/it, loss=4.1339, tokens/Max input_id: 31797\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [14:23<01:10,  5.06s/it, loss=4.1349, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [14:26<00:56,  4.32s/it, loss=4.1342, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [14:29<00:48,  4.01s/it, loss=4.1338, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [14:32<00:41,  3.76s/it, loss=4.1338, tokens/Max input_id: 31801\n",
      "Max target_input: 31801\n",
      "Max label: 31801\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [14:36<00:35,  3.55s/it, loss=4.1334, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [14:38<00:29,  3.28s/it, loss=4.1334, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [14:44<00:32,  4.05s/it, loss=4.1338, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [14:47<00:27,  3.87s/it, loss=4.1327, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [14:51<00:22,  3.69s/it, loss=4.1319, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [14:53<00:16,  3.29s/it, loss=4.1310, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [14:56<00:13,  3.30s/it, loss=4.1299, tokens/Max input_id: 31782\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Training:  99%|█████████▉| 247/250 [15:01<00:11,  3.70s/it, loss=4.1310, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Training:  99%|█████████▉| 248/250 [15:06<00:08,  4.13s/it, loss=4.1313, tokens/Max input_id: 31800\n",
      "Max target_input: 31800\n",
      "Max label: 31800\n",
      "Training: 100%|█████████▉| 249/250 [15:09<00:03,  3.66s/it, loss=4.1321, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Training: 100%|██████████| 250/250 [15:26<00:00,  3.71s/it, loss=4.1328, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size:Tokenizer vocab size: 32000 \n",
      "32000\n",
      "Special tokens:\n",
      "Special tokens:\n",
      "  [PAD] ID: 0  [PAD] ID: 0\n",
      "\n",
      "  [UNK] ID: 1  [UNK] ID: 1\n",
      "\n",
      "  [BOS] ID: 2  [BOS] ID: 2\n",
      "\n",
      "  [EOS] ID: 3  [EOS] ID: 3\n",
      "\n",
      "  [DE] ID: 4\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:07<03:45,  7.27s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:09<02:10,  4.37s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:11<01:27,  3.03s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:11<01:00,  2.16s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:13<00:48,  1.79s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:14<00:40,  1.55s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:15<00:33,  1.35s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:15<00:29,  1.22s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:17<00:29,  1.29s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:18<00:25,  1.14s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:19<00:24,  1.15s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:20<00:24,  1.23s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:21<00:22,  1.21s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:22<00:19,  1.06s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:23<00:17,  1.01s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:24<00:15,  1.06it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:25<00:14,  1.01it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:26<00:13,  1.06it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:27<00:12,  1.06it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:28<00:11,  1.05it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:28<00:09,  1.14it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:29<00:09,  1.10it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:31<00:08,  1.01it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:32<00:08,  1.04s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:33<00:08,  1.20s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:35<00:08,  1.34s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:36<00:06,  1.21s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:49<00:00,  1.55s/it]\n",
      "Removed old checkpoint: model_epoch_5.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_5.pt\n",
      "Saved training results to training_results_20250511_221841.csv\n",
      "Train Loss: 4.1328\n",
      "Val Loss: 4.6361\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: , the European Union.\n",
      "\n",
      "Epoch 6/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:11<49:21, 11.89s/it, loss=3.8740, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:17<32:44,  7.92s/it, loss=4.0307, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:19<22:14,  5.40s/it, loss=4.0556, tokens/s=Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:26<24:08,  5.89s/it, loss=4.0178, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:28<18:16,  4.48s/it, loss=4.0152, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:33<19:22,  4.77s/it, loss=4.0060, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:35<15:49,  3.91s/it, loss=3.9965, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:38<14:20,  3.56s/it, loss=3.9877, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:43<16:12,  4.03s/it, loss=3.9856, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:45<13:55,  3.48s/it, loss=3.9793, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:48<13:10,  3.31s/it, loss=3.9746, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:54<16:31,  4.17s/it, loss=3.9884, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:57<14:36,  3.70s/it, loss=3.9962, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:59<12:20,  3.14s/it, loss=4.0028, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [01:01<10:59,  2.81s/it, loss=3.9963, tokens/sMax input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [01:03<09:47,  2.51s/it, loss=3.9890, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [01:05<09:52,  2.54s/it, loss=3.9965, tokens/sMax input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:08<10:16,  2.66s/it, loss=3.9959, tokens/sMax input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:13<12:53,  3.35s/it, loss=3.9958, tokens/sMax input_id: 31773\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:19<16:19,  4.26s/it, loss=3.9956, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:22<13:58,  3.66s/it, loss=3.9909, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:25<13:01,  3.43s/it, loss=4.0026, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:27<11:42,  3.10s/it, loss=3.9952, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:32<14:24,  3.83s/it, loss=3.9937, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:38<15:58,  4.26s/it, loss=3.9978, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:44<18:46,  5.03s/it, loss=4.0032, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:47<15:58,  4.30s/it, loss=4.0053, tokens/sMax input_id: 31771\n",
      "Max target_input: 31806\n",
      "Max label: 31806\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [01:53<17:50,  4.82s/it, loss=4.0180, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [01:56<15:57,  4.33s/it, loss=4.0171, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [02:00<14:37,  3.99s/it, loss=4.0167, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [02:04<15:13,  4.17s/it, loss=4.0219, tokens/sMax input_id: 31764\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [02:11<18:01,  4.96s/it, loss=4.0195, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [02:14<15:49,  4.37s/it, loss=4.0213, tokens/sMax input_id: 31767\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:17<14:02,  3.90s/it, loss=4.0247, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:20<13:17,  3.71s/it, loss=4.0265, tokens/sMax input_id: 31766\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:23<12:56,  3.63s/it, loss=4.0265, tokens/sMax input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:28<13:34,  3.82s/it, loss=4.0253, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:30<11:37,  3.29s/it, loss=4.0214, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:34<13:04,  3.72s/it, loss=4.0189, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:37<11:54,  3.40s/it, loss=4.0138, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:40<11:11,  3.21s/it, loss=4.0095, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:44<11:42,  3.38s/it, loss=4.0083, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:49<13:43,  3.98s/it, loss=4.0109, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:51<12:03,  3.51s/it, loss=4.0065, tokens/sMax input_id: 31770\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [02:55<11:33,  3.38s/it, loss=4.0079, tokens/sMax input_id: 31769\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [02:57<10:35,  3.11s/it, loss=4.0085, tokens/sMax input_id: 31767\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [03:00<10:08,  3.00s/it, loss=4.0092, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [03:07<14:37,  4.34s/it, loss=4.0054, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [03:10<13:22,  3.99s/it, loss=4.0050, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [03:14<13:04,  3.92s/it, loss=4.0088, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [03:21<15:27,  4.66s/it, loss=4.0141, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:23<13:18,  4.03s/it, loss=4.0151, tokens/sMax input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:26<12:16,  3.74s/it, loss=4.0131, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:33<15:40,  4.80s/it, loss=4.0188, tokens/sMax input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:36<13:45,  4.23s/it, loss=4.0217, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:40<12:41,  3.93s/it, loss=4.0176, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:42<11:03,  3.44s/it, loss=4.0151, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:47<12:33,  3.93s/it, loss=4.0184, tokens/sMax input_id: 31764\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:50<11:41,  3.67s/it, loss=4.0191, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [03:55<12:52,  4.07s/it, loss=4.0183, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [03:59<12:37,  4.01s/it, loss=4.0161, tokens/sMax input_id: 31770\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [04:01<11:09,  3.56s/it, loss=4.0115, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [04:04<09:59,  3.21s/it, loss=4.0086, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [04:09<12:17,  3.96s/it, loss=4.0108, tokens/sMax input_id: 31767\n",
      "Max target_input: 31766\n",
      "Max label: 31766\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [04:13<11:57,  3.88s/it, loss=4.0071, tokens/sMax input_id: 31781\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [04:18<12:32,  4.09s/it, loss=4.0060, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [04:20<10:51,  3.56s/it, loss=4.0039, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [04:23<10:31,  3.47s/it, loss=4.0016, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [04:26<10:02,  3.33s/it, loss=4.0010, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [04:29<09:02,  3.01s/it, loss=4.0020, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:34<10:45,  3.61s/it, loss=4.0005, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:37<10:14,  3.45s/it, loss=3.9997, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:39<09:02,  3.07s/it, loss=3.9972, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:41<08:33,  2.92s/it, loss=3.9981, tokens/sMax input_id: 31767\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [04:44<07:47,  2.67s/it, loss=3.9965, tokens/sMax input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [04:49<09:52,  3.40s/it, loss=3.9968, tokens/sMax input_id: 31867\n",
      "Max target_input: 31867\n",
      "Max label: 31867\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [04:52<09:38,  3.34s/it, loss=3.9974, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [04:57<10:52,  3.79s/it, loss=3.9980, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [04:59<09:48,  3.44s/it, loss=3.9995, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [05:03<09:58,  3.52s/it, loss=4.0001, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [05:05<08:55,  3.17s/it, loss=3.9997, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [05:12<11:24,  4.07s/it, loss=3.9985, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [05:16<11:42,  4.21s/it, loss=3.9981, tokens/sMax input_id: 31794\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [05:24<14:22,  5.20s/it, loss=3.9961, tokens/sMax input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [05:27<12:30,  4.55s/it, loss=3.9956, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [05:29<10:48,  3.96s/it, loss=3.9916, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [05:31<09:15,  3.41s/it, loss=3.9900, tokens/sMax input_id: 31782\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [05:35<09:28,  3.51s/it, loss=3.9881, tokens/sMax input_id: 31789\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [05:43<12:54,  4.81s/it, loss=3.9907, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [05:45<10:50,  4.06s/it, loss=3.9902, tokens/sMax input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [05:49<10:14,  3.87s/it, loss=3.9897, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [05:51<09:17,  3.53s/it, loss=3.9878, tokens/sMax input_id: 31782\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [05:57<10:32,  4.03s/it, loss=3.9890, tokens/sMax input_id: 31761\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [05:58<08:34,  3.30s/it, loss=3.9852, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [06:02<09:14,  3.58s/it, loss=3.9876, tokens/sMax input_id: 31772\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [06:05<08:08,  3.17s/it, loss=3.9837, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [06:07<07:35,  2.97s/it, loss=3.9834, tokens/sMax input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [06:11<08:23,  3.31s/it, loss=3.9855, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [06:15<08:23,  3.33s/it, loss=3.9822, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [06:22<11:20,  4.54s/it, loss=3.9857, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [06:24<09:24,  3.79s/it, loss=3.9842, tokens/Max input_id: 31771\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [06:27<08:27,  3.43s/it, loss=3.9814, tokens/Max input_id: 31771\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [06:29<08:00,  3.27s/it, loss=3.9793, tokens/Max input_id: 31794\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [06:32<07:45,  3.19s/it, loss=3.9807, tokens/Max input_id: 31738\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [06:36<07:42,  3.19s/it, loss=3.9795, tokens/Max input_id: 31766\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [06:41<09:06,  3.80s/it, loss=3.9779, tokens/Max input_id: 31771\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [06:44<08:26,  3.54s/it, loss=3.9768, tokens/Max input_id: 31767\n",
      "Max target_input: 31825\n",
      "Max label: 31825\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [06:46<07:41,  3.25s/it, loss=3.9771, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [06:49<07:04,  3.01s/it, loss=3.9772, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [06:53<08:07,  3.48s/it, loss=3.9741, tokens/Max input_id: 31771\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [07:00<10:04,  4.35s/it, loss=3.9753, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [07:03<09:10,  3.99s/it, loss=3.9746, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [07:10<11:26,  5.01s/it, loss=3.9752, tokens/Max input_id: 31803\n",
      "Max target_input: 31803\n",
      "Max label: 31803\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [07:13<09:38,  4.25s/it, loss=3.9747, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [07:15<08:18,  3.70s/it, loss=3.9735, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [07:18<07:56,  3.56s/it, loss=3.9719, tokens/Max input_id: 31779\n",
      "Max target_input: 31779\n",
      "Max label: 31779\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [07:27<10:54,  4.92s/it, loss=3.9725, tokens/Max input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [07:34<12:24,  5.64s/it, loss=3.9731, tokens/Max input_id: 31764\n",
      "Max target_input: 31828\n",
      "Max label: 31828\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [07:37<10:36,  4.86s/it, loss=3.9751, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [07:39<08:42,  4.02s/it, loss=3.9747, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [07:42<07:41,  3.58s/it, loss=3.9761, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [07:44<07:07,  3.34s/it, loss=3.9782, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [07:49<07:42,  3.64s/it, loss=3.9773, tokens/Max input_id: 31782\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [07:51<06:39,  3.17s/it, loss=3.9753, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [07:55<07:26,  3.57s/it, loss=3.9752, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [07:58<07:09,  3.46s/it, loss=3.9747, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [08:00<06:07,  2.99s/it, loss=3.9727, tokens/Max input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [08:03<05:59,  2.95s/it, loss=3.9716, tokens/Max input_id: 31771\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [08:06<06:03,  3.01s/it, loss=3.9704, tokens/Max input_id: 31771\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [08:09<05:47,  2.90s/it, loss=3.9694, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [08:13<06:07,  3.09s/it, loss=3.9708, tokens/Max input_id: 31768\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [08:15<05:39,  2.88s/it, loss=3.9693, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [08:17<05:05,  2.61s/it, loss=3.9687, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [08:25<08:09,  4.22s/it, loss=3.9674, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [08:30<08:44,  4.56s/it, loss=3.9665, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [08:35<08:53,  4.68s/it, loss=3.9662, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [08:37<07:25,  3.95s/it, loss=3.9647, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [08:41<07:04,  3.79s/it, loss=3.9632, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [08:43<06:18,  3.41s/it, loss=3.9623, tokens/Max input_id: 31767\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [08:47<06:14,  3.40s/it, loss=3.9630, tokens/Max input_id: 31772\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [08:51<06:42,  3.69s/it, loss=3.9613, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [08:53<05:50,  3.25s/it, loss=3.9620, tokens/Max input_id: 31794\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [08:58<06:25,  3.61s/it, loss=3.9621, tokens/Max input_id: 31815\n",
      "Max target_input: 31815\n",
      "Max label: 31815\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [09:01<06:21,  3.60s/it, loss=3.9608, tokens/Max input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [09:08<08:03,  4.61s/it, loss=3.9609, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [09:17<10:02,  5.79s/it, loss=3.9600, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [09:19<08:15,  4.81s/it, loss=3.9582, tokens/Max input_id: 31768\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [09:23<07:36,  4.47s/it, loss=3.9592, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [09:29<08:02,  4.78s/it, loss=3.9589, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [09:35<08:42,  5.23s/it, loss=3.9589, tokens/Max input_id: 31794\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [09:38<07:49,  4.74s/it, loss=3.9599, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [09:45<08:41,  5.32s/it, loss=3.9597, tokens/Max input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [09:49<08:08,  5.03s/it, loss=3.9591, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [09:55<08:23,  5.24s/it, loss=3.9583, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [09:57<06:52,  4.34s/it, loss=3.9581, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [10:02<07:02,  4.50s/it, loss=3.9590, tokens/Max input_id: 31779\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [10:09<07:47,  5.03s/it, loss=3.9584, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [10:12<07:06,  4.64s/it, loss=3.9603, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [10:17<07:07,  4.69s/it, loss=3.9611, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [10:22<07:09,  4.78s/it, loss=3.9612, tokens/Max input_id: 31794\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [10:29<07:57,  5.36s/it, loss=3.9609, tokens/Max input_id: 31765\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [10:33<07:26,  5.08s/it, loss=3.9619, tokens/Max input_id: 31767\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [10:35<05:57,  4.11s/it, loss=3.9603, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [10:38<05:13,  3.64s/it, loss=3.9593, tokens/Max input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [10:42<05:30,  3.88s/it, loss=3.9593, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [10:46<05:17,  3.78s/it, loss=3.9592, tokens/Max input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [10:48<04:48,  3.47s/it, loss=3.9587, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [10:53<05:24,  3.96s/it, loss=3.9593, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [10:55<04:25,  3.28s/it, loss=3.9581, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [10:59<04:45,  3.56s/it, loss=3.9580, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [11:06<05:55,  4.50s/it, loss=3.9562, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [11:08<04:48,  3.70s/it, loss=3.9555, tokens/Max input_id: 31789\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [11:11<04:31,  3.53s/it, loss=3.9562, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [11:14<04:19,  3.42s/it, loss=3.9560, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [11:16<03:41,  2.96s/it, loss=3.9568, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [11:20<03:57,  3.20s/it, loss=3.9568, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [11:22<03:34,  2.94s/it, loss=3.9576, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [11:24<03:17,  2.75s/it, loss=3.9568, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [11:28<03:35,  3.03s/it, loss=3.9575, tokens/Max input_id: 31772\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [11:31<03:24,  2.92s/it, loss=3.9576, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [11:33<03:04,  2.68s/it, loss=3.9562, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [11:40<04:28,  3.95s/it, loss=3.9548, tokens/Max input_id: 31771\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [11:42<03:55,  3.51s/it, loss=3.9547, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [11:45<03:29,  3.17s/it, loss=3.9542, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [11:48<03:29,  3.22s/it, loss=3.9542, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [11:51<03:28,  3.25s/it, loss=3.9537, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [11:53<02:56,  2.80s/it, loss=3.9526, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [11:56<02:55,  2.83s/it, loss=3.9524, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [11:59<02:55,  2.88s/it, loss=3.9520, tokens/Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [12:06<04:02,  4.04s/it, loss=3.9516, tokens/Max input_id: 31800\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [12:10<04:01,  4.10s/it, loss=3.9515, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [12:13<03:38,  3.76s/it, loss=3.9498, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [12:16<03:20,  3.52s/it, loss=3.9500, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [12:19<03:13,  3.46s/it, loss=3.9499, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [12:22<02:49,  3.09s/it, loss=3.9495, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [12:24<02:38,  2.94s/it, loss=3.9491, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [12:27<02:41,  3.04s/it, loss=3.9483, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [12:32<03:04,  3.56s/it, loss=3.9467, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [12:36<03:02,  3.57s/it, loss=3.9465, tokens/Max input_id: 31794\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [12:40<03:08,  3.77s/it, loss=3.9454, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [12:46<03:31,  4.32s/it, loss=3.9462, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [12:52<03:58,  4.97s/it, loss=3.9469, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [12:56<03:36,  4.61s/it, loss=3.9463, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [12:59<03:09,  4.12s/it, loss=3.9461, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [13:04<03:13,  4.29s/it, loss=3.9473, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [13:07<02:54,  3.96s/it, loss=3.9473, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [13:10<02:42,  3.78s/it, loss=3.9474, tokens/Max input_id: 31771\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [13:13<02:22,  3.39s/it, loss=3.9474, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [13:16<02:19,  3.40s/it, loss=3.9469, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [13:21<02:39,  3.99s/it, loss=3.9467, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [13:25<02:31,  3.89s/it, loss=3.9454, tokens/Max input_id: 31790\n",
      "Max target_input: 31790\n",
      "Max label: 31790\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [13:30<02:39,  4.20s/it, loss=3.9445, tokens/Max input_id: 31794\n",
      "Max target_input: 31757\n",
      "Max label: 31757\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [13:32<02:16,  3.68s/it, loss=3.9443, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [13:37<02:21,  3.93s/it, loss=3.9444, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [13:39<02:00,  3.43s/it, loss=3.9428, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [13:42<01:47,  3.15s/it, loss=3.9431, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [13:46<01:59,  3.63s/it, loss=3.9428, tokens/Max input_id: 31771\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [13:50<01:53,  3.55s/it, loss=3.9418, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [13:53<01:45,  3.40s/it, loss=3.9409, tokens/Max input_id: 31762\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [13:56<01:44,  3.47s/it, loss=3.9408, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [14:01<01:53,  3.92s/it, loss=3.9400, tokens/Max input_id: 31794\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [14:04<01:39,  3.55s/it, loss=3.9387, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [14:07<01:30,  3.34s/it, loss=3.9388, tokens/Max input_id: 31772\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [14:11<01:30,  3.50s/it, loss=3.9398, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [14:13<01:18,  3.14s/it, loss=3.9387, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [14:16<01:15,  3.15s/it, loss=3.9362, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [14:18<01:03,  2.76s/it, loss=3.9345, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [14:20<00:57,  2.60s/it, loss=3.9331, tokens/Max input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [14:25<01:05,  3.13s/it, loss=3.9329, tokens/Max input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [14:27<00:54,  2.74s/it, loss=3.9316, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [14:31<01:02,  3.29s/it, loss=3.9306, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [14:38<01:19,  4.44s/it, loss=3.9297, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [14:40<01:03,  3.71s/it, loss=3.9283, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [14:47<01:14,  4.66s/it, loss=3.9281, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [14:50<01:00,  4.05s/it, loss=3.9287, tokens/Max input_id: 31797\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [14:58<01:13,  5.23s/it, loss=3.9300, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [15:00<00:57,  4.46s/it, loss=3.9293, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [15:04<00:51,  4.28s/it, loss=3.9289, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [15:08<00:43,  3.98s/it, loss=3.9292, tokens/Max input_id: 31801\n",
      "Max target_input: 31801\n",
      "Max label: 31801\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [15:10<00:36,  3.62s/it, loss=3.9288, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [15:13<00:29,  3.25s/it, loss=3.9284, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [15:17<00:28,  3.62s/it, loss=3.9290, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [15:21<00:25,  3.69s/it, loss=3.9278, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [15:24<00:21,  3.60s/it, loss=3.9272, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [15:27<00:16,  3.24s/it, loss=3.9262, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [15:30<00:12,  3.14s/it, loss=3.9252, tokens/Max input_id: 31782\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Training:  99%|█████████▉| 247/250 [15:34<00:10,  3.51s/it, loss=3.9264, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Training:  99%|█████████▉| 248/250 [15:38<00:07,  3.52s/it, loss=3.9265, tokens/Max input_id: 31800\n",
      "Max target_input: 31800\n",
      "Max label: 31800\n",
      "Training: 100%|█████████▉| 249/250 [15:42<00:03,  3.72s/it, loss=3.9271, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Training: 100%|██████████| 250/250 [15:59<00:00,  3.84s/it, loss=3.9278, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:07<03:45,  7.28s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:09<02:10,  4.36s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:10<01:26,  2.99s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:11<01:00,  2.15s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:12<00:48,  1.79s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:14<00:40,  1.55s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:14<00:33,  1.34s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:15<00:29,  1.22s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:18<00:34,  1.50s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:18<00:28,  1.27s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:19<00:25,  1.21s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:20<00:21,  1.05s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:21<00:20,  1.07s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:22<00:17,  1.03it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:23<00:15,  1.07it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:24<00:14,  1.11it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:25<00:14,  1.02it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:26<00:13,  1.05it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:27<00:12,  1.05it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:28<00:11,  1.04it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:28<00:09,  1.13it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:29<00:09,  1.10it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:31<00:10,  1.20s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:33<00:10,  1.25s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:33<00:08,  1.16s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:35<00:07,  1.23s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:36<00:05,  1.13s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:49<00:00,  1.54s/it]\n",
      "Removed old checkpoint: model_epoch_6.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_6.pt\n",
      "Saved training results to training_results_20250511_223533.csv\n",
      "Train Loss: 3.9278\n",
      "Val Loss: 4.5882\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: , the European Union.\n",
      "\n",
      "Epoch 7/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:09<40:48,  9.84s/it, loss=3.6476, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:14<28:28,  6.89s/it, loss=3.8039, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:16<19:22,  4.71s/it, loss=3.8380, tokens/s=Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:24<23:55,  5.84s/it, loss=3.7947, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:26<18:10,  4.45s/it, loss=3.7847, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:29<16:44,  4.12s/it, loss=3.7724, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:31<13:59,  3.45s/it, loss=3.7521, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:34<12:52,  3.19s/it, loss=3.7492, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:40<15:49,  3.94s/it, loss=3.7515, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:43<14:53,  3.72s/it, loss=3.7443, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:48<16:20,  4.10s/it, loss=3.7418, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:52<16:52,  4.26s/it, loss=3.7630, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:55<14:41,  3.72s/it, loss=3.7739, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:57<12:28,  3.17s/it, loss=3.7795, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [00:59<10:59,  2.81s/it, loss=3.7732, tokens/sMax input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [01:02<11:15,  2.89s/it, loss=3.7729, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [01:06<12:21,  3.18s/it, loss=3.7848, tokens/sMax input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:08<11:13,  2.90s/it, loss=3.7850, tokens/sMax input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:12<12:46,  3.32s/it, loss=3.7887, tokens/sMax input_id: 31773\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:19<16:45,  4.37s/it, loss=3.7912, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:22<15:25,  4.04s/it, loss=3.7871, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:27<16:06,  4.24s/it, loss=3.7998, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:29<13:54,  3.68s/it, loss=3.7918, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:33<13:39,  3.63s/it, loss=3.7910, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:38<15:32,  4.14s/it, loss=3.7977, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:46<19:11,  5.14s/it, loss=3.8037, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:51<18:51,  5.07s/it, loss=3.8070, tokens/sMax input_id: 31771\n",
      "Max target_input: 31806\n",
      "Max label: 31806\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [01:58<21:05,  5.70s/it, loss=3.8201, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [02:02<19:29,  5.29s/it, loss=3.8199, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [02:05<16:11,  4.42s/it, loss=3.8196, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [02:09<16:21,  4.48s/it, loss=3.8255, tokens/sMax input_id: 31764\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [02:18<21:05,  5.81s/it, loss=3.8227, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [02:21<18:13,  5.04s/it, loss=3.8255, tokens/sMax input_id: 31767\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:24<15:47,  4.39s/it, loss=3.8278, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:28<14:57,  4.17s/it, loss=3.8280, tokens/sMax input_id: 31766\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:30<13:03,  3.66s/it, loss=3.8278, tokens/sMax input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:33<12:21,  3.48s/it, loss=3.8267, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:37<11:54,  3.37s/it, loss=3.8222, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:42<13:36,  3.87s/it, loss=3.8203, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:44<12:18,  3.52s/it, loss=3.8156, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:47<11:30,  3.31s/it, loss=3.8098, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:50<11:01,  3.18s/it, loss=3.8075, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:55<13:02,  3.78s/it, loss=3.8106, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [03:00<13:44,  4.00s/it, loss=3.8067, tokens/sMax input_id: 31770\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [03:05<14:56,  4.37s/it, loss=3.8080, tokens/sMax input_id: 31769\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [03:07<13:02,  3.84s/it, loss=3.8094, tokens/sMax input_id: 31767\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [03:12<13:13,  3.91s/it, loss=3.8100, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [03:18<16:06,  4.78s/it, loss=3.8054, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [03:23<15:34,  4.65s/it, loss=3.8050, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [03:31<18:47,  5.64s/it, loss=3.8091, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [03:39<21:13,  6.40s/it, loss=3.8148, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:41<17:18,  5.25s/it, loss=3.8159, tokens/sMax input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:45<15:09,  4.62s/it, loss=3.8146, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:50<16:00,  4.90s/it, loss=3.8195, tokens/sMax input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:53<14:04,  4.33s/it, loss=3.8218, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:58<14:37,  4.52s/it, loss=3.8186, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [04:00<12:21,  3.84s/it, loss=3.8163, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [04:06<14:03,  4.39s/it, loss=3.8194, tokens/sMax input_id: 31764\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [04:08<11:51,  3.73s/it, loss=3.8205, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [04:12<12:12,  3.86s/it, loss=3.8200, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [04:18<14:05,  4.47s/it, loss=3.8175, tokens/sMax input_id: 31770\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [04:21<12:37,  4.03s/it, loss=3.8130, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [04:24<11:02,  3.55s/it, loss=3.8097, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [04:30<13:15,  4.28s/it, loss=3.8119, tokens/sMax input_id: 31767\n",
      "Max target_input: 31766\n",
      "Max label: 31766\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [04:32<11:45,  3.81s/it, loss=3.8085, tokens/sMax input_id: 31781\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [04:36<11:42,  3.82s/it, loss=3.8065, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [04:40<11:15,  3.69s/it, loss=3.8050, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [04:43<10:33,  3.48s/it, loss=3.8016, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [04:46<10:07,  3.35s/it, loss=3.8009, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [04:48<09:13,  3.07s/it, loss=3.8027, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:51<09:22,  3.14s/it, loss=3.8007, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:54<08:37,  2.91s/it, loss=3.7992, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:57<08:43,  2.96s/it, loss=3.7959, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:59<08:16,  2.82s/it, loss=3.7966, tokens/sMax input_id: 31767\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [05:01<07:33,  2.59s/it, loss=3.7952, tokens/sMax input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [05:05<08:07,  2.80s/it, loss=3.7955, tokens/sMax input_id: 31867\n",
      "Max target_input: 31867\n",
      "Max label: 31867\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [05:07<07:52,  2.73s/it, loss=3.7956, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [05:12<09:21,  3.26s/it, loss=3.7956, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [05:15<09:22,  3.29s/it, loss=3.7966, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [05:18<09:07,  3.22s/it, loss=3.7974, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [05:20<08:10,  2.90s/it, loss=3.7959, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [05:23<08:15,  2.95s/it, loss=3.7942, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [05:26<08:19,  2.99s/it, loss=3.7936, tokens/sMax input_id: 31794\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [05:33<11:17,  4.08s/it, loss=3.7916, tokens/sMax input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [05:37<10:52,  3.95s/it, loss=3.7904, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [05:39<09:35,  3.51s/it, loss=3.7853, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [05:41<08:13,  3.02s/it, loss=3.7836, tokens/sMax input_id: 31782\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [05:44<07:46,  2.88s/it, loss=3.7816, tokens/sMax input_id: 31789\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [05:51<11:39,  4.34s/it, loss=3.7844, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [05:55<11:20,  4.25s/it, loss=3.7839, tokens/sMax input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [06:01<12:20,  4.66s/it, loss=3.7835, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [06:06<12:12,  4.63s/it, loss=3.7817, tokens/sMax input_id: 31782\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [06:10<11:56,  4.57s/it, loss=3.7827, tokens/sMax input_id: 31761\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [06:13<10:25,  4.01s/it, loss=3.7785, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [06:17<10:40,  4.13s/it, loss=3.7807, tokens/sMax input_id: 31772\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [06:19<09:02,  3.52s/it, loss=3.7761, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [06:22<08:09,  3.20s/it, loss=3.7757, tokens/sMax input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [06:26<09:12,  3.64s/it, loss=3.7783, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [06:29<08:14,  3.27s/it, loss=3.7750, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [06:37<12:09,  4.87s/it, loss=3.7783, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [06:39<09:59,  4.03s/it, loss=3.7760, tokens/Max input_id: 31771\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [06:42<08:42,  3.53s/it, loss=3.7726, tokens/Max input_id: 31771\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [06:45<08:11,  3.34s/it, loss=3.7706, tokens/Max input_id: 31794\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [06:48<07:50,  3.22s/it, loss=3.7719, tokens/Max input_id: 31738\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [06:50<07:04,  2.93s/it, loss=3.7707, tokens/Max input_id: 31766\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [06:56<09:15,  3.86s/it, loss=3.7694, tokens/Max input_id: 31771\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [06:59<08:36,  3.61s/it, loss=3.7674, tokens/Max input_id: 31767\n",
      "Max target_input: 31825\n",
      "Max label: 31825\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [07:01<07:48,  3.30s/it, loss=3.7671, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [07:04<07:10,  3.05s/it, loss=3.7670, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [07:09<08:29,  3.64s/it, loss=3.7639, tokens/Max input_id: 31771\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [07:15<10:04,  4.35s/it, loss=3.7642, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [07:18<09:01,  3.93s/it, loss=3.7635, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [07:26<11:34,  5.07s/it, loss=3.7646, tokens/Max input_id: 31803\n",
      "Max target_input: 31803\n",
      "Max label: 31803\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [07:28<09:48,  4.33s/it, loss=3.7639, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [07:31<08:25,  3.75s/it, loss=3.7631, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [07:37<10:25,  4.67s/it, loss=3.7621, tokens/Max input_id: 31779\n",
      "Max target_input: 31779\n",
      "Max label: 31779\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [07:45<12:06,  5.46s/it, loss=3.7629, tokens/Max input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [07:52<13:25,  6.10s/it, loss=3.7638, tokens/Max input_id: 31764\n",
      "Max target_input: 31828\n",
      "Max label: 31828\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [07:59<13:57,  6.39s/it, loss=3.7662, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [08:01<11:00,  5.08s/it, loss=3.7659, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [08:05<10:01,  4.66s/it, loss=3.7671, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [08:10<10:01,  4.70s/it, loss=3.7690, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [08:14<09:38,  4.56s/it, loss=3.7686, tokens/Max input_id: 31782\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [08:16<07:56,  3.78s/it, loss=3.7664, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [08:20<07:36,  3.65s/it, loss=3.7662, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [08:23<07:09,  3.47s/it, loss=3.7658, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [08:24<06:05,  2.98s/it, loss=3.7641, tokens/Max input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [08:27<05:58,  2.94s/it, loss=3.7629, tokens/Max input_id: 31771\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [08:30<06:00,  2.98s/it, loss=3.7619, tokens/Max input_id: 31771\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [08:34<06:06,  3.05s/it, loss=3.7606, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [08:37<06:34,  3.32s/it, loss=3.7620, tokens/Max input_id: 31768\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [08:40<05:57,  3.03s/it, loss=3.7601, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [08:42<05:15,  2.70s/it, loss=3.7595, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [08:47<06:51,  3.55s/it, loss=3.7583, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [08:52<07:12,  3.76s/it, loss=3.7570, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [08:58<08:31,  4.48s/it, loss=3.7563, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [09:00<07:13,  3.83s/it, loss=3.7549, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [09:03<06:35,  3.53s/it, loss=3.7533, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [09:05<05:45,  3.12s/it, loss=3.7526, tokens/Max input_id: 31767\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [09:07<05:14,  2.86s/it, loss=3.7531, tokens/Max input_id: 31772\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [09:11<05:25,  2.99s/it, loss=3.7515, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [09:14<05:26,  3.02s/it, loss=3.7514, tokens/Max input_id: 31794\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [09:18<06:18,  3.53s/it, loss=3.7511, tokens/Max input_id: 31815\n",
      "Max target_input: 31815\n",
      "Max label: 31815\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [09:21<05:45,  3.26s/it, loss=3.7501, tokens/Max input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [09:26<06:50,  3.91s/it, loss=3.7505, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [09:29<06:02,  3.49s/it, loss=3.7498, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [09:31<05:10,  3.01s/it, loss=3.7478, tokens/Max input_id: 31768\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [09:33<04:45,  2.79s/it, loss=3.7486, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [09:38<05:58,  3.55s/it, loss=3.7479, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [09:44<06:49,  4.10s/it, loss=3.7480, tokens/Max input_id: 31794\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [09:47<06:07,  3.71s/it, loss=3.7490, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [09:52<06:40,  4.09s/it, loss=3.7488, tokens/Max input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [09:54<05:53,  3.64s/it, loss=3.7485, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [09:58<05:58,  3.74s/it, loss=3.7478, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [10:01<05:33,  3.51s/it, loss=3.7471, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [10:06<05:58,  3.81s/it, loss=3.7483, tokens/Max input_id: 31779\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [10:09<05:39,  3.65s/it, loss=3.7475, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [10:12<05:14,  3.42s/it, loss=3.7491, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [10:15<05:00,  3.31s/it, loss=3.7498, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [10:18<04:42,  3.14s/it, loss=3.7503, tokens/Max input_id: 31794\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [10:23<05:46,  3.90s/it, loss=3.7502, tokens/Max input_id: 31765\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [10:27<05:45,  3.93s/it, loss=3.7515, tokens/Max input_id: 31767\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [10:29<04:48,  3.31s/it, loss=3.7500, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [10:32<04:27,  3.11s/it, loss=3.7495, tokens/Max input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [10:37<05:14,  3.70s/it, loss=3.7496, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [10:41<05:33,  3.97s/it, loss=3.7495, tokens/Max input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [10:44<04:58,  3.60s/it, loss=3.7493, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [10:50<05:38,  4.13s/it, loss=3.7503, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [10:51<04:35,  3.40s/it, loss=3.7493, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [10:55<04:50,  3.63s/it, loss=3.7494, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [11:02<05:59,  4.55s/it, loss=3.7478, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [11:04<04:50,  3.72s/it, loss=3.7472, tokens/Max input_id: 31789\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [11:07<04:33,  3.56s/it, loss=3.7477, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [11:09<03:57,  3.12s/it, loss=3.7474, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [11:12<03:49,  3.06s/it, loss=3.7485, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [11:16<04:01,  3.27s/it, loss=3.7489, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [11:18<03:39,  3.01s/it, loss=3.7498, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [11:20<03:18,  2.76s/it, loss=3.7493, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [11:23<03:16,  2.77s/it, loss=3.7501, tokens/Max input_id: 31772\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [11:26<03:07,  2.69s/it, loss=3.7503, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [11:28<02:51,  2.48s/it, loss=3.7488, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [11:36<04:49,  4.26s/it, loss=3.7477, tokens/Max input_id: 31771\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [11:39<04:10,  3.74s/it, loss=3.7475, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [11:41<03:38,  3.30s/it, loss=3.7472, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [11:43<03:15,  3.01s/it, loss=3.7473, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [11:46<03:13,  3.02s/it, loss=3.7473, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [11:48<02:46,  2.64s/it, loss=3.7461, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [11:50<02:40,  2.59s/it, loss=3.7461, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [11:54<02:58,  2.92s/it, loss=3.7455, tokens/Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [12:01<04:08,  4.14s/it, loss=3.7452, tokens/Max input_id: 31800\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [12:04<03:43,  3.79s/it, loss=3.7450, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [12:07<03:20,  3.45s/it, loss=3.7434, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [12:10<03:06,  3.28s/it, loss=3.7438, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [12:13<03:05,  3.32s/it, loss=3.7439, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [12:17<03:05,  3.37s/it, loss=3.7435, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [12:20<03:09,  3.51s/it, loss=3.7431, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [12:23<02:55,  3.31s/it, loss=3.7425, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [12:28<03:12,  3.71s/it, loss=3.7410, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [12:31<03:07,  3.67s/it, loss=3.7405, tokens/Max input_id: 31794\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [12:38<03:39,  4.39s/it, loss=3.7394, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [12:46<04:28,  5.48s/it, loss=3.7403, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [12:52<04:41,  5.86s/it, loss=3.7412, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [12:56<04:00,  5.11s/it, loss=3.7403, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [12:59<03:35,  4.69s/it, loss=3.7406, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [13:05<03:40,  4.90s/it, loss=3.7417, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [13:09<03:21,  4.58s/it, loss=3.7416, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [13:15<03:46,  5.27s/it, loss=3.7419, tokens/Max input_id: 31771\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [13:18<03:06,  4.44s/it, loss=3.7418, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [13:21<02:49,  4.13s/it, loss=3.7415, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [13:26<02:52,  4.31s/it, loss=3.7414, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [13:30<02:44,  4.21s/it, loss=3.7401, tokens/Max input_id: 31790\n",
      "Max target_input: 31790\n",
      "Max label: 31790\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [13:34<02:34,  4.08s/it, loss=3.7392, tokens/Max input_id: 31794\n",
      "Max target_input: 31757\n",
      "Max label: 31757\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [13:36<02:10,  3.53s/it, loss=3.7387, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [13:40<02:06,  3.53s/it, loss=3.7388, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [13:42<01:48,  3.09s/it, loss=3.7370, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [13:44<01:36,  2.85s/it, loss=3.7371, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [13:48<01:48,  3.30s/it, loss=3.7366, tokens/Max input_id: 31771\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [13:51<01:43,  3.25s/it, loss=3.7357, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [13:54<01:37,  3.14s/it, loss=3.7350, tokens/Max input_id: 31762\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [13:58<01:35,  3.20s/it, loss=3.7350, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [14:01<01:32,  3.18s/it, loss=3.7340, tokens/Max input_id: 31794\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [14:03<01:24,  3.00s/it, loss=3.7329, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [14:06<01:18,  2.92s/it, loss=3.7328, tokens/Max input_id: 31772\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [14:09<01:18,  3.02s/it, loss=3.7336, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [14:12<01:10,  2.81s/it, loss=3.7325, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [14:15<01:08,  2.87s/it, loss=3.7299, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [14:16<00:58,  2.54s/it, loss=3.7279, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [14:18<00:51,  2.32s/it, loss=3.7266, tokens/Max input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [14:21<00:52,  2.52s/it, loss=3.7264, tokens/Max input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [14:23<00:46,  2.30s/it, loss=3.7250, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [14:28<00:56,  2.96s/it, loss=3.7241, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [14:34<01:11,  3.97s/it, loss=3.7237, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [14:36<00:57,  3.39s/it, loss=3.7226, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [14:43<01:10,  4.42s/it, loss=3.7224, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [14:45<00:57,  3.85s/it, loss=3.7230, tokens/Max input_id: 31797\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [14:51<01:01,  4.41s/it, loss=3.7246, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [14:54<00:50,  3.86s/it, loss=3.7240, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [14:58<00:49,  4.11s/it, loss=3.7235, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [15:02<00:42,  3.89s/it, loss=3.7240, tokens/Max input_id: 31801\n",
      "Max target_input: 31801\n",
      "Max label: 31801\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [15:04<00:35,  3.56s/it, loss=3.7236, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [15:07<00:29,  3.23s/it, loss=3.7234, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [15:11<00:27,  3.46s/it, loss=3.7240, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [15:13<00:22,  3.18s/it, loss=3.7231, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [15:16<00:18,  3.05s/it, loss=3.7226, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [15:18<00:14,  2.82s/it, loss=3.7217, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [15:21<00:11,  2.81s/it, loss=3.7208, tokens/Max input_id: 31782\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Training:  99%|█████████▉| 247/250 [15:25<00:09,  3.19s/it, loss=3.7222, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Training:  99%|█████████▉| 248/250 [15:29<00:06,  3.25s/it, loss=3.7220, tokens/Max input_id: 31800\n",
      "Max target_input: 31800\n",
      "Max label: 31800\n",
      "Training: 100%|█████████▉| 249/250 [15:31<00:02,  3.00s/it, loss=3.7227, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Training: 100%|██████████| 250/250 [15:48<00:00,  3.79s/it, loss=3.7233, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:07<03:41,  7.13s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:09<02:08,  4.29s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:10<01:25,  2.96s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:11<00:59,  2.12s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:12<00:47,  1.77s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:13<00:39,  1.52s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:14<00:32,  1.30s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:15<00:28,  1.19s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:16<00:28,  1.23s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:17<00:23,  1.07s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:18<00:22,  1.06s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:20<00:23,  1.19s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:21<00:22,  1.18s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:22<00:18,  1.05s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:22<00:16,  1.01it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:23<00:14,  1.10it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:24<00:14,  1.04it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:25<00:12,  1.08it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:26<00:11,  1.09it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:27<00:11,  1.07it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:28<00:09,  1.18it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:29<00:08,  1.14it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:30<00:08,  1.05it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:32<00:10,  1.27s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:33<00:08,  1.17s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:34<00:07,  1.21s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:35<00:05,  1.10s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:48<00:00,  1.51s/it]\n",
      "Removed old checkpoint: model_epoch_7.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_7.pt\n",
      "Saved training results to training_results_20250511_225213.csv\n",
      "Train Loss: 3.7233\n",
      "Val Loss: 4.5867\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: , the European?\n",
      "\n",
      "Epoch 8/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:09<40:51,  9.84s/it, loss=3.4404, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:14<27:28,  6.65s/it, loss=3.6133, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:16<18:51,  4.58s/it, loss=3.6542, tokens/s=Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:23<23:36,  5.76s/it, loss=3.6171, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:26<18:10,  4.45s/it, loss=3.6045, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:29<17:12,  4.23s/it, loss=3.5951, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:31<14:16,  3.52s/it, loss=3.5734, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:34<13:08,  3.26s/it, loss=3.5683, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:42<18:19,  4.56s/it, loss=3.5675, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:44<15:32,  3.89s/it, loss=3.5697, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:47<14:58,  3.76s/it, loss=3.5622, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:52<15:27,  3.90s/it, loss=3.5809, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:54<13:44,  3.48s/it, loss=3.5934, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:56<11:46,  2.99s/it, loss=3.5965, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [00:59<12:05,  3.09s/it, loss=3.5837, tokens/sMax input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [01:01<10:56,  2.80s/it, loss=3.5811, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [01:05<11:39,  3.00s/it, loss=3.5940, tokens/sMax input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:07<10:36,  2.74s/it, loss=3.5968, tokens/sMax input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:11<12:12,  3.17s/it, loss=3.5964, tokens/sMax input_id: 31773\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:20<18:09,  4.73s/it, loss=3.5957, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:22<15:23,  4.03s/it, loss=3.5920, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:25<14:05,  3.71s/it, loss=3.6074, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:27<12:19,  3.26s/it, loss=3.6022, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:30<11:57,  3.18s/it, loss=3.5992, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:34<12:50,  3.43s/it, loss=3.6058, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:42<17:52,  4.79s/it, loss=3.6127, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:45<15:19,  4.12s/it, loss=3.6143, tokens/sMax input_id: 31771\n",
      "Max target_input: 31806\n",
      "Max label: 31806\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [01:50<17:01,  4.60s/it, loss=3.6269, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [01:53<15:07,  4.10s/it, loss=3.6269, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [01:57<14:12,  3.88s/it, loss=3.6284, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [02:02<15:13,  4.17s/it, loss=3.6341, tokens/sMax input_id: 31764\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [02:09<18:34,  5.11s/it, loss=3.6310, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [02:12<16:18,  4.51s/it, loss=3.6343, tokens/sMax input_id: 31767\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:15<14:37,  4.06s/it, loss=3.6361, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:22<17:20,  4.84s/it, loss=3.6358, tokens/sMax input_id: 31766\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:25<15:09,  4.25s/it, loss=3.6355, tokens/sMax input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:28<14:06,  3.97s/it, loss=3.6334, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:30<12:12,  3.46s/it, loss=3.6290, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:35<14:03,  4.00s/it, loss=3.6265, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:41<15:46,  4.51s/it, loss=3.6216, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:45<15:05,  4.33s/it, loss=3.6137, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:48<14:02,  4.05s/it, loss=3.6113, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:53<14:10,  4.11s/it, loss=3.6158, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:55<12:20,  3.59s/it, loss=3.6111, tokens/sMax input_id: 31770\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [02:58<11:53,  3.48s/it, loss=3.6117, tokens/sMax input_id: 31769\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [03:02<11:44,  3.45s/it, loss=3.6120, tokens/sMax input_id: 31767\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [03:06<12:07,  3.58s/it, loss=3.6134, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [03:12<14:53,  4.42s/it, loss=3.6091, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [03:15<13:20,  3.98s/it, loss=3.6077, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [03:18<12:51,  3.86s/it, loss=3.6119, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [03:26<16:25,  4.95s/it, loss=3.6169, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:28<13:52,  4.21s/it, loss=3.6177, tokens/sMax input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:31<12:28,  3.80s/it, loss=3.6156, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:37<14:17,  4.37s/it, loss=3.6209, tokens/sMax input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:40<12:47,  3.93s/it, loss=3.6223, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:46<14:24,  4.46s/it, loss=3.6179, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:48<12:19,  3.83s/it, loss=3.6150, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:53<13:51,  4.33s/it, loss=3.6188, tokens/sMax input_id: 31764\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:55<11:36,  3.65s/it, loss=3.6187, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [04:00<12:21,  3.90s/it, loss=3.6179, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [04:06<14:04,  4.47s/it, loss=3.6157, tokens/sMax input_id: 31770\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [04:09<12:25,  3.97s/it, loss=3.6108, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [04:11<10:52,  3.49s/it, loss=3.6063, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [04:17<13:11,  4.26s/it, loss=3.6075, tokens/sMax input_id: 31767\n",
      "Max target_input: 31766\n",
      "Max label: 31766\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [04:20<11:35,  3.76s/it, loss=3.6047, tokens/sMax input_id: 31781\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [04:26<13:40,  4.46s/it, loss=3.6022, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [04:28<11:26,  3.75s/it, loss=3.6007, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [04:30<10:19,  3.40s/it, loss=3.5971, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [04:33<09:39,  3.20s/it, loss=3.5964, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [04:35<08:45,  2.92s/it, loss=3.5976, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:38<08:43,  2.93s/it, loss=3.5956, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:42<09:00,  3.04s/it, loss=3.5932, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:44<08:06,  2.75s/it, loss=3.5895, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:46<07:46,  2.65s/it, loss=3.5904, tokens/sMax input_id: 31767\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [04:48<07:10,  2.46s/it, loss=3.5884, tokens/sMax input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [04:52<08:06,  2.80s/it, loss=3.5889, tokens/sMax input_id: 31867\n",
      "Max target_input: 31867\n",
      "Max label: 31867\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [04:55<08:27,  2.93s/it, loss=3.5893, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [05:02<11:32,  4.03s/it, loss=3.5891, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [05:04<10:12,  3.58s/it, loss=3.5896, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [05:07<09:34,  3.38s/it, loss=3.5902, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [05:09<08:28,  3.01s/it, loss=3.5882, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [05:12<08:21,  2.98s/it, loss=3.5863, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [05:17<10:03,  3.62s/it, loss=3.5854, tokens/sMax input_id: 31794\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [05:24<13:02,  4.71s/it, loss=3.5835, tokens/sMax input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [05:27<11:16,  4.10s/it, loss=3.5823, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [05:30<09:51,  3.61s/it, loss=3.5775, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [05:31<08:24,  3.10s/it, loss=3.5749, tokens/sMax input_id: 31782\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [05:35<08:42,  3.23s/it, loss=3.5738, tokens/sMax input_id: 31789\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [05:42<11:45,  4.38s/it, loss=3.5772, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [05:44<09:51,  3.70s/it, loss=3.5761, tokens/sMax input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [05:47<09:18,  3.51s/it, loss=3.5758, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [05:50<08:40,  3.29s/it, loss=3.5739, tokens/sMax input_id: 31782\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [05:55<09:44,  3.72s/it, loss=3.5757, tokens/sMax input_id: 31761\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [05:56<08:03,  3.10s/it, loss=3.5717, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [06:01<08:57,  3.47s/it, loss=3.5743, tokens/sMax input_id: 31772\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [06:03<07:45,  3.02s/it, loss=3.5705, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [06:05<07:08,  2.80s/it, loss=3.5703, tokens/sMax input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [06:11<09:52,  3.90s/it, loss=3.5732, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [06:14<09:00,  3.58s/it, loss=3.5698, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [06:22<11:57,  4.78s/it, loss=3.5731, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [06:24<09:49,  3.96s/it, loss=3.5709, tokens/Max input_id: 31771\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [06:26<08:34,  3.48s/it, loss=3.5675, tokens/Max input_id: 31771\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [06:32<10:11,  4.16s/it, loss=3.5650, tokens/Max input_id: 31794\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [06:35<09:36,  3.95s/it, loss=3.5666, tokens/Max input_id: 31738\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [06:38<08:15,  3.42s/it, loss=3.5656, tokens/Max input_id: 31766\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [06:42<09:01,  3.76s/it, loss=3.5646, tokens/Max input_id: 31771\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [06:45<08:38,  3.63s/it, loss=3.5625, tokens/Max input_id: 31767\n",
      "Max target_input: 31825\n",
      "Max label: 31825\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [06:49<08:32,  3.61s/it, loss=3.5621, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [06:52<07:42,  3.28s/it, loss=3.5625, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [06:57<08:59,  3.86s/it, loss=3.5594, tokens/Max input_id: 31771\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [07:00<08:32,  3.69s/it, loss=3.5595, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [07:03<07:45,  3.37s/it, loss=3.5591, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [07:11<10:44,  4.71s/it, loss=3.5607, tokens/Max input_id: 31803\n",
      "Max target_input: 31803\n",
      "Max label: 31803\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [07:13<09:05,  4.01s/it, loss=3.5602, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [07:15<07:52,  3.50s/it, loss=3.5592, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [07:18<07:29,  3.35s/it, loss=3.5585, tokens/Max input_id: 31779\n",
      "Max target_input: 31779\n",
      "Max label: 31779\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [07:24<08:43,  3.94s/it, loss=3.5595, tokens/Max input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [07:31<11:11,  5.08s/it, loss=3.5605, tokens/Max input_id: 31764\n",
      "Max target_input: 31828\n",
      "Max label: 31828\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [07:34<09:46,  4.48s/it, loss=3.5627, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [07:36<08:07,  3.75s/it, loss=3.5622, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [07:39<07:17,  3.39s/it, loss=3.5639, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [07:42<06:47,  3.18s/it, loss=3.5660, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [07:45<07:05,  3.35s/it, loss=3.5650, tokens/Max input_id: 31782\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [07:48<06:21,  3.03s/it, loss=3.5631, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [07:51<06:29,  3.12s/it, loss=3.5625, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [07:55<07:07,  3.45s/it, loss=3.5627, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [07:57<06:06,  2.98s/it, loss=3.5619, tokens/Max input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [08:02<07:06,  3.50s/it, loss=3.5614, tokens/Max input_id: 31771\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [08:04<06:09,  3.05s/it, loss=3.5604, tokens/Max input_id: 31771\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [08:06<05:50,  2.92s/it, loss=3.5594, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [08:09<05:46,  2.91s/it, loss=3.5612, tokens/Max input_id: 31768\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [08:12<05:19,  2.71s/it, loss=3.5595, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [08:13<04:48,  2.47s/it, loss=3.5588, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [08:20<06:54,  3.58s/it, loss=3.5579, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [08:24<07:10,  3.75s/it, loss=3.5565, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [08:27<06:53,  3.63s/it, loss=3.5561, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [08:29<06:01,  3.20s/it, loss=3.5553, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [08:32<05:38,  3.02s/it, loss=3.5538, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [08:35<05:38,  3.05s/it, loss=3.5527, tokens/Max input_id: 31767\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [08:37<05:09,  2.81s/it, loss=3.5526, tokens/Max input_id: 31772\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [08:41<05:42,  3.15s/it, loss=3.5511, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [08:43<05:07,  2.85s/it, loss=3.5508, tokens/Max input_id: 31794\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [08:47<05:31,  3.09s/it, loss=3.5505, tokens/Max input_id: 31815\n",
      "Max target_input: 31815\n",
      "Max label: 31815\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [08:50<05:09,  2.92s/it, loss=3.5493, tokens/Max input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [08:56<06:53,  3.93s/it, loss=3.5493, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [08:58<06:07,  3.53s/it, loss=3.5484, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [09:00<05:12,  3.04s/it, loss=3.5459, tokens/Max input_id: 31768\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [09:03<04:47,  2.82s/it, loss=3.5466, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [09:06<04:50,  2.88s/it, loss=3.5459, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [09:12<06:35,  3.96s/it, loss=3.5457, tokens/Max input_id: 31794\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [09:15<06:03,  3.67s/it, loss=3.5463, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [09:19<06:10,  3.78s/it, loss=3.5462, tokens/Max input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [09:22<05:33,  3.43s/it, loss=3.5455, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [09:25<05:28,  3.43s/it, loss=3.5451, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [09:28<05:10,  3.27s/it, loss=3.5443, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [09:32<05:22,  3.43s/it, loss=3.5454, tokens/Max input_id: 31779\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [09:35<05:10,  3.34s/it, loss=3.5448, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [09:38<04:52,  3.18s/it, loss=3.5464, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [09:41<04:44,  3.12s/it, loss=3.5471, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [09:44<04:53,  3.27s/it, loss=3.5480, tokens/Max input_id: 31794\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [09:50<06:00,  4.04s/it, loss=3.5489, tokens/Max input_id: 31765\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [09:53<05:31,  3.77s/it, loss=3.5502, tokens/Max input_id: 31767\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [09:55<04:37,  3.19s/it, loss=3.5488, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [09:58<04:14,  2.96s/it, loss=3.5482, tokens/Max input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [10:04<05:34,  3.93s/it, loss=3.5489, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [10:09<05:49,  4.16s/it, loss=3.5490, tokens/Max input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [10:11<05:09,  3.73s/it, loss=3.5493, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [10:14<04:51,  3.55s/it, loss=3.5507, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [10:16<04:02,  2.99s/it, loss=3.5497, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [10:20<04:25,  3.32s/it, loss=3.5500, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [10:27<05:45,  4.37s/it, loss=3.5485, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [10:29<04:44,  3.64s/it, loss=3.5482, tokens/Max input_id: 31789\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [10:32<04:30,  3.51s/it, loss=3.5487, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [10:34<03:57,  3.12s/it, loss=3.5485, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [10:37<03:52,  3.10s/it, loss=3.5502, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [10:41<04:06,  3.33s/it, loss=3.5502, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [10:44<03:48,  3.13s/it, loss=3.5509, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [10:46<03:29,  2.91s/it, loss=3.5502, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [10:49<03:28,  2.94s/it, loss=3.5513, tokens/Max input_id: 31772\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [10:53<03:42,  3.18s/it, loss=3.5515, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [10:56<03:24,  2.97s/it, loss=3.5503, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [11:03<04:53,  4.32s/it, loss=3.5494, tokens/Max input_id: 31771\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [11:06<04:17,  3.85s/it, loss=3.5491, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [11:08<03:49,  3.48s/it, loss=3.5492, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [11:12<03:50,  3.54s/it, loss=3.5492, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [11:17<04:21,  4.09s/it, loss=3.5492, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [11:19<03:35,  3.42s/it, loss=3.5479, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [11:22<03:20,  3.23s/it, loss=3.5481, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [11:27<03:39,  3.60s/it, loss=3.5475, tokens/Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [11:34<04:40,  4.67s/it, loss=3.5473, tokens/Max input_id: 31800\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [11:37<04:06,  4.18s/it, loss=3.5472, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [11:39<03:36,  3.74s/it, loss=3.5461, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [11:42<03:17,  3.46s/it, loss=3.5461, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [11:48<03:53,  4.17s/it, loss=3.5464, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [11:50<03:15,  3.56s/it, loss=3.5458, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [11:53<03:00,  3.35s/it, loss=3.5456, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [11:55<02:41,  3.05s/it, loss=3.5450, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [11:59<02:46,  3.20s/it, loss=3.5436, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [12:05<03:18,  3.88s/it, loss=3.5432, tokens/Max input_id: 31794\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [12:10<03:37,  4.35s/it, loss=3.5425, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [12:16<03:59,  4.88s/it, loss=3.5434, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [12:22<04:13,  5.28s/it, loss=3.5442, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [12:25<03:32,  4.51s/it, loss=3.5433, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [12:29<03:14,  4.23s/it, loss=3.5433, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [12:33<03:18,  4.42s/it, loss=3.5442, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [12:37<02:57,  4.03s/it, loss=3.5442, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [12:40<02:41,  3.77s/it, loss=3.5444, tokens/Max input_id: 31771\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [12:42<02:20,  3.36s/it, loss=3.5443, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [12:45<02:18,  3.37s/it, loss=3.5442, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [12:51<02:37,  3.93s/it, loss=3.5441, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [12:55<02:32,  3.91s/it, loss=3.5429, tokens/Max input_id: 31790\n",
      "Max target_input: 31790\n",
      "Max label: 31790\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [12:59<02:33,  4.05s/it, loss=3.5420, tokens/Max input_id: 31794\n",
      "Max target_input: 31757\n",
      "Max label: 31757\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [13:01<02:08,  3.48s/it, loss=3.5414, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [13:05<02:05,  3.49s/it, loss=3.5415, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [13:07<01:46,  3.05s/it, loss=3.5399, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [13:09<01:41,  2.99s/it, loss=3.5402, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [13:14<01:52,  3.42s/it, loss=3.5396, tokens/Max input_id: 31771\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [13:17<01:44,  3.26s/it, loss=3.5388, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [13:21<01:45,  3.41s/it, loss=3.5379, tokens/Max input_id: 31762\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [13:24<01:39,  3.33s/it, loss=3.5379, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [13:28<01:44,  3.61s/it, loss=3.5372, tokens/Max input_id: 31794\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [13:31<01:33,  3.33s/it, loss=3.5358, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [13:33<01:25,  3.18s/it, loss=3.5359, tokens/Max input_id: 31772\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [13:39<01:42,  3.96s/it, loss=3.5364, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [13:42<01:26,  3.45s/it, loss=3.5351, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [13:44<01:13,  3.05s/it, loss=3.5327, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [13:45<01:00,  2.65s/it, loss=3.5308, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [13:47<00:52,  2.41s/it, loss=3.5295, tokens/Max input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [13:52<01:05,  3.10s/it, loss=3.5291, tokens/Max input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [13:54<00:55,  2.76s/it, loss=3.5275, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [13:59<01:07,  3.54s/it, loss=3.5267, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [14:04<01:11,  3.96s/it, loss=3.5261, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [14:06<00:57,  3.39s/it, loss=3.5249, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [14:15<01:18,  4.90s/it, loss=3.5244, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [14:17<01:02,  4.19s/it, loss=3.5249, tokens/Max input_id: 31797\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [14:23<01:05,  4.68s/it, loss=3.5266, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [14:26<00:52,  4.05s/it, loss=3.5261, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [14:29<00:47,  3.92s/it, loss=3.5255, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [14:34<00:45,  4.11s/it, loss=3.5261, tokens/Max input_id: 31801\n",
      "Max target_input: 31801\n",
      "Max label: 31801\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [14:37<00:37,  3.78s/it, loss=3.5255, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [14:39<00:30,  3.36s/it, loss=3.5253, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [14:42<00:26,  3.30s/it, loss=3.5260, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [14:45<00:21,  3.04s/it, loss=3.5249, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [14:48<00:19,  3.18s/it, loss=3.5242, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [14:51<00:14,  2.91s/it, loss=3.5233, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [14:53<00:11,  2.90s/it, loss=3.5223, tokens/Max input_id: 31782\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Training:  99%|█████████▉| 247/250 [14:57<00:09,  3.13s/it, loss=3.5235, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Training:  99%|█████████▉| 248/250 [15:00<00:05,  2.94s/it, loss=3.5234, tokens/Max input_id: 31800\n",
      "Max target_input: 31800\n",
      "Max label: 31800\n",
      "Training: 100%|█████████▉| 249/250 [15:02<00:02,  2.77s/it, loss=3.5240, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Training: 100%|██████████| 250/250 [15:20<00:00,  3.68s/it, loss=3.5248, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size:Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      " 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:07<03:41,  7.15s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:08<01:52,  3.75s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:10<01:30,  3.11s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:11<01:02,  2.22s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:12<00:49,  1.83s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:13<00:40,  1.56s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:14<00:33,  1.33s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:15<00:29,  1.23s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:16<00:28,  1.23s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:17<00:23,  1.08s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:18<00:22,  1.07s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:20<00:23,  1.19s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:21<00:22,  1.17s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:22<00:18,  1.04s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:22<00:16,  1.02it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:23<00:14,  1.09it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:24<00:14,  1.05it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:25<00:12,  1.10it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:26<00:11,  1.09it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:27<00:11,  1.06it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:28<00:09,  1.18it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:29<00:08,  1.12it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:30<00:09,  1.05s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:32<00:10,  1.26s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:33<00:08,  1.18s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:34<00:07,  1.25s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:35<00:05,  1.15s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:48<00:00,  1.53s/it]\n",
      "Saved checkpoint to checkpoints/model_epoch_8.pt\n",
      "Saved training results to training_results_20250511_230825.csv\n",
      "Train Loss: 3.5248\n",
      "Val Loss: 4.5827\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: , the European?\n",
      "\n",
      "Epoch 9/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size:Tokenizer vocab size: 32000\n",
      " Special tokens:\n",
      "32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [PAD] ID: 0  [EN] ID: 5\n",
      "\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:10<43:02, 10.37s/it, loss=3.2292, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:15<29:04,  7.03s/it, loss=3.4267, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:18<21:36,  5.25s/it, loss=3.4526, tokens/s=Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:25<24:09,  5.89s/it, loss=3.4053, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:26<18:11,  4.46s/it, loss=3.4085, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:31<17:46,  4.37s/it, loss=3.3992, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:33<14:42,  3.63s/it, loss=3.3725, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:37<15:54,  3.95s/it, loss=3.3667, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:43<17:55,  4.46s/it, loss=3.3677, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:45<15:08,  3.79s/it, loss=3.3603, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:48<14:04,  3.53s/it, loss=3.3533, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:52<14:32,  3.67s/it, loss=3.3718, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [00:56<14:20,  3.63s/it, loss=3.3857, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [00:58<12:07,  3.08s/it, loss=3.3897, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [00:59<10:41,  2.73s/it, loss=3.3773, tokens/sMax input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [01:01<09:33,  2.45s/it, loss=3.3741, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [01:04<09:37,  2.48s/it, loss=3.3880, tokens/sMax input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:07<09:57,  2.58s/it, loss=3.3892, tokens/sMax input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:10<10:53,  2.83s/it, loss=3.3890, tokens/sMax input_id: 31773\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:16<14:42,  3.84s/it, loss=3.3904, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:19<12:51,  3.37s/it, loss=3.3893, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:22<13:19,  3.51s/it, loss=3.4025, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:25<11:45,  3.11s/it, loss=3.3960, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:28<12:08,  3.22s/it, loss=3.3925, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:33<13:49,  3.69s/it, loss=3.3987, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:39<16:52,  4.52s/it, loss=3.4045, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [01:43<16:03,  4.32s/it, loss=3.4058, tokens/sMax input_id: 31771\n",
      "Max target_input: 31806\n",
      "Max label: 31806\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [01:50<18:20,  4.96s/it, loss=3.4181, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [01:52<15:57,  4.33s/it, loss=3.4175, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [01:55<13:36,  3.71s/it, loss=3.4190, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [01:58<12:42,  3.48s/it, loss=3.4274, tokens/sMax input_id: 31764\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [02:06<17:35,  4.84s/it, loss=3.4239, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [02:09<15:22,  4.25s/it, loss=3.4266, tokens/sMax input_id: 31767\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:11<13:44,  3.82s/it, loss=3.4299, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:15<13:02,  3.64s/it, loss=3.4321, tokens/sMax input_id: 31766\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:17<11:39,  3.27s/it, loss=3.4304, tokens/sMax input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:21<12:18,  3.47s/it, loss=3.4293, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:23<10:46,  3.05s/it, loss=3.4277, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:27<12:10,  3.46s/it, loss=3.4254, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:30<11:16,  3.22s/it, loss=3.4205, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:33<10:43,  3.08s/it, loss=3.4137, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [02:37<11:24,  3.29s/it, loss=3.4119, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [02:40<11:32,  3.35s/it, loss=3.4180, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [02:42<10:32,  3.07s/it, loss=3.4139, tokens/sMax input_id: 31770\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [02:45<10:22,  3.04s/it, loss=3.4149, tokens/sMax input_id: 31769\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [02:48<09:36,  2.82s/it, loss=3.4167, tokens/sMax input_id: 31767\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [02:51<10:17,  3.04s/it, loss=3.4175, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [02:58<13:36,  4.04s/it, loss=3.4119, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [03:01<12:29,  3.73s/it, loss=3.4117, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [03:04<11:53,  3.57s/it, loss=3.4161, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [03:09<13:47,  4.16s/it, loss=3.4201, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:13<13:04,  3.96s/it, loss=3.4194, tokens/sMax input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:16<12:27,  3.80s/it, loss=3.4167, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [03:22<14:12,  4.35s/it, loss=3.4230, tokens/sMax input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [03:25<12:43,  3.92s/it, loss=3.4256, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [03:28<11:43,  3.63s/it, loss=3.4211, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [03:31<11:18,  3.52s/it, loss=3.4183, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [03:37<13:26,  4.20s/it, loss=3.4226, tokens/sMax input_id: 31764\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [03:39<11:19,  3.56s/it, loss=3.4230, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [03:42<11:00,  3.48s/it, loss=3.4218, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [03:45<10:41,  3.39s/it, loss=3.4197, tokens/sMax input_id: 31770\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [03:49<10:48,  3.45s/it, loss=3.4142, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [03:51<09:43,  3.12s/it, loss=3.4099, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [03:57<12:06,  3.91s/it, loss=3.4104, tokens/sMax input_id: 31767\n",
      "Max target_input: 31766\n",
      "Max label: 31766\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [04:00<10:51,  3.52s/it, loss=3.4063, tokens/sMax input_id: 31781\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [04:03<10:30,  3.43s/it, loss=3.4036, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [04:06<10:08,  3.33s/it, loss=3.4016, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [04:09<09:26,  3.11s/it, loss=3.3981, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [04:11<09:08,  3.03s/it, loss=3.3966, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [04:14<08:27,  2.82s/it, loss=3.3977, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [04:17<08:39,  2.90s/it, loss=3.3951, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [04:20<08:51,  2.98s/it, loss=3.3925, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [04:22<08:01,  2.72s/it, loss=3.3887, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [04:24<07:36,  2.60s/it, loss=3.3885, tokens/sMax input_id: 31767\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [04:27<07:04,  2.42s/it, loss=3.3867, tokens/sMax input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [04:30<07:31,  2.60s/it, loss=3.3873, tokens/sMax input_id: 31867\n",
      "Max target_input: 31867\n",
      "Max label: 31867\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [04:33<08:11,  2.84s/it, loss=3.3871, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [04:37<09:13,  3.22s/it, loss=3.3867, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [04:39<08:31,  2.99s/it, loss=3.3877, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [04:43<08:32,  3.01s/it, loss=3.3882, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [04:45<07:47,  2.76s/it, loss=3.3856, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [04:49<09:01,  3.22s/it, loss=3.3837, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [04:53<09:36,  3.45s/it, loss=3.3834, tokens/sMax input_id: 31794\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [05:00<12:05,  4.37s/it, loss=3.3813, tokens/sMax input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [05:02<10:38,  3.87s/it, loss=3.3797, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [05:05<09:20,  3.42s/it, loss=3.3752, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [05:08<08:52,  3.27s/it, loss=3.3724, tokens/sMax input_id: 31782\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [05:10<08:16,  3.06s/it, loss=3.3715, tokens/sMax input_id: 31789\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [05:18<11:45,  4.38s/it, loss=3.3748, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [05:20<09:57,  3.74s/it, loss=3.3733, tokens/sMax input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [05:23<09:39,  3.64s/it, loss=3.3728, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [05:27<09:41,  3.68s/it, loss=3.3718, tokens/sMax input_id: 31782\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [05:31<10:02,  3.84s/it, loss=3.3735, tokens/sMax input_id: 31761\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [05:33<08:14,  3.17s/it, loss=3.3699, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [05:36<08:06,  3.14s/it, loss=3.3730, tokens/sMax input_id: 31772\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [05:38<07:16,  2.84s/it, loss=3.3692, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [05:41<07:31,  2.95s/it, loss=3.3698, tokens/sMax input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [05:46<09:00,  3.56s/it, loss=3.3727, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [05:49<08:05,  3.21s/it, loss=3.3698, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [05:56<10:51,  4.34s/it, loss=3.3726, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [05:58<09:00,  3.63s/it, loss=3.3702, tokens/Max input_id: 31771\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [06:01<08:44,  3.54s/it, loss=3.3682, tokens/Max input_id: 31771\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [06:04<08:39,  3.54s/it, loss=3.3664, tokens/Max input_id: 31794\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [06:08<08:23,  3.45s/it, loss=3.3685, tokens/Max input_id: 31738\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [06:10<07:23,  3.06s/it, loss=3.3676, tokens/Max input_id: 31766\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [06:14<08:07,  3.38s/it, loss=3.3667, tokens/Max input_id: 31771\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [06:18<08:18,  3.49s/it, loss=3.3649, tokens/Max input_id: 31767\n",
      "Max target_input: 31825\n",
      "Max label: 31825\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [06:20<07:33,  3.19s/it, loss=3.3646, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [06:22<06:52,  2.92s/it, loss=3.3651, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [06:28<08:25,  3.61s/it, loss=3.3632, tokens/Max input_id: 31771\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [06:31<08:18,  3.59s/it, loss=3.3637, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [06:35<08:14,  3.58s/it, loss=3.3628, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [06:42<10:42,  4.69s/it, loss=3.3645, tokens/Max input_id: 31803\n",
      "Max target_input: 31803\n",
      "Max label: 31803\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [06:45<09:09,  4.04s/it, loss=3.3645, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [06:47<07:54,  3.51s/it, loss=3.3640, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [06:50<07:41,  3.44s/it, loss=3.3629, tokens/Max input_id: 31779\n",
      "Max target_input: 31779\n",
      "Max label: 31779\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [06:58<10:35,  4.78s/it, loss=3.3642, tokens/Max input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [07:05<11:50,  5.38s/it, loss=3.3654, tokens/Max input_id: 31764\n",
      "Max target_input: 31828\n",
      "Max label: 31828\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [07:08<10:16,  4.71s/it, loss=3.3682, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [07:10<08:31,  3.93s/it, loss=3.3682, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [07:13<07:32,  3.51s/it, loss=3.3704, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [07:16<07:38,  3.59s/it, loss=3.3731, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [07:20<07:55,  3.74s/it, loss=3.3726, tokens/Max input_id: 31782\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [07:23<06:49,  3.25s/it, loss=3.3710, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [07:27<07:23,  3.55s/it, loss=3.3713, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [07:31<07:52,  3.81s/it, loss=3.3714, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [07:33<06:39,  3.25s/it, loss=3.3712, tokens/Max input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [07:37<06:42,  3.30s/it, loss=3.3712, tokens/Max input_id: 31771\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [07:39<05:53,  2.92s/it, loss=3.3699, tokens/Max input_id: 31771\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [07:41<05:35,  2.79s/it, loss=3.3693, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [07:45<06:10,  3.12s/it, loss=3.3714, tokens/Max input_id: 31768\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [07:47<05:40,  2.89s/it, loss=3.3700, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [07:49<05:10,  2.65s/it, loss=3.3696, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [07:55<06:59,  3.62s/it, loss=3.3687, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [08:02<08:27,  4.42s/it, loss=3.3680, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [08:05<07:54,  4.16s/it, loss=3.3677, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [08:07<06:47,  3.61s/it, loss=3.3676, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [08:10<06:11,  3.32s/it, loss=3.3667, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [08:13<06:00,  3.24s/it, loss=3.3656, tokens/Max input_id: 31767\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [08:16<05:29,  3.00s/it, loss=3.3657, tokens/Max input_id: 31772\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [08:19<05:54,  3.26s/it, loss=3.3646, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [08:23<05:45,  3.20s/it, loss=3.3643, tokens/Max input_id: 31794\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [08:27<06:15,  3.51s/it, loss=3.3643, tokens/Max input_id: 31815\n",
      "Max target_input: 31815\n",
      "Max label: 31815\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [08:29<05:45,  3.26s/it, loss=3.3632, tokens/Max input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [08:35<06:43,  3.84s/it, loss=3.3636, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [08:38<06:28,  3.74s/it, loss=3.3629, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [08:40<05:28,  3.19s/it, loss=3.3605, tokens/Max input_id: 31768\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [08:43<05:10,  3.04s/it, loss=3.3607, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [08:47<05:47,  3.44s/it, loss=3.3600, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [08:54<07:19,  4.40s/it, loss=3.3596, tokens/Max input_id: 31794\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [08:57<06:35,  4.00s/it, loss=3.3607, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [09:01<06:37,  4.06s/it, loss=3.3606, tokens/Max input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [09:04<05:50,  3.62s/it, loss=3.3602, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [09:10<07:05,  4.43s/it, loss=3.3599, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [09:12<05:53,  3.72s/it, loss=3.3596, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [09:16<05:44,  3.67s/it, loss=3.3608, tokens/Max input_id: 31779\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [09:18<05:20,  3.44s/it, loss=3.3594, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [09:22<05:23,  3.51s/it, loss=3.3610, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [09:27<05:49,  3.84s/it, loss=3.3616, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [09:30<05:22,  3.58s/it, loss=3.3624, tokens/Max input_id: 31794\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [09:35<06:05,  4.11s/it, loss=3.3633, tokens/Max input_id: 31765\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [09:39<06:09,  4.20s/it, loss=3.3644, tokens/Max input_id: 31767\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [09:41<05:08,  3.54s/it, loss=3.3627, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [09:45<04:57,  3.46s/it, loss=3.3621, tokens/Max input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [09:50<05:36,  3.96s/it, loss=3.3625, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [09:57<06:56,  4.96s/it, loss=3.3624, tokens/Max input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [10:01<06:35,  4.77s/it, loss=3.3630, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [10:07<06:50,  5.00s/it, loss=3.3641, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [10:11<06:15,  4.63s/it, loss=3.3627, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [10:15<06:06,  4.59s/it, loss=3.3627, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [10:23<07:21,  5.58s/it, loss=3.3610, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [10:25<05:50,  4.49s/it, loss=3.3608, tokens/Max input_id: 31789\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [10:32<06:31,  5.09s/it, loss=3.3614, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [10:34<05:22,  4.24s/it, loss=3.3611, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [10:36<04:26,  3.56s/it, loss=3.3626, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [10:42<05:17,  4.29s/it, loss=3.3624, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [10:44<04:35,  3.77s/it, loss=3.3630, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [10:47<04:01,  3.36s/it, loss=3.3623, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [10:49<03:42,  3.13s/it, loss=3.3631, tokens/Max input_id: 31772\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [10:53<03:44,  3.20s/it, loss=3.3635, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [10:55<03:21,  2.92s/it, loss=3.3622, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [11:02<04:39,  4.12s/it, loss=3.3610, tokens/Max input_id: 31771\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [11:04<04:03,  3.64s/it, loss=3.3604, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [11:08<03:52,  3.53s/it, loss=3.3602, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [11:10<03:27,  3.19s/it, loss=3.3603, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [11:13<03:24,  3.19s/it, loss=3.3605, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [11:16<03:09,  3.00s/it, loss=3.3589, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [11:18<02:56,  2.85s/it, loss=3.3589, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [11:22<03:03,  3.01s/it, loss=3.3581, tokens/Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [11:28<04:02,  4.05s/it, loss=3.3580, tokens/Max input_id: 31800\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [11:33<04:10,  4.24s/it, loss=3.3577, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [11:36<03:39,  3.79s/it, loss=3.3562, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [11:38<03:19,  3.49s/it, loss=3.3561, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [11:42<03:14,  3.46s/it, loss=3.3564, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [11:45<03:03,  3.34s/it, loss=3.3560, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [11:48<02:51,  3.17s/it, loss=3.3559, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [11:50<02:36,  2.96s/it, loss=3.3551, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [11:53<02:38,  3.05s/it, loss=3.3541, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [11:57<02:48,  3.31s/it, loss=3.3536, tokens/Max input_id: 31794\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [12:03<03:19,  3.99s/it, loss=3.3529, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [12:09<03:42,  4.53s/it, loss=3.3539, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [12:14<03:52,  4.85s/it, loss=3.3546, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [12:18<03:33,  4.55s/it, loss=3.3537, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [12:21<03:04,  4.01s/it, loss=3.3535, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [12:25<03:04,  4.09s/it, loss=3.3547, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [12:28<02:49,  3.85s/it, loss=3.3547, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [12:33<02:55,  4.07s/it, loss=3.3551, tokens/Max input_id: 31771\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [12:35<02:28,  3.54s/it, loss=3.3551, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [12:38<02:12,  3.22s/it, loss=3.3552, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [12:42<02:24,  3.60s/it, loss=3.3549, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [12:47<02:32,  3.92s/it, loss=3.3539, tokens/Max input_id: 31790\n",
      "Max target_input: 31790\n",
      "Max label: 31790\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [12:52<02:40,  4.23s/it, loss=3.3533, tokens/Max input_id: 31794\n",
      "Max target_input: 31757\n",
      "Max label: 31757\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [12:54<02:14,  3.63s/it, loss=3.3525, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [12:57<01:58,  3.28s/it, loss=3.3526, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [13:00<01:50,  3.17s/it, loss=3.3511, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [13:02<01:40,  2.95s/it, loss=3.3512, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [13:06<01:51,  3.37s/it, loss=3.3510, tokens/Max input_id: 31771\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [13:09<01:44,  3.27s/it, loss=3.3500, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [13:13<01:47,  3.46s/it, loss=3.3489, tokens/Max input_id: 31762\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [13:16<01:37,  3.24s/it, loss=3.3490, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [13:19<01:35,  3.29s/it, loss=3.3482, tokens/Max input_id: 31794\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [13:22<01:26,  3.11s/it, loss=3.3468, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [13:26<01:28,  3.28s/it, loss=3.3465, tokens/Max input_id: 31772\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [13:30<01:33,  3.61s/it, loss=3.3471, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [13:33<01:20,  3.23s/it, loss=3.3460, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [13:35<01:09,  2.91s/it, loss=3.3434, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [13:37<01:04,  2.82s/it, loss=3.3418, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [13:39<00:56,  2.56s/it, loss=3.3405, tokens/Max input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [13:43<01:00,  2.88s/it, loss=3.3403, tokens/Max input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [13:45<00:51,  2.57s/it, loss=3.3389, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [13:50<01:06,  3.50s/it, loss=3.3380, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [13:56<01:14,  4.14s/it, loss=3.3373, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [13:58<00:59,  3.52s/it, loss=3.3364, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [14:05<01:11,  4.45s/it, loss=3.3358, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [14:08<01:03,  4.21s/it, loss=3.3365, tokens/Max input_id: 31797\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [14:15<01:09,  4.93s/it, loss=3.3383, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [14:18<00:55,  4.24s/it, loss=3.3381, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [14:21<00:47,  3.99s/it, loss=3.3376, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [14:25<00:44,  4.02s/it, loss=3.3380, tokens/Max input_id: 31801\n",
      "Max target_input: 31801\n",
      "Max label: 31801\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [14:29<00:39,  3.94s/it, loss=3.3375, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [14:31<00:31,  3.48s/it, loss=3.3375, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [14:34<00:27,  3.38s/it, loss=3.3384, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [14:38<00:23,  3.35s/it, loss=3.3374, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [14:41<00:19,  3.26s/it, loss=3.3369, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [14:43<00:15,  3.07s/it, loss=3.3362, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [14:46<00:12,  3.09s/it, loss=3.3354, tokens/Max input_id: 31782\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Training:  99%|█████████▉| 247/250 [14:52<00:11,  3.94s/it, loss=3.3368, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Training:  99%|█████████▉| 248/250 [14:55<00:07,  3.62s/it, loss=3.3367, tokens/Max input_id: 31800\n",
      "Max target_input: 31800\n",
      "Max label: 31800\n",
      "Training: 100%|█████████▉| 249/250 [14:58<00:03,  3.37s/it, loss=3.3371, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Training: 100%|██████████| 250/250 [15:18<00:00,  3.67s/it, loss=3.3382, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size:Tokenizer vocab size: 32000 32000\n",
      "Special tokens:\n",
      "\n",
      "  [PAD] ID: 0Special tokens:\n",
      "\n",
      "  [UNK] ID: 1\n",
      "  [PAD] ID: 0  [BOS] ID: 2\n",
      "\n",
      "  [UNK] ID: 1  [EOS] ID: 3\n",
      "\n",
      "  [BOS] ID: 2  [DE] ID: 4\n",
      "\n",
      "  [EOS] ID: 3  [EN] ID: 5\n",
      "\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size:Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      " 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:08<04:13,  8.16s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:09<02:05,  4.18s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:11<01:34,  3.26s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:12<01:05,  2.33s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:13<00:51,  1.91s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:14<00:42,  1.64s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:15<00:35,  1.40s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:16<00:30,  1.26s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:18<00:35,  1.53s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:19<00:28,  1.30s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:20<00:25,  1.21s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:21<00:21,  1.06s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:22<00:20,  1.10s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:23<00:17,  1.00it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:24<00:16,  1.04it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:24<00:14,  1.12it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:26<00:18,  1.20s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:27<00:15,  1.12s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:28<00:13,  1.08s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:29<00:12,  1.04s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:30<00:10,  1.08it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:31<00:09,  1.06it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:33<00:11,  1.24s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:34<00:10,  1.31s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:35<00:08,  1.28s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:37<00:08,  1.36s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:38<00:06,  1.24s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:52<00:00,  1.64s/it]\n",
      "Saved checkpoint to checkpoints/model_epoch_9.pt\n",
      "Saved training results to training_results_20250511_232438.csv\n",
      "Train Loss: 3.3382\n",
      "Val Loss: 4.6190\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: , if?\n",
      "\n",
      "Epoch 10/10\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]                               Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   0%|          | 1/250 [00:10<42:53, 10.33s/it, loss=3.0791, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 2/250 [00:16<33:19,  8.06s/it, loss=3.2366, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   1%|          | 3/250 [00:18<22:00,  5.35s/it, loss=3.2410, tokens/s=Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 4/250 [00:25<23:29,  5.73s/it, loss=3.1967, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 5/250 [00:27<18:00,  4.41s/it, loss=3.1980, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   2%|▏         | 6/250 [00:33<20:17,  4.99s/it, loss=3.1894, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 7/250 [00:35<16:44,  4.14s/it, loss=3.1625, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   3%|▎         | 8/250 [00:38<15:24,  3.82s/it, loss=3.1587, tokens/s=Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▎         | 9/250 [00:44<17:38,  4.39s/it, loss=3.1660, tokens/s=Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 10/250 [00:46<14:59,  3.75s/it, loss=3.1599, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   4%|▍         | 11/250 [00:52<17:31,  4.40s/it, loss=3.1522, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▍         | 12/250 [00:59<20:40,  5.21s/it, loss=3.1761, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   5%|▌         | 13/250 [01:03<18:33,  4.70s/it, loss=3.1880, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 14/250 [01:05<15:07,  3.85s/it, loss=3.1916, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▌         | 15/250 [01:07<13:00,  3.32s/it, loss=3.1779, tokens/sMax input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   6%|▋         | 16/250 [01:10<12:21,  3.17s/it, loss=3.1785, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 17/250 [01:14<13:10,  3.39s/it, loss=3.1949, tokens/sMax input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   7%|▋         | 18/250 [01:16<11:50,  3.06s/it, loss=3.1963, tokens/sMax input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 19/250 [01:20<13:29,  3.51s/it, loss=3.1995, tokens/sMax input_id: 31773\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 20/250 [01:29<19:13,  5.01s/it, loss=3.2030, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   8%|▊         | 21/250 [01:31<16:07,  4.22s/it, loss=3.2002, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 22/250 [01:35<14:54,  3.92s/it, loss=3.2158, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:   9%|▉         | 23/250 [01:38<14:05,  3.73s/it, loss=3.2103, tokens/sMax input_id: 31764\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|▉         | 24/250 [01:43<15:22,  4.08s/it, loss=3.2073, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 25/250 [01:50<18:51,  5.03s/it, loss=3.2118, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  10%|█         | 26/250 [01:59<23:13,  6.22s/it, loss=3.2208, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 27/250 [02:02<19:19,  5.20s/it, loss=3.2216, tokens/sMax input_id: 31771\n",
      "Max target_input: 31806\n",
      "Max label: 31806\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  11%|█         | 28/250 [02:09<21:24,  5.79s/it, loss=3.2359, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 29/250 [02:14<20:14,  5.50s/it, loss=3.2372, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 30/250 [02:16<16:35,  4.53s/it, loss=3.2383, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  12%|█▏        | 31/250 [02:21<16:37,  4.55s/it, loss=3.2463, tokens/sMax input_id: 31764\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 32/250 [02:28<19:24,  5.34s/it, loss=3.2433, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  13%|█▎        | 33/250 [02:31<16:42,  4.62s/it, loss=3.2475, tokens/sMax input_id: 31767\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▎        | 34/250 [02:33<14:33,  4.04s/it, loss=3.2521, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 35/250 [02:38<15:04,  4.21s/it, loss=3.2545, tokens/sMax input_id: 31766\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  14%|█▍        | 36/250 [02:41<13:16,  3.72s/it, loss=3.2539, tokens/sMax input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▍        | 37/250 [02:44<13:14,  3.73s/it, loss=3.2528, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  15%|█▌        | 38/250 [02:46<11:26,  3.24s/it, loss=3.2508, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 39/250 [02:52<13:34,  3.86s/it, loss=3.2468, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▌        | 40/250 [02:55<12:22,  3.53s/it, loss=3.2413, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  16%|█▋        | 41/250 [02:58<12:32,  3.60s/it, loss=3.2337, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 42/250 [03:03<13:20,  3.85s/it, loss=3.2316, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  17%|█▋        | 43/250 [03:08<15:15,  4.42s/it, loss=3.2378, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 44/250 [03:11<13:26,  3.91s/it, loss=3.2347, tokens/sMax input_id: 31770\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 45/250 [03:16<14:08,  4.14s/it, loss=3.2363, tokens/sMax input_id: 31769\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  18%|█▊        | 46/250 [03:18<12:30,  3.68s/it, loss=3.2374, tokens/sMax input_id: 31767\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 47/250 [03:22<12:36,  3.73s/it, loss=3.2375, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  19%|█▉        | 48/250 [03:31<17:21,  5.16s/it, loss=3.2319, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|█▉        | 49/250 [03:34<15:41,  4.69s/it, loss=3.2319, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 50/250 [03:38<14:52,  4.46s/it, loss=3.2342, tokens/sMax input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  20%|██        | 51/250 [03:46<18:06,  5.46s/it, loss=3.2388, tokens/sMax input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 52/250 [03:49<15:13,  4.62s/it, loss=3.2370, tokens/sMax input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  21%|██        | 53/250 [03:53<14:58,  4.56s/it, loss=3.2341, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 54/250 [04:00<16:51,  5.16s/it, loss=3.2394, tokens/sMax input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 55/250 [04:06<18:09,  5.59s/it, loss=3.2411, tokens/sMax input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  22%|██▏       | 56/250 [04:11<16:57,  5.25s/it, loss=3.2371, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 57/250 [04:13<14:20,  4.46s/it, loss=3.2340, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  23%|██▎       | 58/250 [04:21<17:27,  5.45s/it, loss=3.2382, tokens/sMax input_id: 31764\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▎       | 59/250 [04:24<15:10,  4.76s/it, loss=3.2386, tokens/sMax input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 60/250 [04:29<15:24,  4.86s/it, loss=3.2377, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  24%|██▍       | 61/250 [04:35<16:07,  5.12s/it, loss=3.2362, tokens/sMax input_id: 31770\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▍       | 62/250 [04:39<14:49,  4.73s/it, loss=3.2309, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  25%|██▌       | 63/250 [04:43<13:45,  4.42s/it, loss=3.2271, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 64/250 [04:50<16:29,  5.32s/it, loss=3.2273, tokens/sMax input_id: 31767\n",
      "Max target_input: 31766\n",
      "Max label: 31766\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▌       | 65/250 [04:54<15:06,  4.90s/it, loss=3.2228, tokens/sMax input_id: 31781\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  26%|██▋       | 66/250 [05:00<15:37,  5.09s/it, loss=3.2206, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 67/250 [05:02<12:55,  4.24s/it, loss=3.2185, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  27%|██▋       | 68/250 [05:05<12:20,  4.07s/it, loss=3.2152, tokens/sMax input_id: 31776\n",
      "Max target_input: 31776\n",
      "Max label: 31776\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 69/250 [05:09<11:35,  3.84s/it, loss=3.2144, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 70/250 [05:11<10:28,  3.49s/it, loss=3.2163, tokens/sMax input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  28%|██▊       | 71/250 [05:17<11:59,  4.02s/it, loss=3.2132, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 72/250 [05:19<10:37,  3.58s/it, loss=3.2100, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  29%|██▉       | 73/250 [05:21<09:19,  3.16s/it, loss=3.2062, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|██▉       | 74/250 [05:24<08:37,  2.94s/it, loss=3.2070, tokens/sMax input_id: 31767\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 75/250 [05:27<08:41,  2.98s/it, loss=3.2050, tokens/sMax input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  30%|███       | 76/250 [05:31<09:50,  3.39s/it, loss=3.2057, tokens/sMax input_id: 31867\n",
      "Max target_input: 31867\n",
      "Max label: 31867\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 77/250 [05:36<11:06,  3.85s/it, loss=3.2056, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  31%|███       | 78/250 [05:41<12:00,  4.19s/it, loss=3.2052, tokens/sMax input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 79/250 [05:45<11:28,  4.03s/it, loss=3.2061, tokens/sMax input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 80/250 [05:49<11:48,  4.17s/it, loss=3.2063, tokens/sMax input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  32%|███▏      | 81/250 [05:52<10:03,  3.57s/it, loss=3.2035, tokens/sMax input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 82/250 [05:56<10:37,  3.79s/it, loss=3.2017, tokens/sMax input_id: 31771\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  33%|███▎      | 83/250 [06:01<11:54,  4.28s/it, loss=3.2012, tokens/sMax input_id: 31794\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▎      | 84/250 [06:10<15:29,  5.60s/it, loss=3.1989, tokens/sMax input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 85/250 [06:13<13:11,  4.79s/it, loss=3.1983, tokens/sMax input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  34%|███▍      | 86/250 [06:15<11:12,  4.10s/it, loss=3.1938, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▍      | 87/250 [06:18<10:07,  3.73s/it, loss=3.1910, tokens/sMax input_id: 31782\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  35%|███▌      | 88/250 [06:21<09:02,  3.35s/it, loss=3.1891, tokens/sMax input_id: 31789\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 89/250 [06:28<12:04,  4.50s/it, loss=3.1923, tokens/sMax input_id: 31794\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▌      | 90/250 [06:30<10:02,  3.77s/it, loss=3.1907, tokens/sMax input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  36%|███▋      | 91/250 [06:33<09:31,  3.59s/it, loss=3.1903, tokens/sMax input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 92/250 [06:37<09:37,  3.66s/it, loss=3.1886, tokens/sMax input_id: 31782\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  37%|███▋      | 93/250 [06:40<09:18,  3.56s/it, loss=3.1898, tokens/sMax input_id: 31761\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 94/250 [06:42<07:44,  2.98s/it, loss=3.1854, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 95/250 [06:45<07:43,  2.99s/it, loss=3.1885, tokens/sMax input_id: 31772\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  38%|███▊      | 96/250 [06:47<06:58,  2.72s/it, loss=3.1843, tokens/sMax input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 97/250 [06:50<07:16,  2.85s/it, loss=3.1842, tokens/sMax input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  39%|███▉      | 98/250 [06:54<08:06,  3.20s/it, loss=3.1872, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|███▉      | 99/250 [06:57<07:25,  2.95s/it, loss=3.1842, tokens/sMax input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 100/250 [07:03<10:14,  4.09s/it, loss=3.1876, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  40%|████      | 101/250 [07:06<09:19,  3.75s/it, loss=3.1854, tokens/Max input_id: 31771\n",
      "Max target_input: 31769\n",
      "Max label: 31769\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 102/250 [07:09<08:19,  3.38s/it, loss=3.1834, tokens/Max input_id: 31771\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  41%|████      | 103/250 [07:12<08:09,  3.33s/it, loss=3.1818, tokens/Max input_id: 31794\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 104/250 [07:16<08:31,  3.50s/it, loss=3.1837, tokens/Max input_id: 31738\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 105/250 [07:18<07:30,  3.11s/it, loss=3.1827, tokens/Max input_id: 31766\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  42%|████▏     | 106/250 [07:24<09:12,  3.84s/it, loss=3.1815, tokens/Max input_id: 31771\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 107/250 [07:27<08:32,  3.58s/it, loss=3.1805, tokens/Max input_id: 31767\n",
      "Max target_input: 31825\n",
      "Max label: 31825\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  43%|████▎     | 108/250 [07:29<07:44,  3.27s/it, loss=3.1808, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▎     | 109/250 [07:33<07:49,  3.33s/it, loss=3.1814, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 110/250 [07:39<10:10,  4.36s/it, loss=3.1787, tokens/Max input_id: 31771\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  44%|████▍     | 111/250 [07:45<11:15,  4.86s/it, loss=3.1793, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▍     | 112/250 [07:50<11:10,  4.86s/it, loss=3.1787, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  45%|████▌     | 113/250 [07:58<12:58,  5.68s/it, loss=3.1803, tokens/Max input_id: 31803\n",
      "Max target_input: 31803\n",
      "Max label: 31803\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 114/250 [08:02<11:37,  5.13s/it, loss=3.1799, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▌     | 115/250 [08:04<09:43,  4.33s/it, loss=3.1790, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  46%|████▋     | 116/250 [08:09<10:15,  4.59s/it, loss=3.1779, tokens/Max input_id: 31779\n",
      "Max target_input: 31779\n",
      "Max label: 31779\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 117/250 [08:18<12:46,  5.76s/it, loss=3.1787, tokens/Max input_id: 31771\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  47%|████▋     | 118/250 [08:25<13:45,  6.25s/it, loss=3.1796, tokens/Max input_id: 31764\n",
      "Max target_input: 31828\n",
      "Max label: 31828\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 119/250 [08:29<11:52,  5.44s/it, loss=3.1825, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 120/250 [08:32<10:19,  4.76s/it, loss=3.1828, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  48%|████▊     | 121/250 [08:35<09:05,  4.23s/it, loss=3.1852, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 122/250 [08:39<08:44,  4.09s/it, loss=3.1879, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  49%|████▉     | 123/250 [08:42<08:01,  3.79s/it, loss=3.1867, tokens/Max input_id: 31782\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|████▉     | 124/250 [08:45<07:27,  3.55s/it, loss=3.1850, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 125/250 [08:49<07:45,  3.72s/it, loss=3.1858, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  50%|█████     | 126/250 [08:53<08:08,  3.94s/it, loss=3.1861, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 127/250 [08:55<06:48,  3.32s/it, loss=3.1852, tokens/Max input_id: 31764\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  51%|█████     | 128/250 [08:58<06:32,  3.21s/it, loss=3.1855, tokens/Max input_id: 31771\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 129/250 [09:01<06:24,  3.18s/it, loss=3.1845, tokens/Max input_id: 31771\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 130/250 [09:04<05:57,  2.98s/it, loss=3.1839, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  52%|█████▏    | 131/250 [09:07<05:48,  2.93s/it, loss=3.1853, tokens/Max input_id: 31768\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 132/250 [09:09<05:23,  2.74s/it, loss=3.1836, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  53%|█████▎    | 133/250 [09:11<04:52,  2.50s/it, loss=3.1837, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▎    | 134/250 [09:18<07:29,  3.87s/it, loss=3.1832, tokens/Max input_id: 31767\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 135/250 [09:22<07:41,  4.01s/it, loss=3.1821, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  54%|█████▍    | 136/250 [09:26<07:29,  3.95s/it, loss=3.1816, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▍    | 137/250 [09:28<06:28,  3.44s/it, loss=3.1815, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  55%|█████▌    | 138/250 [09:32<06:37,  3.55s/it, loss=3.1811, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 139/250 [09:34<05:50,  3.15s/it, loss=3.1803, tokens/Max input_id: 31767\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▌    | 140/250 [09:37<05:21,  2.92s/it, loss=3.1799, tokens/Max input_id: 31772\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  56%|█████▋    | 141/250 [09:41<05:57,  3.28s/it, loss=3.1793, tokens/Max input_id: 31773\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 142/250 [09:43<05:16,  2.93s/it, loss=3.1791, tokens/Max input_id: 31794\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  57%|█████▋    | 143/250 [09:47<05:49,  3.27s/it, loss=3.1791, tokens/Max input_id: 31815\n",
      "Max target_input: 31815\n",
      "Max label: 31815\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 144/250 [09:50<05:34,  3.15s/it, loss=3.1779, tokens/Max input_id: 31770\n",
      "Max target_input: 31770\n",
      "Max label: 31770\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 145/250 [09:55<06:35,  3.77s/it, loss=3.1786, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  58%|█████▊    | 146/250 [09:58<05:51,  3.38s/it, loss=3.1778, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 147/250 [10:00<05:03,  2.95s/it, loss=3.1753, tokens/Max input_id: 31768\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  59%|█████▉    | 148/250 [10:03<05:22,  3.16s/it, loss=3.1754, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|█████▉    | 149/250 [10:07<05:31,  3.28s/it, loss=3.1745, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 150/250 [10:11<06:11,  3.72s/it, loss=3.1742, tokens/Max input_id: 31794\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  60%|██████    | 151/250 [10:14<05:39,  3.43s/it, loss=3.1750, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 152/250 [10:21<07:13,  4.42s/it, loss=3.1747, tokens/Max input_id: 31773\n",
      "Max target_input: 31868\n",
      "Max label: 31868\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  61%|██████    | 153/250 [10:24<06:22,  3.94s/it, loss=3.1741, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 154/250 [10:28<06:17,  3.94s/it, loss=3.1739, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 155/250 [10:30<05:18,  3.36s/it, loss=3.1733, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  62%|██████▏   | 156/250 [10:34<05:28,  3.50s/it, loss=3.1743, tokens/Max input_id: 31779\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 157/250 [10:38<05:38,  3.64s/it, loss=3.1730, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  63%|██████▎   | 158/250 [10:41<05:19,  3.48s/it, loss=3.1745, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▎   | 159/250 [10:44<05:03,  3.34s/it, loss=3.1752, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 160/250 [10:47<05:10,  3.45s/it, loss=3.1763, tokens/Max input_id: 31794\n",
      "Max target_input: 31789\n",
      "Max label: 31789\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  64%|██████▍   | 161/250 [10:53<06:14,  4.21s/it, loss=3.1770, tokens/Max input_id: 31765\n",
      "Max target_input: 31765\n",
      "Max label: 31765\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▍   | 162/250 [10:56<05:35,  3.81s/it, loss=3.1778, tokens/Max input_id: 31767\n",
      "Max target_input: 31794\n",
      "Max label: 31794\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  65%|██████▌   | 163/250 [10:58<04:41,  3.24s/it, loss=3.1762, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 164/250 [11:01<04:42,  3.28s/it, loss=3.1758, tokens/Max input_id: 31773\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▌   | 165/250 [11:06<05:11,  3.67s/it, loss=3.1765, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  66%|██████▋   | 166/250 [11:11<05:35,  3.99s/it, loss=3.1764, tokens/Max input_id: 31782\n",
      "Max target_input: 31782\n",
      "Max label: 31782\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 167/250 [11:14<04:59,  3.61s/it, loss=3.1767, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  67%|██████▋   | 168/250 [11:17<04:45,  3.48s/it, loss=3.1778, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 169/250 [11:20<04:25,  3.28s/it, loss=3.1765, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 170/250 [11:24<04:49,  3.62s/it, loss=3.1763, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  68%|██████▊   | 171/250 [11:31<06:13,  4.73s/it, loss=3.1749, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 172/250 [11:33<05:03,  3.89s/it, loss=3.1748, tokens/Max input_id: 31789\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  69%|██████▉   | 173/250 [11:36<04:44,  3.70s/it, loss=3.1754, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|██████▉   | 174/250 [11:40<04:31,  3.57s/it, loss=3.1749, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 175/250 [11:42<03:52,  3.10s/it, loss=3.1763, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  70%|███████   | 176/250 [11:46<04:13,  3.42s/it, loss=3.1762, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 177/250 [11:48<03:49,  3.15s/it, loss=3.1773, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  71%|███████   | 178/250 [11:51<03:27,  2.89s/it, loss=3.1767, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 179/250 [11:54<03:37,  3.07s/it, loss=3.1772, tokens/Max input_id: 31772\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 180/250 [11:57<03:24,  2.92s/it, loss=3.1775, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  72%|███████▏  | 181/250 [11:59<03:03,  2.67s/it, loss=3.1762, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 182/250 [12:06<04:33,  4.02s/it, loss=3.1748, tokens/Max input_id: 31771\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  73%|███████▎  | 183/250 [12:08<03:58,  3.56s/it, loss=3.1742, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▎  | 184/250 [12:12<03:51,  3.52s/it, loss=3.1741, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 185/250 [12:14<03:28,  3.21s/it, loss=3.1740, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  74%|███████▍  | 186/250 [12:19<03:47,  3.55s/it, loss=3.1738, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▍  | 187/250 [12:21<03:10,  3.02s/it, loss=3.1722, tokens/Max input_id: 31794\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  75%|███████▌  | 188/250 [12:23<03:01,  2.93s/it, loss=3.1721, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 189/250 [12:27<03:14,  3.20s/it, loss=3.1711, tokens/Max input_id: 31770\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▌  | 190/250 [12:35<04:29,  4.49s/it, loss=3.1709, tokens/Max input_id: 31800\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  76%|███████▋  | 191/250 [12:38<03:59,  4.06s/it, loss=3.1701, tokens/Max input_id: 31793\n",
      "Max target_input: 31793\n",
      "Max label: 31793\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 192/250 [12:40<03:33,  3.67s/it, loss=3.1681, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  77%|███████▋  | 193/250 [12:43<03:13,  3.40s/it, loss=3.1677, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 194/250 [12:49<03:52,  4.15s/it, loss=3.1679, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 195/250 [12:51<03:14,  3.53s/it, loss=3.1674, tokens/Max input_id: 31771\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  78%|███████▊  | 196/250 [12:54<02:59,  3.33s/it, loss=3.1676, tokens/Max input_id: 31794\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 197/250 [12:56<02:41,  3.04s/it, loss=3.1667, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  79%|███████▉  | 198/250 [13:00<02:41,  3.10s/it, loss=3.1661, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|███████▉  | 199/250 [13:05<03:06,  3.66s/it, loss=3.1652, tokens/Max input_id: 31794\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 200/250 [13:10<03:29,  4.20s/it, loss=3.1646, tokens/Max input_id: 31794\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  80%|████████  | 201/250 [13:16<03:57,  4.84s/it, loss=3.1656, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 202/250 [13:22<04:11,  5.23s/it, loss=3.1662, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  81%|████████  | 203/250 [13:25<03:31,  4.49s/it, loss=3.1654, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 204/250 [13:29<03:16,  4.28s/it, loss=3.1648, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 205/250 [13:34<03:22,  4.49s/it, loss=3.1658, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  82%|████████▏ | 206/250 [13:37<03:00,  4.10s/it, loss=3.1659, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 207/250 [13:40<02:44,  3.83s/it, loss=3.1667, tokens/Max input_id: 31771\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  83%|████████▎ | 208/250 [13:43<02:22,  3.39s/it, loss=3.1667, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▎ | 209/250 [13:46<02:20,  3.44s/it, loss=3.1669, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 210/250 [13:52<02:41,  4.05s/it, loss=3.1669, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  84%|████████▍ | 211/250 [13:57<02:49,  4.35s/it, loss=3.1658, tokens/Max input_id: 31790\n",
      "Max target_input: 31790\n",
      "Max label: 31790\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▍ | 212/250 [14:03<03:00,  4.75s/it, loss=3.1651, tokens/Max input_id: 31794\n",
      "Max target_input: 31757\n",
      "Max label: 31757\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  85%|████████▌ | 213/250 [14:07<02:48,  4.56s/it, loss=3.1646, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 214/250 [14:11<02:38,  4.41s/it, loss=3.1648, tokens/Max input_id: 31767\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▌ | 215/250 [14:13<02:11,  3.76s/it, loss=3.1631, tokens/Max input_id: 31771\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  86%|████████▋ | 216/250 [14:17<02:11,  3.87s/it, loss=3.1629, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 217/250 [14:22<02:15,  4.11s/it, loss=3.1624, tokens/Max input_id: 31771\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  87%|████████▋ | 218/250 [14:26<02:14,  4.22s/it, loss=3.1614, tokens/Max input_id: 31768\n",
      "Max target_input: 31768\n",
      "Max label: 31768\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 219/250 [14:32<02:28,  4.79s/it, loss=3.1601, tokens/Max input_id: 31762\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 220/250 [14:35<02:06,  4.21s/it, loss=3.1600, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  88%|████████▊ | 221/250 [14:38<01:52,  3.88s/it, loss=3.1593, tokens/Max input_id: 31794\n",
      "Max target_input: 31809\n",
      "Max label: 31809\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 222/250 [14:42<01:47,  3.83s/it, loss=3.1576, tokens/Max input_id: 31768\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  89%|████████▉ | 223/250 [14:45<01:37,  3.60s/it, loss=3.1573, tokens/Max input_id: 31772\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|████████▉ | 224/250 [14:50<01:40,  3.86s/it, loss=3.1579, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 225/250 [14:52<01:25,  3.40s/it, loss=3.1568, tokens/Max input_id: 31794\n",
      "Max target_input: 31777\n",
      "Max label: 31777\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  90%|█████████ | 226/250 [14:55<01:18,  3.29s/it, loss=3.1541, tokens/Max input_id: 31794\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 227/250 [14:57<01:05,  2.86s/it, loss=3.1525, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  91%|█████████ | 228/250 [14:59<00:56,  2.58s/it, loss=3.1510, tokens/Max input_id: 31787\n",
      "Max target_input: 31787\n",
      "Max label: 31787\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 229/250 [15:03<01:02,  2.97s/it, loss=3.1511, tokens/Max input_id: 31767\n",
      "Max target_input: 31762\n",
      "Max label: 31762\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 230/250 [15:05<00:58,  2.91s/it, loss=3.1493, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  92%|█████████▏| 231/250 [15:10<01:05,  3.45s/it, loss=3.1484, tokens/Max input_id: 31771\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 232/250 [15:15<01:10,  3.93s/it, loss=3.1483, tokens/Max input_id: 31767\n",
      "Max target_input: 31772\n",
      "Max label: 31772\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  93%|█████████▎| 233/250 [15:17<00:57,  3.38s/it, loss=3.1473, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▎| 234/250 [15:25<01:15,  4.73s/it, loss=3.1469, tokens/Max input_id: 31764\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 235/250 [15:28<01:01,  4.08s/it, loss=3.1478, tokens/Max input_id: 31797\n",
      "Max target_input: 31797\n",
      "Max label: 31797\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  94%|█████████▍| 236/250 [15:34<01:06,  4.75s/it, loss=3.1495, tokens/Max input_id: 31767\n",
      "Max target_input: 31767\n",
      "Max label: 31767\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▍| 237/250 [15:37<00:53,  4.12s/it, loss=3.1490, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  95%|█████████▌| 238/250 [15:42<00:55,  4.63s/it, loss=3.1483, tokens/Max input_id: 31773\n",
      "Max target_input: 31773\n",
      "Max label: 31773\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 239/250 [15:46<00:46,  4.27s/it, loss=3.1490, tokens/Max input_id: 31801\n",
      "Max target_input: 31801\n",
      "Max label: 31801\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▌| 240/250 [15:49<00:38,  3.85s/it, loss=3.1487, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  96%|█████████▋| 241/250 [15:51<00:30,  3.42s/it, loss=3.1487, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 242/250 [15:55<00:28,  3.55s/it, loss=3.1499, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  97%|█████████▋| 243/250 [15:58<00:22,  3.25s/it, loss=3.1490, tokens/Max input_id: 31767\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 244/250 [16:00<00:18,  3.11s/it, loss=3.1483, tokens/Max input_id: 31767\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 245/250 [16:03<00:14,  2.89s/it, loss=3.1474, tokens/Max input_id: 31794\n",
      "Max target_input: 31764\n",
      "Max label: 31764\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Training:  98%|█████████▊| 246/250 [16:06<00:12,  3.14s/it, loss=3.1468, tokens/Max input_id: 31782\n",
      "Max target_input: 31792\n",
      "Max label: 31792\n",
      "Training:  99%|█████████▉| 247/250 [16:11<00:10,  3.55s/it, loss=3.1481, tokens/Max input_id: 31781\n",
      "Max target_input: 31781\n",
      "Max label: 31781\n",
      "Training:  99%|█████████▉| 248/250 [16:13<00:06,  3.25s/it, loss=3.1475, tokens/Max input_id: 31800\n",
      "Max target_input: 31800\n",
      "Max label: 31800\n",
      "Training: 100%|█████████▉| 249/250 [16:16<00:02,  2.98s/it, loss=3.1480, tokens/Max input_id: 31771\n",
      "Max target_input: 31771\n",
      "Max label: 31771\n",
      "Training: 100%|██████████| 250/250 [16:34<00:00,  3.98s/it, loss=3.1489, tokens/\n",
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   3%|█                               | 1/32 [00:07<03:44,  7.25s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   6%|██                              | 2/32 [00:09<02:11,  4.37s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:   9%|███                             | 3/32 [00:11<01:28,  3.04s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  12%|████                            | 4/32 [00:11<01:01,  2.19s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  16%|█████                           | 5/32 [00:13<00:49,  1.84s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  19%|██████                          | 6/32 [00:14<00:41,  1.60s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  22%|███████                         | 7/32 [00:16<00:41,  1.65s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  25%|████████                        | 8/32 [00:17<00:34,  1.44s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  28%|█████████                       | 9/32 [00:18<00:32,  1.42s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  31%|█████████▋                     | 10/32 [00:19<00:27,  1.23s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  34%|██████████▋                    | 11/32 [00:20<00:24,  1.18s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  38%|███████████▋                   | 12/32 [00:21<00:21,  1.06s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  41%|████████████▌                  | 13/32 [00:22<00:20,  1.10s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  44%|█████████████▌                 | 14/32 [00:23<00:22,  1.24s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  47%|██████████████▌                | 15/32 [00:24<00:19,  1.14s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  50%|███████████████▌               | 16/32 [00:25<00:16,  1.04s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  53%|████████████████▍              | 17/32 [00:26<00:16,  1.07s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  56%|█████████████████▍             | 18/32 [00:27<00:14,  1.01s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  59%|██████████████████▍            | 19/32 [00:28<00:12,  1.01it/s]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  62%|███████████████████▍           | 20/32 [00:29<00:12,  1.00s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  66%|████████████████████▎          | 21/32 [00:31<00:12,  1.16s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  69%|█████████████████████▎         | 22/32 [00:32<00:11,  1.12s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  72%|██████████████████████▎        | 23/32 [00:33<00:10,  1.14s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  75%|███████████████████████▎       | 24/32 [00:34<00:09,  1.17s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  78%|████████████████████████▏      | 25/32 [00:35<00:07,  1.11s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  81%|█████████████████████████▏     | 26/32 [00:37<00:08,  1.43s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating:  84%|██████████████████████████▏    | 27/32 [00:38<00:06,  1.27s/it]Tokenizer vocab size: 32000\n",
      "Special tokens:\n",
      "  [PAD] ID: 0\n",
      "  [UNK] ID: 1\n",
      "  [BOS] ID: 2\n",
      "  [EOS] ID: 3\n",
      "  [DE] ID: 4\n",
      "  [EN] ID: 5\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:51<00:00,  1.62s/it]\n",
      "Removed old checkpoint: model_epoch_10.pt\n",
      "Saved checkpoint to checkpoints/model_epoch_10.pt\n",
      "Saved training results to training_results_20250511_234207.csv\n",
      "Train Loss: 3.1489\n",
      "Val Loss: 4.6518\n",
      "Learning Rate: 0.000100\n",
      "[DE] ID: 4\n",
      "[EN] ID: 5\n",
      "\n",
      "Sample translation:\n",
      "German: Hallo, wie geht es dir?\n",
      "English: ??\n"
     ]
    }
   ],
   "source": [
    "# tokenizer with full dataset\n",
    "\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.read_csv(\"training_results_20250511_234207.csv\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(results['train_loss'], label='Train Loss', color='blue')\n",
    "plt.plot(results['val_loss'], label='Validation Loss', color='green')\n",
    "plt.title('Seq2Seq Transformer Loss over Training Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_losses, val_losses):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    # Plot curves\n",
    "    plt.plot(train_losses, label='Train Loss', color='royalblue', linewidth=2.5)\n",
    "    plt.plot(val_losses, label='Validation Loss', color='seagreen', linewidth=2.5)\n",
    "\n",
    "    # Style tweaks\n",
    "    plt.title(\"Seq2Seq Transformer Loss over Epochs\", fontsize=14, weight='bold')\n",
    "    plt.xlabel(\"Epoch\", fontsize=12)\n",
    "    plt.ylabel(\"Loss\", fontsize=12)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Optional: remove top/right borders\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(results['train_loss'], results['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_split = pd.read_csv(\"training_results_20250511_185336.csv\")\n",
    "plot_loss(results_split['train_loss'], results_split['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-en-translator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
